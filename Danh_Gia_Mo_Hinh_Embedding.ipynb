{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Đánh Giá Mô Hình Embedding Cho Luật Tiếng Việt\n",
        "\n",
        "Notebook này thực hiện đánh giá sơ bộ nhiều mô hình embedding cho tiếng Việt và luật tiếng Việt\n",
        "\n",
        "## Yêu cầu:\n",
        "- Đánh giá các mô hình embedding từ 512 token trở lên\n",
        "- Lưu embeddings trên RAM\n",
        "- Làm giàu data: 200-300 văn bản luật\n",
        "- Sử dụng queries từ benchmark\n",
        "- Đánh giá top 10-15 kết quả và ngưỡng điểm\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔄 Importing core libraries...\n",
            "⚠️  huggingface_hub: expected 0.16.4, got 0.34.4\n",
            "⚠️  tokenizers: expected 0.13.3, got 0.22.0\n",
            "⚠️  transformers: expected 4.32.1, got 4.56.1\n",
            "⚠️  sentence-transformers: expected 2.2.2, got 5.1.0\n",
            "\n",
            "🔄 Importing transformers...\n",
            "✅ transformers imported successfully\n",
            "✅ transformers functionality test passed\n",
            "\n",
            "🔄 Importing sentence-transformers...\n",
            "✅ sentence-transformers imported successfully\n",
            "✅ sentence-transformers functionality test passed (embedding shape: (1, 384))\n",
            "\n",
            "🔄 Importing document processing...\n",
            "✅ python-docx imported successfully\n",
            "\n",
            "🖥️  Using device: cuda\n",
            "   GPU: NVIDIA GeForce RTX 3050 Ti Laptop GPU\n",
            "   GPU Memory: 4.3 GB\n",
            "\n",
            "🎉 All libraries loaded successfully! Ready for evaluation.\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "print(\"🔄 Importing core libraries...\")\n",
        "\n",
        "# Check installed versions\n",
        "def check_version(package_name, expected_version=None):\n",
        "    try:\n",
        "        import importlib.metadata\n",
        "        version = importlib.metadata.version(package_name)\n",
        "        if expected_version and version != expected_version:\n",
        "            print(f\"⚠️  {package_name}: expected {expected_version}, got {version}\")\n",
        "        else:\n",
        "            print(f\"✅ {package_name}: {version}\")\n",
        "        return True, version\n",
        "    except Exception as e:\n",
        "        print(f\"❌ {package_name}: not found or error ({e})\")\n",
        "        return False, None\n",
        "\n",
        "# Check critical versions\n",
        "check_version(\"huggingface_hub\", \"0.16.4\")\n",
        "check_version(\"tokenizers\", \"0.13.3\")\n",
        "check_version(\"transformers\", \"4.32.1\")\n",
        "check_version(\"sentence-transformers\", \"2.2.2\")\n",
        "\n",
        "# Import transformers with detailed error handling\n",
        "print(\"\\n🔄 Importing transformers...\")\n",
        "try:\n",
        "    from transformers import AutoTokenizer, AutoModel\n",
        "    print(\"✅ transformers imported successfully\")\n",
        "    \n",
        "    # Quick functionality test\n",
        "    test_tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "    test_tokens = test_tokenizer(\"test\", return_tensors=\"pt\")\n",
        "    print(\"✅ transformers functionality test passed\")\n",
        "    del test_tokenizer, test_tokens\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"❌ transformers failed: {e}\")\n",
        "    print(\"🔧 If this fails, please restart kernel and run first cell again\")\n",
        "    raise\n",
        "\n",
        "# Import sentence-transformers with detailed error handling\n",
        "print(\"\\n🔄 Importing sentence-transformers...\")\n",
        "try:\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "    print(\"✅ sentence-transformers imported successfully\")\n",
        "    \n",
        "    # Quick functionality test\n",
        "    test_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "    test_embedding = test_model.encode([\"test sentence\"])\n",
        "    print(f\"✅ sentence-transformers functionality test passed (embedding shape: {test_embedding.shape})\")\n",
        "    del test_model, test_embedding\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"❌ sentence-transformers failed: {e}\")\n",
        "    print(\"🔧 If this fails, please restart kernel and run first cell again\")\n",
        "    raise\n",
        "\n",
        "# Import document processing\n",
        "print(\"\\n🔄 Importing document processing...\")\n",
        "try:\n",
        "    from docx import Document\n",
        "    print(\"✅ python-docx imported successfully\")\n",
        "except ImportError:\n",
        "    print(\"📦 Installing python-docx...\")\n",
        "    import subprocess\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"python-docx==0.8.11\"])\n",
        "    from docx import Document\n",
        "    print(\"✅ python-docx installed and imported\")\n",
        "\n",
        "# Device configuration\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"\\n🖥️  Using device: {device}\")\n",
        "if device == \"cuda\":\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name()}\")\n",
        "    print(f\"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "\n",
        "print(\"\\n🎉 All libraries loaded successfully! Ready for evaluation.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Chuẩn bị dữ liệu luật\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔢 Setting up Roman numeral converter...\n",
            "✅ Roman converter test:\n",
            "   I -> 1\n",
            "   II -> 2\n",
            "   III -> 3\n",
            "   IV -> 4\n",
            "   V -> 5\n",
            "   VI -> 6\n",
            "   VII -> 7\n",
            "   VIII -> 8\n",
            "   IX -> 9\n",
            "   X -> 10\n",
            "   L -> 50\n",
            "   C -> 100\n",
            "   D -> 500\n",
            "   M -> 1000\n",
            "✅ Roman numeral converter ready!\n"
          ]
        }
      ],
      "source": [
        "# ===== ROMAN NUMBER CONVERTER =====\n",
        "print(\"🔢 Setting up Roman numeral converter...\")\n",
        "\n",
        "ROMAN_MAP = {'I':1,'V':5,'X':10,'L':50,'C':100,'D':500,'M':1000}\n",
        "\n",
        "def roman_to_int(s: str):\n",
        "    \"\"\"\n",
        "    Chuyển đổi số La Mã sang số nguyên\n",
        "    Ví dụ: 'I' -> 1, 'IV' -> 4, 'IX' -> 9, 'X' -> 10\n",
        "    \"\"\"\n",
        "    s = s.upper().strip()\n",
        "    if not s or any(ch not in ROMAN_MAP for ch in s):\n",
        "        return None\n",
        "    total = 0\n",
        "    prev = 0\n",
        "    for ch in reversed(s):\n",
        "        val = ROMAN_MAP[ch]\n",
        "        if val < prev:\n",
        "            total -= val\n",
        "        else:\n",
        "            total += val\n",
        "            prev = val\n",
        "    return total\n",
        "\n",
        "# Test Roman converter\n",
        "test_romans = ['I',\"II\",\"III\",\"IV\",\"V\",\"VI\",\"VII\",\"VIII\",\"IX\",\"X\", \"L\", \"C\", \"D\", \"M\"]\n",
        "print(\"✅ Roman converter test:\")\n",
        "for roman in test_romans:\n",
        "    print(f\"   {roman} -> {roman_to_int(roman)}\")\n",
        "\n",
        "print(\"✅ Roman numeral converter ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔧 Setting up embedding utility functions...\n",
            "✅ Embedding utility functions ready!\n",
            "   📦 encode_with_transformers: for transformers models with mean pooling\n",
            "   📦 encode_with_sentence_transformers: for sentence-transformers models\n",
            "   💾 All embeddings stored in RAM (not vector database)\n"
          ]
        }
      ],
      "source": [
        "# ===== UTILITY FUNCTIONS FOR EMBEDDING =====\n",
        "print(\"🔧 Setting up embedding utility functions...\")\n",
        "\n",
        "def mean_pooling(model_output, attention_mask):\n",
        "    \"\"\"\n",
        "    Mean pooling để tạo sentence embeddings từ token embeddings\n",
        "    \n",
        "    Input:\n",
        "    - model_output: output từ transformer model\n",
        "    - attention_mask: mask để ignore padding tokens\n",
        "    \n",
        "    Output:\n",
        "    - Sentence embeddings với mean pooling\n",
        "    \"\"\"\n",
        "    token_embeddings = model_output[0]  # First element of model_output contains all token embeddings\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "\n",
        "def encode_with_transformers(texts, model_name, max_length=512, batch_size=32):\n",
        "    \"\"\"\n",
        "    Encode texts using transformers library với mean pooling\n",
        "    \n",
        "    Input:\n",
        "    - texts: list of texts to encode\n",
        "    - model_name: HuggingFace model name\n",
        "    - max_length: maximum sequence length\n",
        "    - batch_size: batch size for processing\n",
        "    \n",
        "    Output:\n",
        "    - numpy array of embeddings (stored in RAM)\n",
        "    \"\"\"\n",
        "    print(f\"Loading model: {model_name}\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModel.from_pretrained(model_name).to(device)\n",
        "    model.eval()\n",
        "    \n",
        "    all_embeddings = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(0, len(texts), batch_size), desc=\"Encoding\"):\n",
        "            batch = texts[i:i+batch_size]\n",
        "            \n",
        "            # Tokenize\n",
        "            encoded = tokenizer(\n",
        "                batch, \n",
        "                padding=True, \n",
        "                truncation=True, \n",
        "                max_length=max_length,\n",
        "                return_tensors='pt'\n",
        "            ).to(device)\n",
        "            \n",
        "            # Get model output\n",
        "            model_output = model(**encoded)\n",
        "            \n",
        "            # Mean pooling\n",
        "            sentence_embeddings = mean_pooling(model_output, encoded['attention_mask'])\n",
        "            \n",
        "            # Normalize embeddings\n",
        "            sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)\n",
        "            \n",
        "            # Move to CPU and convert to numpy (store in RAM)\n",
        "            embeddings = sentence_embeddings.cpu().numpy()\n",
        "            all_embeddings.append(embeddings)\n",
        "            \n",
        "            # Clear GPU memory\n",
        "            del encoded, model_output, sentence_embeddings, embeddings\n",
        "            torch.cuda.empty_cache() if device == \"cuda\" else None\n",
        "    \n",
        "    # Delete model to free memory\n",
        "    del model, tokenizer\n",
        "    torch.cuda.empty_cache() if device == \"cuda\" else None\n",
        "    \n",
        "    # Combine all embeddings and store in RAM\n",
        "    final_embeddings = np.vstack(all_embeddings)\n",
        "    print(f\"   ✅ Generated {final_embeddings.shape[0]} embeddings, stored in RAM\")\n",
        "    \n",
        "    return final_embeddings\n",
        "\n",
        "def encode_with_sentence_transformers(texts, model_name, batch_size=32):\n",
        "    \"\"\"\n",
        "    Encode texts using sentence-transformers library\n",
        "    \n",
        "    Input:\n",
        "    - texts: list of texts to encode  \n",
        "    - model_name: SentenceTransformer model name\n",
        "    - batch_size: batch size for processing\n",
        "    \n",
        "    Output:\n",
        "    - numpy array of embeddings (stored in RAM)\n",
        "    \"\"\"\n",
        "    print(f\"Loading model: {model_name}\")\n",
        "    model = SentenceTransformer(model_name)\n",
        "    model.to(device)\n",
        "    \n",
        "    # Encode all texts\n",
        "    embeddings = model.encode(\n",
        "        texts,\n",
        "        batch_size=batch_size,\n",
        "        show_progress_bar=True,\n",
        "        convert_to_numpy=True,  # Convert to numpy (RAM storage)\n",
        "        normalize_embeddings=True  # Normalize for cosine similarity\n",
        "    )\n",
        "    \n",
        "    # Delete model to free memory\n",
        "    del model\n",
        "    torch.cuda.empty_cache() if device == \"cuda\" else None\n",
        "    \n",
        "    print(f\"   ✅ Generated {embeddings.shape[0]} embeddings, stored in RAM\")\n",
        "    \n",
        "    return embeddings\n",
        "\n",
        "print(\"✅ Embedding utility functions ready!\")\n",
        "print(\"   📦 encode_with_transformers: for transformers models with mean pooling\")\n",
        "print(\"   📦 encode_with_sentence_transformers: for sentence-transformers models\") \n",
        "print(\"   💾 All embeddings stored in RAM (not vector database)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📖 Setting up document reading functions...\n",
            "✅ Document reading functions ready!\n"
          ]
        }
      ],
      "source": [
        "# ===== DOCUMENT READER FUNCTIONS =====\n",
        "print(\"📖 Setting up document reading functions...\")\n",
        "\n",
        "def read_docx(file_path):\n",
        "    \"\"\"\n",
        "    Đọc file docx và trả về text\n",
        "    Input: đường dẫn file .docx\n",
        "    Output: text content của file\n",
        "    \"\"\"\n",
        "    print(f\"   Reading file: {file_path}\")\n",
        "    doc = Document(file_path)\n",
        "    text = \"\\n\".join((p.text or \"\").strip() for p in doc.paragraphs)\n",
        "    print(f\"   ✅ Successfully read {len(text):,} characters\")\n",
        "    return text\n",
        "\n",
        "def normalize_lines(text: str):\n",
        "    \"\"\"\n",
        "    Chuẩn hóa các dòng text - loại bỏ whitespace thừa\n",
        "    Input: raw text\n",
        "    Output: list các dòng đã được normalize\n",
        "    \"\"\"\n",
        "    lines = [re.sub(r'\\s+$', '', ln) for ln in text.splitlines()]\n",
        "    print(f\"   ✅ Normalized {len(lines):,} lines\")\n",
        "    return lines\n",
        "\n",
        "print(\"✅ Document reading functions ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚖️ Setting up PROPER advanced law document chunking (from chunking.py)...\n",
            "✅ PROPER Advanced law document chunking ready!\n"
          ]
        }
      ],
      "source": [
        "# ===== PROPER ADVANCED LAW DOCUMENT CHUNKING =====\n",
        "print(\"⚖️ Setting up PROPER advanced law document chunking (from chunking.py)...\")\n",
        "\n",
        "def advanced_chunk_law_document(text, max_length=600):\n",
        "    \"\"\"\n",
        "    Chia văn bản luật thành chunks theo logic CHÍNH XÁC \n",
        "    \n",
        "    2-Pass System:\n",
        "    - Pass 1 (prescan): Đếm CHƯƠNG & ĐIỀU ở đầu dòng\n",
        "    - Pass 2 (strict): Strict sequence validation + Clause intro injection\n",
        "    \n",
        "    KEY FEATURES:\n",
        "    - Khoản: PHẢI dạng \"1.\" (số + dấu chấm)\n",
        "    - Điểm: PHẢI dạng \"a)\" (có dấu )). Chỉ bắt chuỗi điểm nếu mở đầu là a).\n",
        "    - TIÊM intro khoản vào content của mọi điểm (QUAN TRỌNG!)\n",
        "    \"\"\"\n",
        "    print(\"   🔍 2-Pass advanced parsing with full validation...\")\n",
        "    lines = normalize_lines(text)\n",
        "    \n",
        "    # ===== Regex patterns (CHÍNH XÁC từ chunking.py) =====\n",
        "    ARTICLE_RE = re.compile(r'^Điều\\s+(\\d+)\\s*[\\.:]?\\s*(.*)$', re.UNICODE)\n",
        "    CHAPTER_RE = re.compile(r'^Chương\\s+([IVXLCDM]+)\\s*(.*)$', re.UNICODE|re.IGNORECASE)\n",
        "    SECTION_RE = re.compile(r'^Mục\\s+(\\d+)\\s*[:\\-]?\\s*(.*)$', re.UNICODE|re.IGNORECASE)\n",
        "    CLAUSE_RE = re.compile(r'^\\s*(\\d+)\\.\\s*(.*)$', re.UNICODE)  # Khoản: PHẢI \"1.\" (số + dấu chấm)\n",
        "    POINT_RE = re.compile(r'^\\s*([a-zA-ZđĐ])\\)\\s+(.*)$', re.UNICODE)  # Điểm: PHẢI \"a)\" (bắt buộc có ')')\n",
        "    \n",
        "    # ===== PASS 1: Pre-scan CHƯƠNG/ĐIỀU =====\n",
        "    def prescan(lines):\n",
        "        chapters_nums, articles_nums = [], []\n",
        "        chapters_labels = []\n",
        "        for line in lines:\n",
        "            if not line: continue\n",
        "            m_ch = CHAPTER_RE.match(line)\n",
        "            if m_ch:\n",
        "                n = roman_to_int(m_ch.group(1))\n",
        "                if n:\n",
        "                    chapters_nums.append(n)\n",
        "                    title = (m_ch.group(2) or \"\").strip()\n",
        "                    chapters_labels.append(f\"Chương {m_ch.group(1).strip()}\" + (f\" – {title}\" if title else \"\"))\n",
        "                continue\n",
        "            m_art = ARTICLE_RE.match(line)\n",
        "            if m_art:\n",
        "                num = int(m_art.group(1))\n",
        "                articles_nums.append(num)\n",
        "                continue\n",
        "        return chapters_nums, articles_nums, chapters_labels\n",
        "    \n",
        "    # ===== Flush helpers =====\n",
        "    def flush_article_intro(chunks, article_no, article_title, article_intro_buf, chapter, section, stats):\n",
        "        content = (article_intro_buf or \"\").strip()\n",
        "        if not content: return\n",
        "        title_line = f\"Điều {article_no}. {article_title}\".strip() if article_title else f\"Điều {article_no}\"\n",
        "        chunks.append({\n",
        "            \"content\": f\"{title_line}\\n{content}\",\n",
        "            \"title\": f\"Điều {article_no} - {article_title}\" if article_title else f\"Điều {article_no}\",\n",
        "            \"type\": \"article_intro\",\n",
        "            \"metadata\": {\n",
        "                \"chapter\": chapter,\n",
        "                \"section\": section,\n",
        "                \"article_no\": article_no,\n",
        "                \"article_title\": article_title,\n",
        "                \"exact_citation\": f\"Điều {article_no}\"\n",
        "            }\n",
        "        })\n",
        "        stats[\"article_intro\"] += 1\n",
        "    \n",
        "    def flush_clause(chunks, article_no, article_title, clause_no, content, chapter, section, stats):\n",
        "        content = (content or \"\").strip()\n",
        "        if not content: return\n",
        "        chunks.append({\n",
        "            \"content\": f\"Khoản {clause_no}. {content}\",\n",
        "            \"title\": f\"Điều {article_no}, Khoản {clause_no}\",\n",
        "            \"type\": \"clause\",\n",
        "            \"metadata\": {\n",
        "                \"chapter\": chapter,\n",
        "                \"section\": section,\n",
        "                \"article_no\": article_no,\n",
        "                \"article_title\": article_title,\n",
        "                \"clause_no\": clause_no,\n",
        "                \"exact_citation\": f\"Điều {article_no} khoản {clause_no}\"\n",
        "            }\n",
        "        })\n",
        "        stats[\"clauses\"] += 1\n",
        "    \n",
        "    def flush_point(chunks, article_no, article_title, clause_no, letter, content, chapter, section, stats, clause_intro=None):\n",
        "        content = (content or \"\").strip()\n",
        "        if not content: return\n",
        "        \n",
        "        # 🔥 TIÊM intro khoản vào đầu nội dung điểm (KEY FEATURE từ chunking.py!)\n",
        "        if clause_intro:\n",
        "            intro = clause_intro.rstrip().rstrip(':') + ':'\n",
        "            content = f\"{intro}\\n{content}\"\n",
        "        \n",
        "        letter = letter.lower()\n",
        "        chunks.append({\n",
        "            \"content\": f\"Khoản {clause_no}, điểm {letter}) {content}\",\n",
        "            \"title\": f\"Điều {article_no}, Khoản {clause_no}, Điểm {letter})\",\n",
        "            \"type\": \"point\",\n",
        "            \"metadata\": {\n",
        "                \"chapter\": chapter,\n",
        "                \"section\": section,\n",
        "                \"article_no\": article_no,\n",
        "                \"article_title\": article_title,\n",
        "                \"clause_no\": clause_no,\n",
        "                \"point_letter\": letter,\n",
        "                \"exact_citation\": f\"Điều {article_no} khoản {clause_no} điểm {letter})\",\n",
        "                \"clause_intro\": clause_intro  # Lưu để trace\n",
        "            }\n",
        "        })\n",
        "        stats[\"points\"] += 1\n",
        "    \n",
        "    print(f\"   📄 Processing {len(lines):,} lines...\")\n",
        "    \n",
        "    # PASS 1: Pre-scan\n",
        "    print(\"   🔍 Pass 1: Pre-scanning structure...\")\n",
        "    chapters_nums, articles_nums, chapters_labels = prescan(lines)\n",
        "    chapters_set, articles_set = set(chapters_nums), set(articles_nums)\n",
        "    \n",
        "    print(f\"      - Pre-scan found {len(chapters_nums)} chapters: {chapters_nums[:10]}{'...' if len(chapters_nums)>10 else ''}\")\n",
        "    print(f\"      - Pre-scan found {len(articles_nums)} articles: {articles_nums[:20]}{'...' if len(articles_nums)>20 else ''}\")\n",
        "    \n",
        "    # PASS 2: Strict chunking\n",
        "    print(\"   🔍 Pass 2: Strict parsing with sequence validation...\")\n",
        "    chunks = []\n",
        "    stats = {\"articles\": 0, \"article_intro\": 0, \"clauses\": 0, \"points\": 0}\n",
        "    warnings = []\n",
        "    \n",
        "    chapter_label = None\n",
        "    section_label = None\n",
        "    article_no = None\n",
        "    article_title = \"\"\n",
        "    expecting_article_title = False\n",
        "    article_intro_buf = \"\"\n",
        "    article_has_any_chunk = False\n",
        "    \n",
        "    clause_no = None\n",
        "    clause_buf = \"\"\n",
        "    clause_intro_current = None  # 🔥 Intro của khoản sẽ được tiêm vào mọi điểm\n",
        "    in_points = False\n",
        "    point_letter = None\n",
        "    point_buf = \"\"\n",
        "    \n",
        "    expected_chapter = None\n",
        "    expected_article = None\n",
        "    seeking_article = False\n",
        "    \n",
        "    def close_clause():\n",
        "        nonlocal clause_no, clause_buf, in_points, point_letter, point_buf, article_has_any_chunk, clause_intro_current\n",
        "        if clause_no is None: return\n",
        "        if in_points and point_letter:\n",
        "            flush_point(chunks, article_no, article_title, clause_no, point_letter,\n",
        "                        point_buf, chapter_label, section_label, stats, clause_intro_current)\n",
        "        elif clause_buf.strip():\n",
        "            flush_clause(chunks, article_no, article_title, clause_no, clause_buf,\n",
        "                         chapter_label, section_label, stats)\n",
        "        article_has_any_chunk = True\n",
        "        clause_no, clause_buf, in_points, point_letter, point_buf = None, \"\", False, None, \"\"\n",
        "        clause_intro_current = None\n",
        "    \n",
        "    def close_article_if_needed():\n",
        "        nonlocal article_intro_buf, article_has_any_chunk\n",
        "        if (not article_has_any_chunk) and article_intro_buf.strip():\n",
        "            flush_article_intro(chunks, article_no, article_title, article_intro_buf,\n",
        "                                chapter_label, section_label, stats)\n",
        "        article_intro_buf = \"\"\n",
        "        article_has_any_chunk = False\n",
        "    \n",
        "    for ln_idx, line in enumerate(lines, start=1):\n",
        "        if not line: continue\n",
        "        \n",
        "        # Seeking article logic (strict sequence validation)\n",
        "        if seeking_article:\n",
        "            m_art_seek = ARTICLE_RE.match(line)\n",
        "            if m_art_seek:\n",
        "                a_no = int(m_art_seek.group(1))\n",
        "                if a_no == expected_article:\n",
        "                    seeking_article = False\n",
        "                    close_clause()\n",
        "                    if article_no is not None:\n",
        "                        close_article_if_needed()\n",
        "                    article_no = a_no\n",
        "                    article_title = (m_art_seek.group(2) or \"\").strip()\n",
        "                    stats[\"articles\"] += 1\n",
        "                    if not article_title:\n",
        "                        expecting_article_title = True\n",
        "                    expected_article = a_no + 1\n",
        "                    clause_no = None; clause_buf = \"\"; in_points = False; point_letter = None; point_buf = \"\"\n",
        "                    clause_intro_current = None\n",
        "                    continue\n",
        "                else:\n",
        "                    continue\n",
        "            m_ch_seek = CHAPTER_RE.match(line)\n",
        "            if m_ch_seek:\n",
        "                break  # Stop if hit new chapter while seeking\n",
        "            continue\n",
        "        \n",
        "        # Expecting article title on next line\n",
        "        if expecting_article_title:\n",
        "            if not (CHAPTER_RE.match(line) or SECTION_RE.match(line) or CLAUSE_RE.match(line) or POINT_RE.match(line) or ARTICLE_RE.match(line)):\n",
        "                article_title = line; expecting_article_title = False; continue\n",
        "            else:\n",
        "                expecting_article_title = False\n",
        "        \n",
        "        # CHƯƠNG (with strict sequence validation)\n",
        "        m_ch = CHAPTER_RE.match(line)\n",
        "        if m_ch:\n",
        "            close_clause()\n",
        "            if article_no is not None:\n",
        "                close_article_if_needed()\n",
        "            article_no = None\n",
        "            article_title = \"\"\n",
        "            article_intro_buf = \"\"\n",
        "            expecting_article_title = False\n",
        "            \n",
        "            roman = m_ch.group(1).strip()\n",
        "            ch_num = roman_to_int(roman) or 0\n",
        "            ch_title = (m_ch.group(2) or \"\").strip()\n",
        "            lbl = f\"Chương {roman}\" + (f\" – {ch_title}\" if ch_title else \"\")\n",
        "            \n",
        "            if expected_chapter is None:\n",
        "                expected_chapter = ch_num + 1\n",
        "            else:\n",
        "                if ch_num == expected_chapter:\n",
        "                    expected_chapter = ch_num + 1\n",
        "                elif ch_num > expected_chapter:\n",
        "                    if expected_chapter not in chapters_set:\n",
        "                        warnings.append(f\"Missing Chapter {expected_chapter} - stopping at {lbl}\")\n",
        "                        break\n",
        "                    else:\n",
        "                        warnings.append(f\"Skipping {lbl} - waiting for Chapter {expected_chapter}\")\n",
        "                        continue\n",
        "                else:\n",
        "                    warnings.append(f\"Skipping {lbl} - backward chapter number\")\n",
        "                    continue\n",
        "            \n",
        "            chapter_label = lbl\n",
        "            section_label = None\n",
        "            continue\n",
        "        \n",
        "        # MỤC\n",
        "        m_sec = SECTION_RE.match(line)\n",
        "        if m_sec:\n",
        "            close_clause()\n",
        "            if article_no is not None:\n",
        "                close_article_if_needed()\n",
        "            article_no = None\n",
        "            article_title = \"\"\n",
        "            article_intro_buf = \"\"\n",
        "            expecting_article_title = False\n",
        "            \n",
        "            sec_no = m_sec.group(1).strip()\n",
        "            sec_title = (m_sec.group(2) or \"\").strip()\n",
        "            section_label = f\"Mục {sec_no}\" + (f\" – {sec_title}\" if sec_title else \"\")\n",
        "            continue\n",
        "        \n",
        "        # ĐIỀU (with strict sequence validation)\n",
        "        m_art = ARTICLE_RE.match(line)\n",
        "        if m_art:\n",
        "            a_no = int(m_art.group(1))\n",
        "            a_title = (m_art.group(2) or \"\").strip()\n",
        "            \n",
        "            if expected_article is None:\n",
        "                expected_article = a_no + 1\n",
        "                close_clause()\n",
        "                if article_no is not None: close_article_if_needed()\n",
        "                article_no = a_no; article_title = a_title; stats[\"articles\"] += 1\n",
        "                if not article_title: expecting_article_title = True\n",
        "                clause_no = None; clause_buf = \"\"; in_points = False; point_letter = None; point_buf = \"\"\n",
        "                clause_intro_current = None\n",
        "                continue\n",
        "            else:\n",
        "                if a_no == expected_article:\n",
        "                    expected_article = a_no + 1\n",
        "                    close_clause()\n",
        "                    if article_no is not None: close_article_if_needed()\n",
        "                    article_no = a_no; article_title = a_title; stats[\"articles\"] += 1\n",
        "                    if not article_title: expecting_article_title = True\n",
        "                    clause_no = None; clause_buf = \"\"; in_points = False; point_letter = None; point_buf = \"\"\n",
        "                    clause_intro_current = None\n",
        "                    continue\n",
        "                elif a_no > expected_article:\n",
        "                    if expected_article not in articles_set:\n",
        "                        warnings.append(f\"Missing Article {expected_article} - stopping at Article {a_no}\")\n",
        "                        break\n",
        "                    else:\n",
        "                        warnings.append(f\"Skipping Article {a_no} - waiting for Article {expected_article}\")\n",
        "                        seeking_article = True\n",
        "                        continue\n",
        "                else:\n",
        "                    warnings.append(f\"Skipping Article {a_no} - backward article number\")\n",
        "                    continue\n",
        "        \n",
        "        # Skip if not in any article\n",
        "        if article_no is None:\n",
        "            continue\n",
        "        \n",
        "        # KHOẢN — PHẢI \"1.\" (số + dấu chấm) - STRICT!\n",
        "        m_k = CLAUSE_RE.match(line)\n",
        "        if m_k and m_k.group(1).isdigit():\n",
        "            if article_intro_buf.strip():\n",
        "                flush_article_intro(chunks, article_no, article_title, article_intro_buf,\n",
        "                                    chapter_label, section_label, stats)\n",
        "                article_intro_buf = \"\"; article_has_any_chunk = True\n",
        "            close_clause()\n",
        "            clause_no = int(m_k.group(1))\n",
        "            clause_buf = (m_k.group(2) or \"\").strip()\n",
        "            in_points = False; point_letter = None; point_buf = \"\"\n",
        "            clause_intro_current = None\n",
        "            continue\n",
        "        \n",
        "        # ĐIỂM — 🔥 chỉ bắt đầu chuỗi điểm nếu mở đầu là a) (KEY LOGIC!)\n",
        "        m_p = POINT_RE.match(line)\n",
        "        if m_p and clause_no is not None:\n",
        "            letter = m_p.group(1).lower()\n",
        "            text = (m_p.group(2) or \"\").strip()\n",
        "            \n",
        "            if not in_points:\n",
        "                if letter != 'a':\n",
        "                    # 🔥 không coi là điểm -> gộp vào nội dung khoản (KEY LOGIC!)\n",
        "                    clause_buf += (\"\\\\n\" if clause_buf else \"\") + f\"{letter}) {text}\"\n",
        "                    continue\n",
        "                # 🔥 bắt đầu chuỗi điểm với 'a)' — KHÔNG flush chunk \"Khoản X\"\n",
        "                # lưu intro khoản để tiêm vào MỌI điểm (KEY FEATURE!)\n",
        "                clause_intro_current = clause_buf.strip() if clause_buf.strip() else None\n",
        "                clause_buf = \"\"\n",
        "                in_points = True\n",
        "                point_letter = letter\n",
        "                point_buf = text\n",
        "                continue\n",
        "            \n",
        "            # đang trong chuỗi điểm: flush điểm trước, mở điểm mới\n",
        "            if point_letter:\n",
        "                flush_point(chunks, article_no, article_title, clause_no, point_letter,\n",
        "                            point_buf, chapter_label, section_label, stats, clause_intro_current)\n",
        "            in_points = True\n",
        "            point_letter = letter\n",
        "            point_buf = text\n",
        "            continue\n",
        "        \n",
        "        # Nội dung kéo dài\n",
        "        if clause_no is not None:\n",
        "            if in_points and point_letter:\n",
        "                point_buf += (\"\\\\n\" if point_buf else \"\") + line\n",
        "            else:\n",
        "                clause_buf += (\"\\\\n\" if clause_buf else \"\") + line\n",
        "        else:\n",
        "            # intro điều (chỉ tồn tại trước khi có khoản đầu tiên)\n",
        "            article_intro_buf += (\"\\\\n\" if article_intro_buf else \"\") + line\n",
        "    \n",
        "    # Kết thúc file\n",
        "    close_clause()\n",
        "    if article_no is not None:\n",
        "        close_article_if_needed()\n",
        "    \n",
        "    # Filter valid chunks\n",
        "    final_chunks = []\n",
        "    for chunk in chunks:\n",
        "        content = chunk['content'].strip()\n",
        "        if len(content) > 50:  # Chỉ lấy chunks đủ dài\n",
        "            final_chunks.append(chunk)\n",
        "    \n",
        "    print(f\"   📊 PROPER advanced parsing results:\")\n",
        "    print(f\"      - Processed {stats['articles']} articles (strict sequence)\")\n",
        "    print(f\"      - Created {stats['article_intro']} article intros\") \n",
        "    print(f\"      - Created {stats['clauses']} clauses\")\n",
        "    print(f\"      - Created {stats['points']} points (with clause intro injection)\")\n",
        "    print(f\"      - Final valid chunks: {len(final_chunks)}\")\n",
        "    \n",
        "    if warnings:\n",
        "        print(f\"   ⚠️  Warnings: {len(warnings)} issues detected\")\n",
        "        for w in warnings[:3]:  # Show first 3 warnings\n",
        "            print(f\"      - {w}\")\n",
        "    \n",
        "    return final_chunks\n",
        "\n",
        "print(\"✅ PROPER Advanced law document chunking ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📚 Loading law document from LuatHonNhan folder...\n",
            "✅ Found law file: LuatHonNhan/luat_hon_nhan_va_gia_dinh.docx\n",
            "\n",
            "📖 Step 1: Reading DOCX file...\n",
            "   Reading file: LuatHonNhan/luat_hon_nhan_va_gia_dinh.docx\n",
            "   ✅ Successfully read 86,564 characters\n",
            "\n",
            "🔨 Step 2: PROPER Advanced chunking with 2-pass validation...\n",
            "   🔍 2-Pass advanced parsing with full validation...\n",
            "   ✅ Normalized 608 lines\n",
            "   📄 Processing 608 lines...\n",
            "   🔍 Pass 1: Pre-scanning structure...\n",
            "      - Pre-scan found 9 chapters: [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "      - Pre-scan found 133 articles: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]...\n",
            "   🔍 Pass 2: Strict parsing with sequence validation...\n",
            "   📊 PROPER advanced parsing results:\n",
            "      - Processed 133 articles (strict sequence)\n",
            "      - Created 44 article intros\n",
            "      - Created 274 clauses\n",
            "      - Created 80 points (with clause intro injection)\n",
            "      - Final valid chunks: 396\n",
            "\n",
            "🗂️ Step 3: Preparing data for evaluation...\n",
            "   ✅ Processed 396 law document chunks\n",
            "   📊 Average chunk length: 226 characters\n",
            "\n",
            "📈 Step 4: Chunk distribution analysis...\n",
            "   📊 Chunk distribution by type:\n",
            "      - article_intro: 44 chunks\n",
            "      - clause: 272 chunks\n",
            "      - point: 80 chunks\n",
            "\n",
            "🔍 Step 5: Sample chunks preview...\n",
            "\n",
            "   📄 Chunk 1: Điều 1 - Phạm vi điều chỉnh\n",
            "      Type: article_intro | Length: 248 chars\n",
            "      Content preview: Điều 1. Phạm vi điều chỉnh\n",
            "Luật này quy định chế độ hôn nhân và gia đình; chuẩn mực pháp lý cho cách ứng xử giữa các thành viên gia đình; trách nhiệm ...\n",
            "      Metadata: {'chapter': 'Chương I', 'section': None, 'article_no': 1, 'article_title': 'Phạm vi điều chỉnh', 'exact_citation': 'Điều 1'}\n",
            "\n",
            "   📄 Chunk 2: Điều 2, Khoản 1\n",
            "      Type: clause | Length: 75 chars\n",
            "      Content preview: Khoản 1. Hôn nhân tự nguyện, tiến bộ, một vợ một chồng, vợ chồng bình đẳng....\n",
            "      Metadata: {'chapter': 'Chương I', 'section': None, 'article_no': 2, 'article_title': 'Những nguyên tắc cơ bản của chế độ hôn nhân và gia đình', 'clause_no': 1, 'exact_citation': 'Điều 2 khoản 1'}\n",
            "\n",
            "   📄 Chunk 3: Điều 2, Khoản 2\n",
            "      Type: clause | Length: 266 chars\n",
            "      Content preview: Khoản 2. Hôn nhân giữa công dân Việt Nam thuộc các dân tộc, tôn giáo, giữa người theo tôn giáo với người không theo tôn giáo, giữa người có tín ngưỡng...\n",
            "      Metadata: {'chapter': 'Chương I', 'section': None, 'article_no': 2, 'article_title': 'Những nguyên tắc cơ bản của chế độ hôn nhân và gia đình', 'clause_no': 2, 'exact_citation': 'Điều 2 khoản 2'}\n",
            "\n",
            "✅ Successfully loaded 396 law document chunks!\n",
            "🎯 Dataset ready for embedding evaluation (Target: 200-300 chunks)\n"
          ]
        }
      ],
      "source": [
        "# ===== LOAD LAW DOCUMENT DATA =====\n",
        "print(\"📚 Loading law document from LuatHonNhan folder...\")\n",
        "\n",
        "law_file_path = \"LuatHonNhan/luat_hon_nhan_va_gia_dinh.docx\"\n",
        "if os.path.exists(law_file_path):\n",
        "    print(f\"✅ Found law file: {law_file_path}\")\n",
        "    \n",
        "    # Bước 1: Đọc file docx\n",
        "    print(\"\\n📖 Step 1: Reading DOCX file...\")\n",
        "    law_text = read_docx(law_file_path)\n",
        "    \n",
        "    # Bước 2: Chia thành chunks với thuật toán PROPER ADVANCED \n",
        "    print(\"\\n🔨 Step 2: PROPER Advanced chunking with 2-pass validation...\")\n",
        "    law_chunks = advanced_chunk_law_document(law_text, max_length=600)\n",
        "    \n",
        "    # Bước 3: Chuẩn bị dữ liệu cho đánh giá\n",
        "    print(\"\\n🗂️ Step 3: Preparing data for evaluation...\")\n",
        "    law_docs = []\n",
        "    for i, chunk in enumerate(law_chunks):\n",
        "        law_docs.append({\n",
        "            'id': i,\n",
        "            'title': chunk['title'],\n",
        "            'text': chunk['content'],\n",
        "            'length': len(chunk['content']),\n",
        "            'type': chunk['type'],\n",
        "            'metadata': chunk.get('metadata', {})\n",
        "        })\n",
        "    \n",
        "    print(f\"   ✅ Processed {len(law_docs)} law document chunks\")\n",
        "    print(f\"   📊 Average chunk length: {np.mean([doc['length'] for doc in law_docs]):.0f} characters\")\n",
        "    \n",
        "    # Bước 4: Thống kê theo loại\n",
        "    print(f\"\\n📈 Step 4: Chunk distribution analysis...\")\n",
        "    type_counts = {}\n",
        "    for doc in law_docs:\n",
        "        doc_type = doc['type']\n",
        "        type_counts[doc_type] = type_counts.get(doc_type, 0) + 1\n",
        "    \n",
        "    print(f\"   📊 Chunk distribution by type:\")\n",
        "    for chunk_type, count in type_counts.items():\n",
        "        print(f\"      - {chunk_type}: {count} chunks\")\n",
        "    \n",
        "    # Bước 5: Hiển thị examples\n",
        "    print(f\"\\n🔍 Step 5: Sample chunks preview...\")\n",
        "    for i in range(min(3, len(law_docs))):\n",
        "        doc = law_docs[i]\n",
        "        print(f\"\\n   📄 Chunk {i+1}: {doc['title']}\")\n",
        "        print(f\"      Type: {doc['type']} | Length: {doc['length']} chars\")\n",
        "        print(f\"      Content preview: {doc['text'][:150]}...\")\n",
        "        if doc.get('metadata'):\n",
        "            print(f\"      Metadata: {doc['metadata']}\")\n",
        "    \n",
        "    print(f\"\\n✅ Successfully loaded {len(law_docs)} law document chunks!\")\n",
        "    print(f\"🎯 Dataset ready for embedding evaluation (Target: 200-300 chunks)\")\n",
        "        \n",
        "else:\n",
        "    print(f\"❌ File {law_file_path} not found!\")\n",
        "    print(\"   Please make sure the LuatHonNhan folder is in the correct location\")\n",
        "    print(f\"   Expected path: {os.path.abspath(law_file_path)}\")\n",
        "    law_docs = []\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Chuẩn bị các query từ benchmark\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🤖 Setting up models for evaluation...\n",
            "✅ Prepared 6 models for evaluation:\n",
            "   1. minhquan6203/paraphrase-vietnamese-law\n",
            "      Type: transformers | Max Length: 512 tokens\n",
            "      Description: Mô hình Sentence Similarity đã fine tune trên bộ luật pháp Việt Nam\n",
            "\n",
            "   2. sentence-transformers/paraphrase-multilingual-mpnet-base-v2\n",
            "      Type: sentence_transformers | Max Length: 512 tokens\n",
            "      Description: Mô hình cơ sở đa ngôn ngữ (base model)\n",
            "\n",
            "   3. huyhuy123/paraphrase-vietnamese-law-ALQAC\n",
            "      Type: transformers | Max Length: 512 tokens\n",
            "      Description: Fine-tuned trực tiếp trên mô hình paraphrase-vietnamese-law\n",
            "\n",
            "   4. namnguyenba2003/Vietnamese_Law_Embedding_finetuned_v3_256dims\n",
            "      Type: transformers | Max Length: 512 tokens\n",
            "      Description: Mô hình embedding luật Việt Nam với 256 dimensions\n",
            "\n",
            "   5. maiduchuy321/vietnamese-bi-encoder-fine-tuning-for-law-chatbot\n",
            "      Type: transformers | Max Length: 512 tokens\n",
            "      Description: Bi-encoder cho chatbot luật Việt Nam\n",
            "\n",
            "   6. BAAI/bge-m3\n",
            "      Type: sentence_transformers | Max Length: 8192 tokens\n",
            "      Description: BGE-M3 - mô hình multilingual embedding hiện đại\n",
            "\n",
            "🎯 All models support ≥512 tokens as required!\n",
            "💾 Embeddings will be stored in RAM (not vector database)\n"
          ]
        }
      ],
      "source": [
        "# ===== MODELS TO EVALUATE =====\n",
        "print(\"🤖 Setting up models for evaluation...\")\n",
        "\n",
        "models_to_evaluate = [\n",
        "    {\n",
        "        'name': 'minhquan6203/paraphrase-vietnamese-law',\n",
        "        'type': 'transformers',  \n",
        "        'description': 'Mô hình Sentence Similarity đã fine tune trên bộ luật pháp Việt Nam',\n",
        "        'max_length': 512\n",
        "    },\n",
        "    {\n",
        "        'name': 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2',\n",
        "        'type': 'sentence_transformers',\n",
        "        'description': 'Mô hình cơ sở đa ngôn ngữ (base model)',\n",
        "        'max_length': 512\n",
        "    },\n",
        "    {\n",
        "        'name': 'huyhuy123/paraphrase-vietnamese-law-ALQAC',\n",
        "        'type': 'transformers',\n",
        "        'description': 'Fine-tuned trực tiếp trên mô hình paraphrase-vietnamese-law',\n",
        "        'max_length': 512\n",
        "    },\n",
        "    {\n",
        "        'name': 'namnguyenba2003/Vietnamese_Law_Embedding_finetuned_v3_256dims',\n",
        "        'type': 'transformers',\n",
        "        'description': 'Mô hình embedding luật Việt Nam với 256 dimensions',\n",
        "        'max_length': 512\n",
        "    },\n",
        "    {\n",
        "        'name': 'maiduchuy321/vietnamese-bi-encoder-fine-tuning-for-law-chatbot',\n",
        "        'type': 'transformers',\n",
        "        'description': 'Bi-encoder cho chatbot luật Việt Nam',\n",
        "        'max_length': 512\n",
        "    },\n",
        "    {\n",
        "        'name': 'BAAI/bge-m3',\n",
        "        'type': 'sentence_transformers',\n",
        "        'description': 'BGE-M3 - mô hình multilingual embedding hiện đại',\n",
        "        'max_length': 8192\n",
        "    }\n",
        "]\n",
        "\n",
        "print(f\"✅ Prepared {len(models_to_evaluate)} models for evaluation:\")\n",
        "for i, model in enumerate(models_to_evaluate):\n",
        "    print(f\"   {i+1}. {model['name']}\")\n",
        "    print(f\"      Type: {model['type']} | Max Length: {model['max_length']} tokens\")\n",
        "    print(f\"      Description: {model['description']}\")\n",
        "    print()\n",
        "\n",
        "print(\"🎯 All models support ≥512 tokens as required!\")\n",
        "print(\"💾 Embeddings will be stored in RAM (not vector database)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prepared 20 benchmark queries\n",
            "Sample queries:\n",
            "1. Người bị bệnh tâm thần là người mất năng lực hành vi dân sự là đúng hay sai?\n",
            "2. Sự thỏa thuận của các bên không vi phạm điều cấm của pháp luật, không trái đạo đức xã hội thì được gọi là hợp đồng là đúng hay sai?\n",
            "3. Tiền phúng viếng đám ma cũng thuộc di sản thừa kế của người chết để lại là đúng hay sai?\n",
            "4. Cá nhân được hưởng di sản thừa kế phải trả nợ thay cho người để lại di sản là đúng hay sai?\n",
            "5. Hợp đồng vô hiệu là hợp đồng vi phạm pháp luật là đúng hay sai?\n"
          ]
        }
      ],
      "source": [
        "# Các query từ benchmark\n",
        "benchmark_queries = [\n",
        "    \"Người bị bệnh tâm thần là người mất năng lực hành vi dân sự là đúng hay sai?\",\n",
        "    \"Sự thỏa thuận của các bên không vi phạm điều cấm của pháp luật, không trái đạo đức xã hội thì được gọi là hợp đồng là đúng hay sai?\",\n",
        "    \"Tiền phúng viếng đám ma cũng thuộc di sản thừa kế của người chết để lại là đúng hay sai?\",\n",
        "    \"Cá nhân được hưởng di sản thừa kế phải trả nợ thay cho người để lại di sản là đúng hay sai?\",\n",
        "    \"Hợp đồng vô hiệu là hợp đồng vi phạm pháp luật là đúng hay sai?\",\n",
        "    \n",
        "    # Các query về Luật Hôn nhân & Gia đình (phù hợp với data LuatHonNhan)\n",
        "    \"Hoa lợi, lợi tức phát sinh từ tài sản riêng của một bên vợ hoặc chồng sẽ là tài sản chung nếu hoa lợi, lợi tức đó là nguồn sống duy nhất của gia đình.\",\n",
        "    \"Hội Liên hiệp phụ nữ có quyền yêu cầu Tòa án ra quyết định hủy kết hôn trái pháp luật do vi phạm sự tự nguyện.\",\n",
        "    \"Hôn nhân chỉ chấm dứt khi một bên vợ, chồng chết.\",\n",
        "    \"Kết hôn có yếu tố nước ngoài có thể đăng ký tại UBND cấp xã.\",\n",
        "    \"Khi cha mẹ không thể nuôi dưỡng, cấp dưỡng được cho con, thì ông bà phải có nghĩa vụ nuôi dưỡng hoặc cấp dưỡng cho cháu.\",\n",
        "    \"Khi hôn nhân chấm dứt, mọi quyền và nghĩa vụ giữa những người đã từng là vợ chồng cũng chấm dứt.\",\n",
        "    \"Khi vợ chồng ly hôn, con dưới 36 tháng tuổi được giao cho người vợ trực tiếp nuôi dưỡng.\",\n",
        "    \"Khi vợ hoặc chồng thực hiện những giao dịch phục vụ cho nhu cầu thiết yếu của gia đình mà không có sự đồng ý của bên kia thì người thực hiện giao dịch đó phải thanh toán bằng tài sản riêng của mình.\",\n",
        "    \"Khi không sống chung cùng với cha mẹ, con đã thành niên có khả năng lao động phải cấp dưỡng cho cha mẹ.\",\n",
        "    \"Chỉ UBND cấp tỉnh nơi công dân Việt Nam cư trú mới có thẩm quyền đăng ký việc kết hôn giữa công dân Việt Nam với người nước ngoài.\",\n",
        "    \n",
        "    # Thêm các query khác để test đa dạng hơn\n",
        "    \"Điều kiện kết hôn của nam và nữ theo pháp luật Việt Nam là gì?\",\n",
        "    \"Tài sản nào được coi là tài sản chung của vợ chồng?\",\n",
        "    \"Thủ tục ly hôn tại tòa án được quy định như thế nào?\",\n",
        "    \"Quyền và nghĩa vụ của cha mẹ đối với con chưa thành niên?\",\n",
        "    \"Trường hợp nào vợ chồng có thể thỏa thuận về chế độ tài sản?\"\n",
        "]\n",
        "\n",
        "print(f\"Prepared {len(benchmark_queries)} benchmark queries\")\n",
        "print(\"Sample queries:\")\n",
        "for i, query in enumerate(benchmark_queries[:5]):\n",
        "    print(f\"{i+1}. {query}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Danh sách các mô hình cần đánh giá (≥512 tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Search và Evaluation Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Setting up search and evaluation functions...\n",
            "✅ Search and evaluation functions ready!\n"
          ]
        }
      ],
      "source": [
        "# ===== SEARCH AND EVALUATION FUNCTIONS =====\n",
        "print(\"🔍 Setting up search and evaluation functions...\")\n",
        "\n",
        "def search_top_k(query_embedding, doc_embeddings, k=15):\n",
        "    \"\"\"\n",
        "    Tìm top-k documents tương tự nhất với query (lưu trên RAM)\n",
        "    \n",
        "    Input:\n",
        "    - query_embedding: vector embedding của query (1D array)\n",
        "    - doc_embeddings: matrix embeddings của documents (2D array)\n",
        "    - k: số lượng top results cần lấy\n",
        "    \n",
        "    Output:\n",
        "    - top_indices: indices của top-k documents\n",
        "    - top_scores: similarity scores của top-k documents\n",
        "    \"\"\"\n",
        "    # Tính cosine similarity giữa query và tất cả documents\n",
        "    similarities = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
        "    \n",
        "    # Sắp xếp theo độ tương tự giảm dần và lấy top-k\n",
        "    top_indices = np.argsort(similarities)[::-1][:k]\n",
        "    top_scores = similarities[top_indices]\n",
        "    \n",
        "    return top_indices, top_scores\n",
        "\n",
        "def calculate_metrics(scores, threshold_07=0.7, threshold_05=0.5):\n",
        "    \"\"\"\n",
        "    Tính toán các metrics đánh giá chất lượng retrieval\n",
        "    \n",
        "    Input:\n",
        "    - scores: array of similarity scores\n",
        "    - threshold_07: ngưỡng cao (0.7)\n",
        "    - threshold_05: ngưỡng thấp (0.5)\n",
        "    \n",
        "    Output:\n",
        "    - dict chứa các metrics\n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"max_score\": float(np.max(scores)),\n",
        "        \"avg_top3\": float(np.mean(scores[:3])) if len(scores) >= 3 else float(np.mean(scores)),\n",
        "        \"avg_top5\": float(np.mean(scores[:5])) if len(scores) >= 5 else float(np.mean(scores)),\n",
        "        \"avg_top10\": float(np.mean(scores[:10])) if len(scores) >= 10 else float(np.mean(scores)),\n",
        "        \"avg_all\": float(np.mean(scores)),\n",
        "        \"scores_above_07\": int(np.sum(scores >= threshold_07)),\n",
        "        \"scores_above_05\": int(np.sum(scores >= threshold_05)),\n",
        "        \"min_score\": float(np.min(scores))\n",
        "    }\n",
        "\n",
        "def display_search_results(query, law_docs, top_indices, top_scores, max_display=5):\n",
        "    \"\"\"\n",
        "    Hiển thị kết quả search một cách rõ ràng\n",
        "    \n",
        "    Input:\n",
        "    - query: câu hỏi query\n",
        "    - law_docs: list of law documents\n",
        "    - top_indices: indices của top results\n",
        "    - top_scores: similarity scores\n",
        "    - max_display: số lượng results tối đa để hiển thị\n",
        "    \"\"\"\n",
        "    print(f\"📝 Query: {query}\")\n",
        "    print(f\"🎯 Top {min(max_display, len(top_indices))} Results:\")\n",
        "    \n",
        "    for i in range(min(max_display, len(top_indices))):\n",
        "        idx = top_indices[i]\n",
        "        score = top_scores[i]\n",
        "        doc = law_docs[idx]\n",
        "        \n",
        "        print(f\"\\n   {i+1}. Score: {score:.4f} | {doc['title']}\")\n",
        "        print(f\"      Type: {doc['type']} | Length: {doc['length']} chars\")\n",
        "        print(f\"      Content: {doc['text'][:200]}...\")\n",
        "        \n",
        "        # Hiển thị metadata nếu có\n",
        "        if doc.get('metadata') and doc['metadata']:\n",
        "            metadata_str = \", \".join([f\"{k}: {v}\" for k, v in doc['metadata'].items()])\n",
        "            print(f\"      Metadata: {metadata_str}\")\n",
        "\n",
        "print(\"✅ Search and evaluation functions ready!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Model Evaluation Engine\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🧪 Setting up model evaluation engine...\n",
            "✅ Model evaluation engine ready!\n"
          ]
        }
      ],
      "source": [
        "# ===== MODEL EVALUATION ENGINE =====\n",
        "print(\"🧪 Setting up model evaluation engine...\")\n",
        "\n",
        "def evaluate_single_model(model_info, law_docs, queries, top_k=15, show_detailed_results=True):\n",
        "    \"\"\"\n",
        "    Đánh giá một mô hình embedding trên dataset luật và benchmark queries\n",
        "    \n",
        "    Input:\n",
        "    - model_info: dict chứa thông tin model (name, type, max_length...)\n",
        "    - law_docs: list of law documents\n",
        "    - queries: list of benchmark queries\n",
        "    - top_k: số lượng top results để đánh giá\n",
        "    - show_detailed_results: có hiển thị kết quả chi tiết không\n",
        "    \n",
        "    Output:\n",
        "    - dict chứa results và metrics của model\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"🔍 EVALUATING MODEL: {model_info['name']}\")\n",
        "    print(f\"📝 Description: {model_info['description']}\")\n",
        "    print(f\"🔧 Type: {model_info['type']} | Max Length: {model_info['max_length']} tokens\")\n",
        "    print(f\"{'='*80}\")\n",
        "    \n",
        "    try:\n",
        "        # Bước 1: Chuẩn bị texts\n",
        "        doc_texts = [doc['text'] for doc in law_docs]\n",
        "        print(f\"\\n📚 Step 1: Prepared {len(doc_texts)} document texts\")\n",
        "        \n",
        "        # Bước 2: Encode documents\n",
        "        print(f\"\\n🔨 Step 2: Encoding documents...\")\n",
        "        if model_info['type'] == 'sentence_transformers':\n",
        "            doc_embeddings = encode_with_sentence_transformers(\n",
        "                doc_texts, \n",
        "                model_info['name'], \n",
        "                batch_size=16\n",
        "            )\n",
        "        else:\n",
        "            doc_embeddings = encode_with_transformers(\n",
        "                doc_texts, \n",
        "                model_info['name'], \n",
        "                max_length=model_info['max_length'],\n",
        "                batch_size=16\n",
        "            )\n",
        "        \n",
        "        print(f\"   ✅ Document embeddings shape: {doc_embeddings.shape}\")\n",
        "        \n",
        "        # Bước 3: Encode queries\n",
        "        print(f\"\\n🔍 Step 3: Encoding queries...\")\n",
        "        if model_info['type'] == 'sentence_transformers':\n",
        "            query_embeddings = encode_with_sentence_transformers(\n",
        "                queries, \n",
        "                model_info['name'], \n",
        "                batch_size=16\n",
        "            )\n",
        "        else:\n",
        "            query_embeddings = encode_with_transformers(\n",
        "                queries, \n",
        "                model_info['name'], \n",
        "                max_length=model_info['max_length'],\n",
        "                batch_size=16\n",
        "            )\n",
        "        \n",
        "        print(f\"   ✅ Query embeddings shape: {query_embeddings.shape}\")\n",
        "        \n",
        "        # Bước 4: Evaluate từng query\n",
        "        print(f\"\\n📊 Step 4: Evaluating {len(queries)} queries...\")\n",
        "        query_results = []\n",
        "        all_metrics = []\n",
        "        \n",
        "        for i, query in enumerate(queries):\n",
        "            print(f\"\\n   🔍 Query {i+1}/{len(queries)}\")\n",
        "            \n",
        "            # Search top-k documents\n",
        "            top_indices, top_scores = search_top_k(\n",
        "                query_embeddings[i], \n",
        "                doc_embeddings, \n",
        "                k=top_k\n",
        "            )\n",
        "            \n",
        "            # Calculate metrics\n",
        "            metrics = calculate_metrics(top_scores)\n",
        "            all_metrics.append(metrics)\n",
        "            \n",
        "            # Store results\n",
        "            query_result = {\n",
        "                'query': query,\n",
        "                'query_id': i,\n",
        "                'top_indices': top_indices.tolist(),\n",
        "                'top_scores': top_scores.tolist(),\n",
        "                'metrics': metrics\n",
        "            }\n",
        "            query_results.append(query_result)\n",
        "            \n",
        "            # Show detailed results for first few queries\n",
        "            if show_detailed_results and i < 3:\n",
        "                display_search_results(query, law_docs, top_indices, top_scores, max_display=3)\n",
        "                print(f\"      📈 Metrics: Max={metrics['max_score']:.4f}, Avg_top5={metrics['avg_top5']:.4f}, Above_0.7={metrics['scores_above_07']}\")\n",
        "        \n",
        "        # Bước 5: Aggregate metrics\n",
        "        print(f\"\\n📈 Step 5: Aggregating metrics...\")\n",
        "        \n",
        "        # Calculate average metrics across all queries\n",
        "        avg_metrics = {}\n",
        "        metric_keys = all_metrics[0].keys()\n",
        "        for key in metric_keys:\n",
        "            if key.startswith('scores_above'):\n",
        "                # For count metrics, sum then average\n",
        "                avg_metrics[f\"avg_{key}\"] = np.mean([m[key] for m in all_metrics])\n",
        "            else:\n",
        "                # For score metrics, just average\n",
        "                avg_metrics[f\"avg_{key}\"] = np.mean([m[key] for m in all_metrics])\n",
        "        \n",
        "        # Final result\n",
        "        final_result = {\n",
        "            'model_name': model_info['name'],\n",
        "            'model_type': model_info['type'],\n",
        "            'model_description': model_info['description'],\n",
        "            'max_length': model_info['max_length'],\n",
        "            'num_queries': len(queries),\n",
        "            'num_documents': len(law_docs),\n",
        "            'top_k': top_k,\n",
        "            'query_results': query_results,\n",
        "            'aggregated_metrics': avg_metrics,\n",
        "            'evaluation_success': True\n",
        "        }\n",
        "        \n",
        "        # Print summary\n",
        "        print(f\"\\n✅ EVALUATION COMPLETED SUCCESSFULLY!\")\n",
        "        print(f\"   📊 Average Results:\")\n",
        "        print(f\"      - Avg Max Score: {avg_metrics['avg_max_score']:.4f}\")\n",
        "        print(f\"      - Avg Top-5 Score: {avg_metrics['avg_avg_top5']:.4f}\")\n",
        "        print(f\"      - Avg Above 0.7: {avg_metrics['avg_scores_above_07']:.1f}\")\n",
        "        print(f\"      - Avg Above 0.5: {avg_metrics['avg_scores_above_05']:.1f}\")\n",
        "        \n",
        "        return final_result\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ EVALUATION FAILED: {str(e)}\")\n",
        "        return {\n",
        "            'model_name': model_info['name'],\n",
        "            'model_type': model_info['type'],\n",
        "            'error': str(e),\n",
        "            'evaluation_success': False\n",
        "        }\n",
        "\n",
        "print(\"✅ Model evaluation engine ready!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Run Evaluation cho tất cả Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 Starting evaluation for all models...\n",
            "✅ Ready to evaluate with:\n",
            "   📚 Documents: 396 law chunks\n",
            "   ❓ Queries: 20 benchmark questions\n",
            "   🤖 Models: 6 models to test\n",
            "   🎯 Top-K: 15 results per query\n",
            "\n",
            "🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 \n",
            "🤖 EVALUATING MODEL 1/6\n",
            "🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 \n",
            "\n",
            "================================================================================\n",
            "🔍 EVALUATING MODEL: minhquan6203/paraphrase-vietnamese-law\n",
            "📝 Description: Mô hình Sentence Similarity đã fine tune trên bộ luật pháp Việt Nam\n",
            "🔧 Type: transformers | Max Length: 512 tokens\n",
            "================================================================================\n",
            "\n",
            "📚 Step 1: Prepared 396 document texts\n",
            "\n",
            "🔨 Step 2: Encoding documents...\n",
            "Loading model: minhquan6203/paraphrase-vietnamese-law\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Encoding: 100%|██████████| 25/25 [00:02<00:00, 10.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ✅ Generated 396 embeddings, stored in RAM\n",
            "   ✅ Document embeddings shape: (396, 768)\n",
            "\n",
            "🔍 Step 3: Encoding queries...\n",
            "Loading model: minhquan6203/paraphrase-vietnamese-law\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Encoding: 100%|██████████| 2/2 [00:00<00:00, 32.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ✅ Generated 20 embeddings, stored in RAM\n",
            "   ✅ Query embeddings shape: (20, 768)\n",
            "\n",
            "📊 Step 4: Evaluating 20 queries...\n",
            "\n",
            "   🔍 Query 1/20\n",
            "📝 Query: Người bị bệnh tâm thần là người mất năng lực hành vi dân sự là đúng hay sai?\n",
            "🎯 Top 3 Results:\n",
            "\n",
            "   1. Score: 0.3415 | Điều 5, Khoản 2, Điểm h)\n",
            "      Type: point | Length: 59 chars\n",
            "      Content: Khoản 2, điểm h) Cấm các hành vi sau đây:\n",
            "Bạo lực gia đình;...\n",
            "      Metadata: chapter: Chương I, section: None, article_no: 5, article_title: Bảo vệ chế độ hôn nhân và gia đình, clause_no: 2, point_letter: h, exact_citation: Điều 5 khoản 2 điểm h), clause_intro: Cấm các hành vi sau đây:\n",
            "\n",
            "   2. Score: 0.3082 | Điều 74 - Bồi thường thiệt hại do con gây ra\n",
            "      Type: article_intro | Length: 187 chars\n",
            "      Content: Điều 74. Bồi thường thiệt hại do con gây ra\n",
            "Cha mẹ phải bồi thường thiệt hại do con chưa thành niên, con đã thành niên mất năng lực hành vi dân sự gây ra theo quy định của Bộ luật dân sự....\n",
            "      Metadata: chapter: Chương V, section: Mục 1 – QUYỀN VÀ NGHĨA VỤ GIỮA CHA MẸ VÀ CON, article_no: 74, article_title: Bồi thường thiệt hại do con gây ra, exact_citation: Điều 74\n",
            "\n",
            "   3. Score: 0.2932 | Điều 3, Khoản 17\n",
            "      Type: clause | Length: 137 chars\n",
            "      Content: Khoản 17. Những người cùng dòng máu về trực hệ là những người có quan hệ huyết thống, trong đó, người này sinh ra người kia kế tiếp nhau....\n",
            "      Metadata: chapter: Chương I, section: None, article_no: 3, article_title: Giải thích từ ngữ, clause_no: 17, exact_citation: Điều 3 khoản 17\n",
            "      📈 Metrics: Max=0.3415, Avg_top5=0.3018, Above_0.7=0\n",
            "\n",
            "   🔍 Query 2/20\n",
            "📝 Query: Sự thỏa thuận của các bên không vi phạm điều cấm của pháp luật, không trái đạo đức xã hội thì được gọi là hợp đồng là đúng hay sai?\n",
            "🎯 Top 3 Results:\n",
            "\n",
            "   1. Score: 0.7058 | Điều 49, Khoản 2\n",
            "      Type: clause | Length: 146 chars\n",
            "      Content: Khoản 2. Hình thức sửa đổi, bổ sung nội dung của thỏa thuận về chế độ tài sản theo thỏa thuận được áp dụng theo quy định tại Điều 47 của Luật này....\n",
            "      Metadata: chapter: Chương III, section: Mục 3 – CHẾ ĐỘ TÀI SẢN CỦA VỢ CHỒNG, article_no: 49, article_title: Sửa đổi, bổ sung nội dung của thỏa thuận về chế độ tài sản của vợ chồng, clause_no: 2, exact_citation: Điều 49 khoản 2\n",
            "\n",
            "   2. Score: 0.6969 | Điều 12, Khoản 3\n",
            "      Type: clause | Length: 115 chars\n",
            "      Content: Khoản 3. Quan hệ tài sản, nghĩa vụ và hợp đồng giữa các bên được giải quyết theo quy định tại Điều 16 của Luật này....\n",
            "      Metadata: chapter: Chương II, section: None, article_no: 12, article_title: Hậu quả pháp lý của việc hủy kết hôn trái pháp luật, clause_no: 3, exact_citation: Điều 12 khoản 3\n",
            "\n",
            "   3. Score: 0.6722 | Điều 48, Khoản 1, Điểm d)\n",
            "      Type: point | Length: 102 chars\n",
            "      Content: Khoản 1, điểm d) Nội dung cơ bản của thỏa thuận về chế độ tài sản bao gồm:\n",
            "Nội dung khác có liên quan....\n",
            "      Metadata: chapter: Chương III, section: Mục 3 – CHẾ ĐỘ TÀI SẢN CỦA VỢ CHỒNG, article_no: 48, article_title: Nội dung cơ bản của thỏa thuận về chế độ tài sản của vợ chồng, clause_no: 1, point_letter: d, exact_citation: Điều 48 khoản 1 điểm d), clause_intro: Nội dung cơ bản của thỏa thuận về chế độ tài sản bao gồm:\n",
            "      📈 Metrics: Max=0.7058, Avg_top5=0.6613, Above_0.7=1\n",
            "\n",
            "   🔍 Query 3/20\n",
            "📝 Query: Tiền phúng viếng đám ma cũng thuộc di sản thừa kế của người chết để lại là đúng hay sai?\n",
            "🎯 Top 3 Results:\n",
            "\n",
            "   1. Score: 0.9016 | Điều 66, Khoản 3\n",
            "      Type: clause | Length: 221 chars\n",
            "      Content: Khoản 3. Trong trường hợp việc chia di sản ảnh hưởng nghiêm trọng đến đời sống của vợ hoặc chồng còn sống, gia đình thì vợ, chồng còn sống có quyền yêu cầu Tòa án hạn chế phân chia di sản theo quy địn...\n",
            "      Metadata: chapter: Chương IV, section: Mục 2 – HÔN NHÂN CHẤM DỨT DO VỢ, CHỒNG CHẾT HOẶC BỊ TÒA ÁN TUYÊN BỐ LÀ ĐÃ CHẾT, article_no: 66, article_title: Giải quyết tài sản của vợ chồng trong trường hợp một bên chết hoặc bị Tòa án tuyên bố là đã chết, clause_no: 3, exact_citation: Điều 66 khoản 3\n",
            "\n",
            "   2. Score: 0.8939 | Điều 66, Khoản 1\n",
            "      Type: clause | Length: 256 chars\n",
            "      Content: Khoản 1. Khi một bên vợ, chồng chết hoặc bị Tòa án tuyên bố là đã chết thì bên còn sống quản lý tài sản chung của vợ chồng, trừ trường hợp trong di chúc có chỉ định người khác quản lý di sản hoặc nhữn...\n",
            "      Metadata: chapter: Chương IV, section: Mục 2 – HÔN NHÂN CHẤM DỨT DO VỢ, CHỒNG CHẾT HOẶC BỊ TÒA ÁN TUYÊN BỐ LÀ ĐÃ CHẾT, article_no: 66, article_title: Giải quyết tài sản của vợ chồng trong trường hợp một bên chết hoặc bị Tòa án tuyên bố là đã chết, clause_no: 1, exact_citation: Điều 66 khoản 1\n",
            "\n",
            "   3. Score: 0.8129 | Điều 66, Khoản 2\n",
            "      Type: clause | Length: 258 chars\n",
            "      Content: Khoản 2. Khi có yêu cầu về chia di sản thì tài sản chung của vợ chồng được chia đôi, trừ trường hợp vợ chồng có thỏa thuận về chế độ tài sản. Phần tài sản của vợ, chồng chết hoặc bị Tòa án tuyên bố là...\n",
            "      Metadata: chapter: Chương IV, section: Mục 2 – HÔN NHÂN CHẤM DỨT DO VỢ, CHỒNG CHẾT HOẶC BỊ TÒA ÁN TUYÊN BỐ LÀ ĐÃ CHẾT, article_no: 66, article_title: Giải quyết tài sản của vợ chồng trong trường hợp một bên chết hoặc bị Tòa án tuyên bố là đã chết, clause_no: 2, exact_citation: Điều 66 khoản 2\n",
            "      📈 Metrics: Max=0.9016, Avg_top5=0.8197, Above_0.7=4\n",
            "\n",
            "   🔍 Query 4/20\n",
            "\n",
            "   🔍 Query 5/20\n",
            "\n",
            "   🔍 Query 6/20\n",
            "\n",
            "   🔍 Query 7/20\n",
            "\n",
            "   🔍 Query 8/20\n",
            "\n",
            "   🔍 Query 9/20\n",
            "\n",
            "   🔍 Query 10/20\n",
            "\n",
            "   🔍 Query 11/20\n",
            "\n",
            "   🔍 Query 12/20\n",
            "\n",
            "   🔍 Query 13/20\n",
            "\n",
            "   🔍 Query 14/20\n",
            "\n",
            "   🔍 Query 15/20\n",
            "\n",
            "   🔍 Query 16/20\n",
            "\n",
            "   🔍 Query 17/20\n",
            "\n",
            "   🔍 Query 18/20\n",
            "\n",
            "   🔍 Query 19/20\n",
            "\n",
            "   🔍 Query 20/20\n",
            "\n",
            "📈 Step 5: Aggregating metrics...\n",
            "\n",
            "✅ EVALUATION COMPLETED SUCCESSFULLY!\n",
            "   📊 Average Results:\n",
            "      - Avg Max Score: 0.9034\n",
            "      - Avg Top-5 Score: 0.8780\n",
            "      - Avg Above 0.7: 11.4\n",
            "      - Avg Above 0.5: 12.8\n",
            "✅ Model 1 evaluation completed successfully!\n",
            "⏳ Waiting 2 seconds before next model...\n",
            "\n",
            "🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 \n",
            "🤖 EVALUATING MODEL 2/6\n",
            "🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 \n",
            "\n",
            "================================================================================\n",
            "🔍 EVALUATING MODEL: sentence-transformers/paraphrase-multilingual-mpnet-base-v2\n",
            "📝 Description: Mô hình cơ sở đa ngôn ngữ (base model)\n",
            "🔧 Type: sentence_transformers | Max Length: 512 tokens\n",
            "================================================================================\n",
            "\n",
            "📚 Step 1: Prepared 396 document texts\n",
            "\n",
            "🔨 Step 2: Encoding documents...\n",
            "Loading model: sentence-transformers/paraphrase-multilingual-mpnet-base-v2\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "162e6c3c8d784b3498431a03d672e288",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ✅ Generated 396 embeddings, stored in RAM\n",
            "   ✅ Document embeddings shape: (396, 768)\n",
            "\n",
            "🔍 Step 3: Encoding queries...\n",
            "Loading model: sentence-transformers/paraphrase-multilingual-mpnet-base-v2\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99ec758f4148480193b41b3817cfd4e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ✅ Generated 20 embeddings, stored in RAM\n",
            "   ✅ Query embeddings shape: (20, 768)\n",
            "\n",
            "📊 Step 4: Evaluating 20 queries...\n",
            "\n",
            "   🔍 Query 1/20\n",
            "📝 Query: Người bị bệnh tâm thần là người mất năng lực hành vi dân sự là đúng hay sai?\n",
            "🎯 Top 3 Results:\n",
            "\n",
            "   1. Score: 0.5186 | Điều 69, Khoản 3\n",
            "      Type: clause | Length: 135 chars\n",
            "      Content: Khoản 3. Giám hộ hoặc đại diện theo quy định của Bộ luật dân sự cho con chưa thành niên, con đã thành niên mất năng lực hành vi dân sự....\n",
            "      Metadata: chapter: Chương V, section: Mục 1 – QUYỀN VÀ NGHĨA VỤ GIỮA CHA MẸ VÀ CON, article_no: 69, article_title: Nghĩa vụ và quyền của cha mẹ, clause_no: 3, exact_citation: Điều 69 khoản 3\n",
            "\n",
            "   2. Score: 0.5023 | Điều 51, Khoản 2\n",
            "      Type: clause | Length: 337 chars\n",
            "      Content: Khoản 2. Cha, mẹ, người thân thích khác có quyền yêu cầu Tòa án giải quyết ly hôn khi một bên vợ, chồng do bị bệnh tâm thần hoặc mắc bệnh khác mà không thể nhận thức, làm chủ được hành vi của mình, đồ...\n",
            "      Metadata: chapter: Chương IV, section: Mục 1 – LY HÔN, article_no: 51, article_title: Quyền yêu cầu giải quyết ly hôn, clause_no: 2, exact_citation: Điều 51 khoản 2\n",
            "\n",
            "   3. Score: 0.4844 | Điều 77, Khoản 3\n",
            "      Type: clause | Length: 140 chars\n",
            "      Content: Khoản 3. Trong trường hợp con đã thành niên mất năng lực hành vi dân sự thì việc định đoạt tài sản riêng của con do người giám hộ thực hiện....\n",
            "      Metadata: chapter: Chương V, section: Mục 1 – QUYỀN VÀ NGHĨA VỤ GIỮA CHA MẸ VÀ CON, article_no: 77, article_title: Định đoạt tài sản riêng của con chưa thành niên, con đã thành niên mất năng lực hành vi dân sự, clause_no: 3, exact_citation: Điều 77 khoản 3\n",
            "      📈 Metrics: Max=0.5186, Avg_top5=0.4899, Above_0.7=0\n",
            "\n",
            "   🔍 Query 2/20\n",
            "📝 Query: Sự thỏa thuận của các bên không vi phạm điều cấm của pháp luật, không trái đạo đức xã hội thì được gọi là hợp đồng là đúng hay sai?\n",
            "🎯 Top 3 Results:\n",
            "\n",
            "   1. Score: 0.6735 | Điều 16, Khoản 1\n",
            "      Type: clause | Length: 296 chars\n",
            "      Content: Khoản 1. Quan hệ tài sản, nghĩa vụ và hợp đồng của nam, nữ chung sống với nhau như vợ chồng mà không đăng ký kết hôn được giải quyết theo thỏa thuận giữa các bên; trong trường hợp không có thỏa thuận ...\n",
            "      Metadata: chapter: Chương II, section: None, article_no: 16, article_title: Giải quyết quan hệ tài sản, nghĩa vụ và hợp đồng của nam, nữ chung sống với nhau như vợ chồng mà không đăng ký kết hôn, clause_no: 1, exact_citation: Điều 16 khoản 1\n",
            "\n",
            "   2. Score: 0.6356 | Điều 37, Khoản 1\n",
            "      Type: clause | Length: 175 chars\n",
            "      Content: Khoản 1. Nghĩa vụ phát sinh từ giao dịch do vợ chồng cùng thỏa thuận xác lập, nghĩa vụ bồi thường thiệt hại mà theo quy định của pháp luật vợ chồng cùng phải chịu trách nhiệm;...\n",
            "      Metadata: chapter: Chương III, section: Mục 3 – CHẾ ĐỘ TÀI SẢN CỦA VỢ CHỒNG, article_no: 37, article_title: Nghĩa vụ chung về tài sản của vợ chồng, clause_no: 1, exact_citation: Điều 37 khoản 1\n",
            "\n",
            "   3. Score: 0.6211 | Điều 50, Khoản 1, Điểm a)\n",
            "      Type: point | Length: 244 chars\n",
            "      Content: Khoản 1, điểm a) Thỏa thuận về chế độ tài sản của vợ chồng bị Tòa án tuyên bố vô hiệu khi thuộc một trong các trường hợp sau đây:\n",
            "Không tuân thủ điều kiện có hiệu lực của giao dịch được quy định tại B...\n",
            "      Metadata: chapter: Chương III, section: Mục 3 – CHẾ ĐỘ TÀI SẢN CỦA VỢ CHỒNG, article_no: 50, article_title: Thỏa thuận về chế độ tài sản của vợ chồng bị vô hiệu, clause_no: 1, point_letter: a, exact_citation: Điều 50 khoản 1 điểm a), clause_intro: Thỏa thuận về chế độ tài sản của vợ chồng bị Tòa án tuyên bố vô hiệu khi thuộc một trong các trường hợp sau đây:\n",
            "      📈 Metrics: Max=0.6735, Avg_top5=0.6327, Above_0.7=0\n",
            "\n",
            "   🔍 Query 3/20\n",
            "📝 Query: Tiền phúng viếng đám ma cũng thuộc di sản thừa kế của người chết để lại là đúng hay sai?\n",
            "🎯 Top 3 Results:\n",
            "\n",
            "   1. Score: 0.6119 | Điều 66, Khoản 1\n",
            "      Type: clause | Length: 256 chars\n",
            "      Content: Khoản 1. Khi một bên vợ, chồng chết hoặc bị Tòa án tuyên bố là đã chết thì bên còn sống quản lý tài sản chung của vợ chồng, trừ trường hợp trong di chúc có chỉ định người khác quản lý di sản hoặc nhữn...\n",
            "      Metadata: chapter: Chương IV, section: Mục 2 – HÔN NHÂN CHẤM DỨT DO VỢ, CHỒNG CHẾT HOẶC BỊ TÒA ÁN TUYÊN BỐ LÀ ĐÃ CHẾT, article_no: 66, article_title: Giải quyết tài sản của vợ chồng trong trường hợp một bên chết hoặc bị Tòa án tuyên bố là đã chết, clause_no: 1, exact_citation: Điều 66 khoản 1\n",
            "\n",
            "   2. Score: 0.5780 | Điều 118, Khoản 4\n",
            "      Type: clause | Length: 56 chars\n",
            "      Content: Khoản 4. Người cấp dưỡng hoặc người được cấp dưỡng chết;...\n",
            "      Metadata: chapter: Chương VII, section: None, article_no: 118, article_title: Chấm dứt nghĩa vụ cấp dưỡng, clause_no: 4, exact_citation: Điều 118 khoản 4\n",
            "\n",
            "   3. Score: 0.5650 | Điều 67, Khoản 2, Điểm b)\n",
            "      Type: point | Length: 328 chars\n",
            "      Content: Khoản 2, điểm b) Quan hệ tài sản của người bị tuyên bố là đã chết trở về với người vợ hoặc chồng được giải quyết như sau:\n",
            "Trong trường hợp hôn nhân không được khôi phục thì tài sản có được trước khi q...\n",
            "      Metadata: chapter: Chương IV, section: Mục 2 – HÔN NHÂN CHẤM DỨT DO VỢ, CHỒNG CHẾT HOẶC BỊ TÒA ÁN TUYÊN BỐ LÀ ĐÃ CHẾT, article_no: 67, article_title: Quan hệ nhân thân, tài sản khi vợ, chồng bị tuyên bố là đã chết mà trở về, clause_no: 2, point_letter: b, exact_citation: Điều 67 khoản 2 điểm b), clause_intro: Quan hệ tài sản của người bị tuyên bố là đã chết trở về với người vợ hoặc chồng được giải quyết như sau:\n",
            "      📈 Metrics: Max=0.6119, Avg_top5=0.5722, Above_0.7=0\n",
            "\n",
            "   🔍 Query 4/20\n",
            "\n",
            "   🔍 Query 5/20\n",
            "\n",
            "   🔍 Query 6/20\n",
            "\n",
            "   🔍 Query 7/20\n",
            "\n",
            "   🔍 Query 8/20\n",
            "\n",
            "   🔍 Query 9/20\n",
            "\n",
            "   🔍 Query 10/20\n",
            "\n",
            "   🔍 Query 11/20\n",
            "\n",
            "   🔍 Query 12/20\n",
            "\n",
            "   🔍 Query 13/20\n",
            "\n",
            "   🔍 Query 14/20\n",
            "\n",
            "   🔍 Query 15/20\n",
            "\n",
            "   🔍 Query 16/20\n",
            "\n",
            "   🔍 Query 17/20\n",
            "\n",
            "   🔍 Query 18/20\n",
            "\n",
            "   🔍 Query 19/20\n",
            "\n",
            "   🔍 Query 20/20\n",
            "\n",
            "📈 Step 5: Aggregating metrics...\n",
            "\n",
            "✅ EVALUATION COMPLETED SUCCESSFULLY!\n",
            "   📊 Average Results:\n",
            "      - Avg Max Score: 0.7647\n",
            "      - Avg Top-5 Score: 0.7310\n",
            "      - Avg Above 0.7: 8.0\n",
            "      - Avg Above 0.5: 14.1\n",
            "✅ Model 2 evaluation completed successfully!\n",
            "⏳ Waiting 2 seconds before next model...\n",
            "\n",
            "🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 \n",
            "🤖 EVALUATING MODEL 3/6\n",
            "🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 \n",
            "\n",
            "================================================================================\n",
            "🔍 EVALUATING MODEL: huyhuy123/paraphrase-vietnamese-law-ALQAC\n",
            "📝 Description: Fine-tuned trực tiếp trên mô hình paraphrase-vietnamese-law\n",
            "🔧 Type: transformers | Max Length: 512 tokens\n",
            "================================================================================\n",
            "\n",
            "📚 Step 1: Prepared 396 document texts\n",
            "\n",
            "🔨 Step 2: Encoding documents...\n",
            "Loading model: huyhuy123/paraphrase-vietnamese-law-ALQAC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Encoding: 100%|██████████| 25/25 [00:02<00:00, 10.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ✅ Generated 396 embeddings, stored in RAM\n",
            "   ✅ Document embeddings shape: (396, 768)\n",
            "\n",
            "🔍 Step 3: Encoding queries...\n",
            "Loading model: huyhuy123/paraphrase-vietnamese-law-ALQAC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Encoding: 100%|██████████| 2/2 [00:00<00:00, 30.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ✅ Generated 20 embeddings, stored in RAM\n",
            "   ✅ Query embeddings shape: (20, 768)\n",
            "\n",
            "📊 Step 4: Evaluating 20 queries...\n",
            "\n",
            "   🔍 Query 1/20\n",
            "\n",
            "   🔍 Query 2/20\n",
            "\n",
            "   🔍 Query 3/20\n",
            "\n",
            "   🔍 Query 4/20\n",
            "\n",
            "   🔍 Query 5/20\n",
            "\n",
            "   🔍 Query 6/20\n",
            "\n",
            "   🔍 Query 7/20\n",
            "\n",
            "   🔍 Query 8/20\n",
            "\n",
            "   🔍 Query 9/20\n",
            "\n",
            "   🔍 Query 10/20\n",
            "\n",
            "   🔍 Query 11/20\n",
            "\n",
            "   🔍 Query 12/20\n",
            "\n",
            "   🔍 Query 13/20\n",
            "\n",
            "   🔍 Query 14/20\n",
            "\n",
            "   🔍 Query 15/20\n",
            "\n",
            "   🔍 Query 16/20\n",
            "\n",
            "   🔍 Query 17/20\n",
            "\n",
            "   🔍 Query 18/20\n",
            "\n",
            "   🔍 Query 19/20\n",
            "\n",
            "   🔍 Query 20/20\n",
            "\n",
            "📈 Step 5: Aggregating metrics...\n",
            "\n",
            "✅ EVALUATION COMPLETED SUCCESSFULLY!\n",
            "   📊 Average Results:\n",
            "      - Avg Max Score: 0.8711\n",
            "      - Avg Top-5 Score: 0.7927\n",
            "      - Avg Above 0.7: 6.6\n",
            "      - Avg Above 0.5: 13.2\n",
            "✅ Model 3 evaluation completed successfully!\n",
            "⏳ Waiting 2 seconds before next model...\n",
            "\n",
            "🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 \n",
            "🤖 EVALUATING MODEL 4/6\n",
            "🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 \n",
            "\n",
            "================================================================================\n",
            "🔍 EVALUATING MODEL: namnguyenba2003/Vietnamese_Law_Embedding_finetuned_v3_256dims\n",
            "📝 Description: Mô hình embedding luật Việt Nam với 256 dimensions\n",
            "🔧 Type: transformers | Max Length: 512 tokens\n",
            "================================================================================\n",
            "\n",
            "📚 Step 1: Prepared 396 document texts\n",
            "\n",
            "🔨 Step 2: Encoding documents...\n",
            "Loading model: namnguyenba2003/Vietnamese_Law_Embedding_finetuned_v3_256dims\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Encoding: 100%|██████████| 25/25 [01:52<00:00,  4.51s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ✅ Generated 396 embeddings, stored in RAM\n",
            "   ✅ Document embeddings shape: (396, 1024)\n",
            "\n",
            "🔍 Step 3: Encoding queries...\n",
            "Loading model: namnguyenba2003/Vietnamese_Law_Embedding_finetuned_v3_256dims\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Encoding: 100%|██████████| 2/2 [00:02<00:00,  1.32s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ✅ Generated 20 embeddings, stored in RAM\n",
            "   ✅ Query embeddings shape: (20, 1024)\n",
            "\n",
            "📊 Step 4: Evaluating 20 queries...\n",
            "\n",
            "   🔍 Query 1/20\n",
            "\n",
            "   🔍 Query 2/20\n",
            "\n",
            "   🔍 Query 3/20\n",
            "\n",
            "   🔍 Query 4/20\n",
            "\n",
            "   🔍 Query 5/20\n",
            "\n",
            "   🔍 Query 6/20\n",
            "\n",
            "   🔍 Query 7/20\n",
            "\n",
            "   🔍 Query 8/20\n",
            "\n",
            "   🔍 Query 9/20\n",
            "\n",
            "   🔍 Query 10/20\n",
            "\n",
            "   🔍 Query 11/20\n",
            "\n",
            "   🔍 Query 12/20\n",
            "\n",
            "   🔍 Query 13/20\n",
            "\n",
            "   🔍 Query 14/20\n",
            "\n",
            "   🔍 Query 15/20\n",
            "\n",
            "   🔍 Query 16/20\n",
            "\n",
            "   🔍 Query 17/20\n",
            "\n",
            "   🔍 Query 18/20\n",
            "\n",
            "   🔍 Query 19/20\n",
            "\n",
            "   🔍 Query 20/20\n",
            "\n",
            "📈 Step 5: Aggregating metrics...\n",
            "\n",
            "✅ EVALUATION COMPLETED SUCCESSFULLY!\n",
            "   📊 Average Results:\n",
            "      - Avg Max Score: 0.8577\n",
            "      - Avg Top-5 Score: 0.8287\n",
            "      - Avg Above 0.7: 12.5\n",
            "      - Avg Above 0.5: 15.0\n",
            "✅ Model 4 evaluation completed successfully!\n",
            "⏳ Waiting 2 seconds before next model...\n",
            "\n",
            "🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 \n",
            "🤖 EVALUATING MODEL 5/6\n",
            "🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 \n",
            "\n",
            "================================================================================\n",
            "🔍 EVALUATING MODEL: maiduchuy321/vietnamese-bi-encoder-fine-tuning-for-law-chatbot\n",
            "📝 Description: Bi-encoder cho chatbot luật Việt Nam\n",
            "🔧 Type: transformers | Max Length: 512 tokens\n",
            "================================================================================\n",
            "\n",
            "📚 Step 1: Prepared 396 document texts\n",
            "\n",
            "🔨 Step 2: Encoding documents...\n",
            "Loading model: maiduchuy321/vietnamese-bi-encoder-fine-tuning-for-law-chatbot\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Encoding: 100%|██████████| 25/25 [00:03<00:00,  7.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ✅ Generated 396 embeddings, stored in RAM\n",
            "   ✅ Document embeddings shape: (396, 768)\n",
            "\n",
            "🔍 Step 3: Encoding queries...\n",
            "Loading model: maiduchuy321/vietnamese-bi-encoder-fine-tuning-for-law-chatbot\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Encoding: 100%|██████████| 2/2 [00:00<00:00, 28.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ✅ Generated 20 embeddings, stored in RAM\n",
            "   ✅ Query embeddings shape: (20, 768)\n",
            "\n",
            "📊 Step 4: Evaluating 20 queries...\n",
            "\n",
            "   🔍 Query 1/20\n",
            "\n",
            "   🔍 Query 2/20\n",
            "\n",
            "   🔍 Query 3/20\n",
            "\n",
            "   🔍 Query 4/20\n",
            "\n",
            "   🔍 Query 5/20\n",
            "\n",
            "   🔍 Query 6/20\n",
            "\n",
            "   🔍 Query 7/20\n",
            "\n",
            "   🔍 Query 8/20\n",
            "\n",
            "   🔍 Query 9/20\n",
            "\n",
            "   🔍 Query 10/20\n",
            "\n",
            "   🔍 Query 11/20\n",
            "\n",
            "   🔍 Query 12/20\n",
            "\n",
            "   🔍 Query 13/20\n",
            "\n",
            "   🔍 Query 14/20\n",
            "\n",
            "   🔍 Query 15/20\n",
            "\n",
            "   🔍 Query 16/20\n",
            "\n",
            "   🔍 Query 17/20\n",
            "\n",
            "   🔍 Query 18/20\n",
            "\n",
            "   🔍 Query 19/20\n",
            "\n",
            "   🔍 Query 20/20\n",
            "\n",
            "📈 Step 5: Aggregating metrics...\n",
            "\n",
            "✅ EVALUATION COMPLETED SUCCESSFULLY!\n",
            "   📊 Average Results:\n",
            "      - Avg Max Score: 0.6379\n",
            "      - Avg Top-5 Score: 0.5981\n",
            "      - Avg Above 0.7: 2.2\n",
            "      - Avg Above 0.5: 10.6\n",
            "✅ Model 5 evaluation completed successfully!\n",
            "⏳ Waiting 2 seconds before next model...\n",
            "\n",
            "🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 \n",
            "🤖 EVALUATING MODEL 6/6\n",
            "🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 🤖 \n",
            "\n",
            "================================================================================\n",
            "🔍 EVALUATING MODEL: BAAI/bge-m3\n",
            "📝 Description: BGE-M3 - mô hình multilingual embedding hiện đại\n",
            "🔧 Type: sentence_transformers | Max Length: 8192 tokens\n",
            "================================================================================\n",
            "\n",
            "📚 Step 1: Prepared 396 document texts\n",
            "\n",
            "🔨 Step 2: Encoding documents...\n",
            "Loading model: BAAI/bge-m3\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "596bca93c109479e9f08b12444d548b7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ✅ Generated 396 embeddings, stored in RAM\n",
            "   ✅ Document embeddings shape: (396, 1024)\n",
            "\n",
            "🔍 Step 3: Encoding queries...\n",
            "Loading model: BAAI/bge-m3\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "505b261994e14b20a815163e601432e9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ✅ Generated 20 embeddings, stored in RAM\n",
            "   ✅ Query embeddings shape: (20, 1024)\n",
            "\n",
            "📊 Step 4: Evaluating 20 queries...\n",
            "\n",
            "   🔍 Query 1/20\n",
            "\n",
            "   🔍 Query 2/20\n",
            "\n",
            "   🔍 Query 3/20\n",
            "\n",
            "   🔍 Query 4/20\n",
            "\n",
            "   🔍 Query 5/20\n",
            "\n",
            "   🔍 Query 6/20\n",
            "\n",
            "   🔍 Query 7/20\n",
            "\n",
            "   🔍 Query 8/20\n",
            "\n",
            "   🔍 Query 9/20\n",
            "\n",
            "   🔍 Query 10/20\n",
            "\n",
            "   🔍 Query 11/20\n",
            "\n",
            "   🔍 Query 12/20\n",
            "\n",
            "   🔍 Query 13/20\n",
            "\n",
            "   🔍 Query 14/20\n",
            "\n",
            "   🔍 Query 15/20\n",
            "\n",
            "   🔍 Query 16/20\n",
            "\n",
            "   🔍 Query 17/20\n",
            "\n",
            "   🔍 Query 18/20\n",
            "\n",
            "   🔍 Query 19/20\n",
            "\n",
            "   🔍 Query 20/20\n",
            "\n",
            "📈 Step 5: Aggregating metrics...\n",
            "\n",
            "✅ EVALUATION COMPLETED SUCCESSFULLY!\n",
            "   📊 Average Results:\n",
            "      - Avg Max Score: 0.7181\n",
            "      - Avg Top-5 Score: 0.6819\n",
            "      - Avg Above 0.7: 4.7\n",
            "      - Avg Above 0.5: 12.9\n",
            "✅ Model 6 evaluation completed successfully!\n",
            "\n",
            "====================================================================================================\n",
            "🎉 EVALUATION SUMMARY\n",
            "====================================================================================================\n",
            "✅ Successful evaluations: 6\n",
            "❌ Failed evaluations: 0\n",
            "📊 Total models evaluated: 6\n",
            "\n",
            "📈 Quick Performance Preview:\n",
            "   🤖 paraphrase-vietnamese-law\n",
            "      Max Score: 0.9034 | Top-5: 0.8780 | Above 0.7: 11.4\n",
            "   🤖 paraphrase-multilingual-mpnet-base-v2\n",
            "      Max Score: 0.7647 | Top-5: 0.7310 | Above 0.7: 8.0\n",
            "   🤖 paraphrase-vietnamese-law-ALQAC\n",
            "      Max Score: 0.8711 | Top-5: 0.7927 | Above 0.7: 6.6\n",
            "   🤖 Vietnamese_Law_Embedding_finetuned_v3_256dims\n",
            "      Max Score: 0.8577 | Top-5: 0.8287 | Above 0.7: 12.5\n",
            "   🤖 vietnamese-bi-encoder-fine-tuning-for-law-chatbot\n",
            "      Max Score: 0.6379 | Top-5: 0.5981 | Above 0.7: 2.2\n",
            "   🤖 bge-m3\n",
            "      Max Score: 0.7181 | Top-5: 0.6819 | Above 0.7: 4.7\n",
            "\n",
            "🎯 Ready for detailed analysis and report generation!\n",
            "📊 Variable 'evaluation_results' contains all results for further analysis.\n"
          ]
        }
      ],
      "source": [
        "# ===== RUN EVALUATION FOR ALL MODELS =====\n",
        "print(\"🚀 Starting evaluation for all models...\")\n",
        "\n",
        "# Check available data\n",
        "if not law_docs:\n",
        "    print(\"❌ Error: No law documents loaded! Please run the data loading cells first.\")\n",
        "    evaluation_results = []\n",
        "else:\n",
        "    print(f\"✅ Ready to evaluate with:\")\n",
        "    print(f\"   📚 Documents: {len(law_docs)} law chunks\")\n",
        "    print(f\"   ❓ Queries: {len(benchmark_queries)} benchmark questions\")\n",
        "    print(f\"   🤖 Models: {len(models_to_evaluate)} models to test\")\n",
        "    print(f\"   🎯 Top-K: 15 results per query\")\n",
        "    \n",
        "    # Storage for results\n",
        "    evaluation_results = []\n",
        "    successful_evaluations = 0\n",
        "    failed_evaluations = 0\n",
        "    \n",
        "    # Evaluate each model\n",
        "    for i, model_info in enumerate(models_to_evaluate):\n",
        "        print(f\"\\n{'🤖 '*20}\")\n",
        "        print(f\"🤖 EVALUATING MODEL {i+1}/{len(models_to_evaluate)}\")\n",
        "        print(f\"{'🤖 '*20}\")\n",
        "        \n",
        "        try:\n",
        "            # Run evaluation\n",
        "            result = evaluate_single_model(\n",
        "                model_info=model_info,\n",
        "                law_docs=law_docs,\n",
        "                queries=benchmark_queries,\n",
        "                top_k=15,\n",
        "                show_detailed_results=(i < 2)  # Show details for first 2 models only\n",
        "            )\n",
        "            \n",
        "            if result['evaluation_success']:\n",
        "                evaluation_results.append(result)\n",
        "                successful_evaluations += 1\n",
        "                print(f\"✅ Model {i+1} evaluation completed successfully!\")\n",
        "            else:\n",
        "                print(f\"❌ Model {i+1} evaluation failed: {result.get('error', 'Unknown error')}\")\n",
        "                failed_evaluations += 1\n",
        "            \n",
        "            # Wait between models to prevent memory issues\n",
        "            if i < len(models_to_evaluate) - 1:\n",
        "                print(f\"⏳ Waiting 2 seconds before next model...\")\n",
        "                time.sleep(2)\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"❌ Unexpected error evaluating model {i+1}: {str(e)}\")\n",
        "            failed_evaluations += 1\n",
        "            continue\n",
        "    \n",
        "    # Final summary\n",
        "    print(f\"\\n{'='*100}\")\n",
        "    print(f\"🎉 EVALUATION SUMMARY\")\n",
        "    print(f\"{'='*100}\")\n",
        "    print(f\"✅ Successful evaluations: {successful_evaluations}\")\n",
        "    print(f\"❌ Failed evaluations: {failed_evaluations}\")\n",
        "    print(f\"📊 Total models evaluated: {len(evaluation_results)}\")\n",
        "    \n",
        "    if evaluation_results:\n",
        "        print(f\"\\n📈 Quick Performance Preview:\")\n",
        "        for result in evaluation_results:\n",
        "            metrics = result['aggregated_metrics']\n",
        "            model_name = result['model_name'].split('/')[-1]  # Get model name without path\n",
        "            print(f\"   🤖 {model_name}\")\n",
        "            print(f\"      Max Score: {metrics['avg_max_score']:.4f} | Top-5: {metrics['avg_avg_top5']:.4f} | Above 0.7: {metrics['avg_scores_above_07']:.1f}\")\n",
        "    \n",
        "    print(f\"\\n🎯 Ready for detailed analysis and report generation!\")\n",
        "    print(f\"📊 Variable 'evaluation_results' contains all results for further analysis.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Analysis và Final Report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 Generating detailed analysis and final report...\n",
            "\n",
            "====================================================================================================\n",
            "📋 COMPREHENSIVE EVALUATION REPORT\n",
            "====================================================================================================\n",
            "📊 DATASET INFORMATION:\n",
            "   📚 Law Documents: 396 chunks from Luật Hôn nhân và Gia đình\n",
            "   ❓ Benchmark Queries: 20 questions\n",
            "   🔍 Evaluation Method: Top-15 retrieval with cosine similarity\n",
            "   💾 Storage: RAM-based (no vector database)\n",
            "\n",
            "🏆 RANKING BY PERFORMANCE:\n",
            "   Metric: Average Max Score across all queries\n",
            "\n",
            "Rank Model                                         Max Score  Top-5    ≥0.7   ≥0.5   Type        \n",
            "-----------------------------------------------------------------------------------------------\n",
            "1    paraphrase-vietnamese-law                     0.9034     0.8780   11.4   12.8   transformers\n",
            "2    paraphrase-vietnamese-law-ALQAC               0.8711     0.7927   6.6    13.2   transformers\n",
            "3    Vietnamese_Law_Embedding_finetuned_v3_25      0.8577     0.8287   12.5   15.0   transformers\n",
            "4    paraphrase-multilingual-mpnet-base-v2         0.7647     0.7310   8.0    14.1   sentence_transformers\n",
            "5    bge-m3                                        0.7181     0.6819   4.7    12.9   sentence_transformers\n",
            "6    vietnamese-bi-encoder-fine-tuning-for-la      0.6379     0.5981   2.2    10.6   transformers\n",
            "\n",
            "⭐ RECOMMENDED MODEL:\n",
            "   🥇 minhquan6203/paraphrase-vietnamese-law\n",
            "   📝 Mô hình Sentence Similarity đã fine tune trên bộ luật pháp Việt Nam\n",
            "   🎯 Performance Highlights:\n",
            "      - Average Max Score: 0.9034\n",
            "      - Average Top-5 Score: 0.8780\n",
            "      - Queries with score ≥ 0.7: 11.4 per query\n",
            "      - Queries with score ≥ 0.5: 12.8 per query\n",
            "\n",
            "📈 PERFORMANCE ANALYSIS:\n",
            "   📊 Overall Statistics:\n",
            "      - Best Max Score: 0.9034\n",
            "      - Worst Max Score: 0.6379\n",
            "      - Average Max Score: 0.7921\n",
            "      - Best Top-5 Score: 0.8780\n",
            "      - Average Top-5 Score: 0.7518\n",
            "\n",
            "🔧 MODEL TYPE COMPARISON:\n",
            "   🔨 Transformers models: 4 models, avg score: 0.8175\n",
            "   📦 Sentence-transformers: 2 models, avg score: 0.7414\n",
            "   ✅ Transformers models perform better on average (+0.0761)\n",
            "\n",
            "💡 RECOMMENDATIONS:\n",
            "   🎯 For Production Deployment:\n",
            "      - Primary: minhquan6203/paraphrase-vietnamese-law\n",
            "      - Type: transformers\n",
            "      - Max Length: 512 tokens\n",
            "   🥈 Alternative Option:\n",
            "      - huyhuy123/paraphrase-vietnamese-law-ALQAC\n",
            "      - Performance difference: 0.0323\n",
            "\n",
            "🔍 DETAILED QUERY ANALYSIS:\n",
            "   📝 Sample Query Performance (Best Model):\n",
            "\n",
            "   Query 1: Người bị bệnh tâm thần là người mất năng lực hành vi dân sự ...\n",
            "      Max Score: 0.3415\n",
            "      Top-3 Average: 0.3143\n",
            "      Results ≥ 0.7: 0\n",
            "\n",
            "   Query 2: Sự thỏa thuận của các bên không vi phạm điều cấm của pháp lu...\n",
            "      Max Score: 0.7058\n",
            "      Top-3 Average: 0.6917\n",
            "      Results ≥ 0.7: 1\n",
            "\n",
            "   Query 3: Tiền phúng viếng đám ma cũng thuộc di sản thừa kế của người ...\n",
            "      Max Score: 0.9016\n",
            "      Top-3 Average: 0.8695\n",
            "      Results ≥ 0.7: 4\n",
            "\n",
            "====================================================================================================\n",
            "✅ EVALUATION COMPLETED SUCCESSFULLY!\n",
            "📊 Summary saved to 'evaluation_summary' variable\n",
            "📋 Full results available in 'evaluation_results' variable\n",
            "====================================================================================================\n",
            "\n",
            "💾 EXPORT OPTIONS:\n",
            "   To save results to JSON file:\n",
            "   → import json\n",
            "   → with open('embedding_evaluation_results.json', 'w', encoding='utf-8') as f:\n",
            "   →     json.dump(evaluation_results, f, ensure_ascii=False, indent=2)\n",
            "\n",
            "🎉 Report generation completed!\n"
          ]
        }
      ],
      "source": [
        "# ===== DETAILED ANALYSIS AND FINAL REPORT =====\n",
        "print(\"📊 Generating detailed analysis and final report...\")\n",
        "\n",
        "if not evaluation_results:\n",
        "    print(\"❌ No evaluation results available. Please run the evaluation first!\")\n",
        "else:\n",
        "    print(f\"\\n{'='*100}\")\n",
        "    print(f\"📋 COMPREHENSIVE EVALUATION REPORT\")\n",
        "    print(f\"{'='*100}\")\n",
        "    \n",
        "    # Sort models by average max score (best first)\n",
        "    sorted_results = sorted(\n",
        "        evaluation_results, \n",
        "        key=lambda x: x['aggregated_metrics']['avg_max_score'], \n",
        "        reverse=True\n",
        "    )\n",
        "    \n",
        "    print(f\"📊 DATASET INFORMATION:\")\n",
        "    print(f\"   📚 Law Documents: {len(law_docs)} chunks from Luật Hôn nhân và Gia đình\")\n",
        "    print(f\"   ❓ Benchmark Queries: {len(benchmark_queries)} questions\")\n",
        "    print(f\"   🔍 Evaluation Method: Top-15 retrieval with cosine similarity\")\n",
        "    print(f\"   💾 Storage: RAM-based (no vector database)\")\n",
        "    \n",
        "    print(f\"\\n🏆 RANKING BY PERFORMANCE:\")\n",
        "    print(f\"   Metric: Average Max Score across all queries\")\n",
        "    \n",
        "    # Create comparison table\n",
        "    print(f\"\\n{'Rank':<4} {'Model':<45} {'Max Score':<10} {'Top-5':<8} {'≥0.7':<6} {'≥0.5':<6} {'Type':<12}\")\n",
        "    print(f\"{'-'*95}\")\n",
        "    \n",
        "    for i, result in enumerate(sorted_results):\n",
        "        metrics = result['aggregated_metrics']\n",
        "        model_name = result['model_name'].split('/')[-1][:40]  # Truncate long names\n",
        "        model_type = result['model_type']\n",
        "        \n",
        "        print(f\"{i+1:<4} {model_name:<45} {metrics['avg_max_score']:<10.4f} \"\n",
        "              f\"{metrics['avg_avg_top5']:<8.4f} {metrics['avg_scores_above_07']:<6.1f} \"\n",
        "              f\"{metrics['avg_scores_above_05']:<6.1f} {model_type:<12}\")\n",
        "    \n",
        "    # Best model analysis\n",
        "    best_model = sorted_results[0]\n",
        "    print(f\"\\n⭐ RECOMMENDED MODEL:\")\n",
        "    print(f\"   🥇 {best_model['model_name']}\")\n",
        "    print(f\"   📝 {best_model['model_description']}\")\n",
        "    print(f\"   🎯 Performance Highlights:\")\n",
        "    best_metrics = best_model['aggregated_metrics']\n",
        "    print(f\"      - Average Max Score: {best_metrics['avg_max_score']:.4f}\")\n",
        "    print(f\"      - Average Top-5 Score: {best_metrics['avg_avg_top5']:.4f}\")\n",
        "    print(f\"      - Queries with score ≥ 0.7: {best_metrics['avg_scores_above_07']:.1f} per query\")\n",
        "    print(f\"      - Queries with score ≥ 0.5: {best_metrics['avg_scores_above_05']:.1f} per query\")\n",
        "    \n",
        "    # Performance analysis\n",
        "    print(f\"\\n📈 PERFORMANCE ANALYSIS:\")\n",
        "    \n",
        "    # Calculate overall statistics\n",
        "    all_max_scores = [r['aggregated_metrics']['avg_max_score'] for r in evaluation_results]\n",
        "    all_top5_scores = [r['aggregated_metrics']['avg_avg_top5'] for r in evaluation_results]\n",
        "    \n",
        "    print(f\"   📊 Overall Statistics:\")\n",
        "    print(f\"      - Best Max Score: {max(all_max_scores):.4f}\")\n",
        "    print(f\"      - Worst Max Score: {min(all_max_scores):.4f}\")\n",
        "    print(f\"      - Average Max Score: {np.mean(all_max_scores):.4f}\")\n",
        "    print(f\"      - Best Top-5 Score: {max(all_top5_scores):.4f}\")\n",
        "    print(f\"      - Average Top-5 Score: {np.mean(all_top5_scores):.4f}\")\n",
        "    \n",
        "    # Model type analysis\n",
        "    transformers_models = [r for r in evaluation_results if r['model_type'] == 'transformers']\n",
        "    sentence_transformers_models = [r for r in evaluation_results if r['model_type'] == 'sentence_transformers']\n",
        "    \n",
        "    if transformers_models and sentence_transformers_models:\n",
        "        print(f\"\\n🔧 MODEL TYPE COMPARISON:\")\n",
        "        \n",
        "        trans_avg = np.mean([r['aggregated_metrics']['avg_max_score'] for r in transformers_models])\n",
        "        sent_avg = np.mean([r['aggregated_metrics']['avg_max_score'] for r in sentence_transformers_models])\n",
        "        \n",
        "        print(f\"   🔨 Transformers models: {len(transformers_models)} models, avg score: {trans_avg:.4f}\")\n",
        "        print(f\"   📦 Sentence-transformers: {len(sentence_transformers_models)} models, avg score: {sent_avg:.4f}\")\n",
        "        \n",
        "        if trans_avg > sent_avg:\n",
        "            print(f\"   ✅ Transformers models perform better on average (+{trans_avg - sent_avg:.4f})\")\n",
        "        else:\n",
        "            print(f\"   ✅ Sentence-transformers models perform better on average (+{sent_avg - trans_avg:.4f})\")\n",
        "    \n",
        "    # Recommendations\n",
        "    print(f\"\\n💡 RECOMMENDATIONS:\")\n",
        "    print(f\"   🎯 For Production Deployment:\")\n",
        "    print(f\"      - Primary: {best_model['model_name']}\")\n",
        "    print(f\"      - Type: {best_model['model_type']}\")\n",
        "    print(f\"      - Max Length: {best_model['max_length']} tokens\")\n",
        "    \n",
        "    if len(sorted_results) > 1:\n",
        "        second_best = sorted_results[1]\n",
        "        print(f\"   🥈 Alternative Option:\")\n",
        "        print(f\"      - {second_best['model_name']}\")\n",
        "        print(f\"      - Performance difference: {best_metrics['avg_max_score'] - second_best['aggregated_metrics']['avg_max_score']:.4f}\")\n",
        "    \n",
        "    print(f\"\\n🔍 DETAILED QUERY ANALYSIS:\")\n",
        "    print(f\"   📝 Sample Query Performance (Best Model):\")\n",
        "    \n",
        "    # Show performance on first 3 queries for best model\n",
        "    best_query_results = best_model['query_results'][:3]\n",
        "    for i, qr in enumerate(best_query_results):\n",
        "        print(f\"\\n   Query {i+1}: {qr['query'][:60]}...\")\n",
        "        print(f\"      Max Score: {qr['metrics']['max_score']:.4f}\")\n",
        "        print(f\"      Top-3 Average: {qr['metrics']['avg_top3']:.4f}\")\n",
        "        print(f\"      Results ≥ 0.7: {qr['metrics']['scores_above_07']}\")\n",
        "    \n",
        "    # Save summary to variables for further use\n",
        "    evaluation_summary = {\n",
        "        'best_model': best_model['model_name'],\n",
        "        'best_score': best_metrics['avg_max_score'],\n",
        "        'total_models_evaluated': len(evaluation_results),\n",
        "        'total_queries': len(benchmark_queries),\n",
        "        'total_documents': len(law_docs),\n",
        "        'sorted_results': sorted_results\n",
        "    }\n",
        "    \n",
        "    print(f\"\\n{'='*100}\")\n",
        "    print(f\"✅ EVALUATION COMPLETED SUCCESSFULLY!\")\n",
        "    print(f\"📊 Summary saved to 'evaluation_summary' variable\")\n",
        "    print(f\"📋 Full results available in 'evaluation_results' variable\")\n",
        "    print(f\"{'='*100}\")\n",
        "    \n",
        "    # Export option\n",
        "    print(f\"\\n💾 EXPORT OPTIONS:\")\n",
        "    print(f\"   To save results to JSON file:\")\n",
        "    print(f\"   → import json\")\n",
        "    print(f\"   → with open('embedding_evaluation_results.json', 'w', encoding='utf-8') as f:\")\n",
        "    print(f\"   →     json.dump(evaluation_results, f, ensure_ascii=False, indent=2)\")\n",
        "    \n",
        "    print(f\"\\n🎉 Report generation completed!\")\n",
        "    \n",
        "    # Make summary available globally\n",
        "    globals()['evaluation_summary'] = evaluation_summary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Test với Single Query\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🧪 Quick test with single query...\n",
            "📝 Test Query: Điều kiện kết hôn của nam và nữ theo pháp luật Việt Nam là gì?\n",
            "🎯 Using manual model: sentence-transformers/paraphrase-multilingual-mpnet-base-v2\n",
            "🔍 Testing single query with model `sentence-transformers/paraphrase-multilingual-mpnet-base-v2`...\n",
            "Loading model: sentence-transformers/paraphrase-multilingual-mpnet-base-v2\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c2166c33860847c8a608f66790151156",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ✅ Generated 1 embeddings, stored in RAM\n",
            "Loading model: sentence-transformers/paraphrase-multilingual-mpnet-base-v2\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20d83ab0089449f09d27fecc1646882d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ✅ Generated 396 embeddings, stored in RAM\n",
            "📝 Query: Điều kiện kết hôn của nam và nữ theo pháp luật Việt Nam là gì?\n",
            "🎯 Top 5 Results:\n",
            "\n",
            "   1. Score: 0.8354 | Điều 126, Khoản 1\n",
            "      Type: clause | Length: 309 chars\n",
            "      Content: Khoản 1. Trong việc kết hôn giữa công dân Việt Nam với người nước ngoài, mỗi bên phải tuân theo pháp luật của nước mình về điều kiện kết hôn; nếu việc kết hôn được tiến hành tại cơ quan nhà nước có th...\n",
            "      Metadata: chapter: Chương VIII, section: None, article_no: 126, article_title: Kết hôn có yếu tố nước ngoài, clause_no: 1, exact_citation: Điều 126 khoản 1\n",
            "\n",
            "   2. Score: 0.8299 | Điều 126, Khoản 2\n",
            "      Type: clause | Length: 173 chars\n",
            "      Content: Khoản 2. Việc kết hôn giữa những người nước ngoài thường trú ở Việt Nam tại cơ quan có thẩm quyền của Việt Nam phải tuân theo các quy định của Luật này về điều kiện kết hôn....\n",
            "      Metadata: chapter: Chương VIII, section: None, article_no: 126, article_title: Kết hôn có yếu tố nước ngoài, clause_no: 2, exact_citation: Điều 126 khoản 2\n",
            "\n",
            "   3. Score: 0.8036 | Điều 122, Khoản 1\n",
            "      Type: clause | Length: 393 chars\n",
            "      Content: Khoản 1. Các quy định của pháp luật về hôn nhân và gia đình của nước Cộng hòa xã hội chủ nghĩa Việt Nam được áp dụng đối với quan hệ hôn nhân và gia đình có yếu tố nước ngoài, trừ trường hợp Luật này ...\n",
            "      Metadata: chapter: Chương VIII, section: None, article_no: 122, article_title: Áp dụng pháp luật đối với quan hệ hôn nhân và gia đình có yếu tố nước ngoài, clause_no: 1, exact_citation: Điều 122 khoản 1\n",
            "\n",
            "   4. Score: 0.8022 | Điều 2, Khoản 2\n",
            "      Type: clause | Length: 266 chars\n",
            "      Content: Khoản 2. Hôn nhân giữa công dân Việt Nam thuộc các dân tộc, tôn giáo, giữa người theo tôn giáo với người không theo tôn giáo, giữa người có tín ngưỡng với người không có tín ngưỡng, giữa công dân Việt...\n",
            "      Metadata: chapter: Chương I, section: None, article_no: 2, article_title: Những nguyên tắc cơ bản của chế độ hôn nhân và gia đình, clause_no: 2, exact_citation: Điều 2 khoản 2\n",
            "\n",
            "   5. Score: 0.7996 | Điều 130 - Áp dụng chế độ tài sản của vợ chồng theo thỏa thuận; giải quyết hậu quả của việc nam, nữ chung sống với nhau như vợ chồng mà không đăng ký kết hôn có yếu tố nước ngoài\n",
            "      Type: article_intro | Length: 500 chars\n",
            "      Content: Điều 130. Áp dụng chế độ tài sản của vợ chồng theo thỏa thuận; giải quyết hậu quả của việc nam, nữ chung sống với nhau như vợ chồng mà không đăng ký kết hôn có yếu tố nước ngoài\n",
            "Trong trường hợp có yê...\n",
            "      Metadata: chapter: Chương VIII, section: None, article_no: 130, article_title: Áp dụng chế độ tài sản của vợ chồng theo thỏa thuận; giải quyết hậu quả của việc nam, nữ chung sống với nhau như vợ chồng mà không đăng ký kết hôn có yếu tố nước ngoài, exact_citation: Điều 130\n",
            "\n",
            "📊 Metrics for this query:\n",
            "   - Max Score: 0.8354\n",
            "   - Top-5 Average: 0.8141\n",
            "   - Results ≥ 0.7: 10\n",
            "   - Results ≥ 0.5: 10\n",
            "\n",
            "✅ Single query test completed!\n"
          ]
        }
      ],
      "source": [
        "# ===== TEST SINGLE QUERY =====\n",
        "print(\"🧪 Quick test with single query...\")\n",
        "\n",
        "# Test query\n",
        "test_query = \"Điều kiện kết hôn của nam và nữ theo pháp luật Việt Nam là gì?\"\n",
        "print(f\"📝 Test Query: {test_query}\")\n",
        "\n",
        "manual_model_name = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\" \n",
        "\n",
        "# Check evaluation summary\n",
        "if 'evaluation_summary' in globals() and evaluation_summary:\n",
        "    if manual_model_name:  \n",
        "        best_model_name = manual_model_name\n",
        "        print(f\"🎯 Using manual model: {best_model_name}\")\n",
        "    else:\n",
        "        best_model_name = evaluation_summary['best_model']\n",
        "        print(f\"🥇 Using best model: {best_model_name}\")\n",
        "\n",
        "    # Find model info\n",
        "    best_model_info = None\n",
        "    for model in models_to_evaluate:\n",
        "        if model['name'] == best_model_name:\n",
        "            best_model_info = model\n",
        "            break\n",
        "\n",
        "    if best_model_info:\n",
        "        print(f\"🔍 Testing single query with model `{best_model_info['name']}`...\")\n",
        "\n",
        "        # Encode query\n",
        "        if best_model_info['type'] == 'sentence_transformers':\n",
        "            test_query_embedding = encode_with_sentence_transformers([test_query], best_model_info['name'])[0]\n",
        "        else:\n",
        "            test_query_embedding = encode_with_transformers([test_query], best_model_info['name'], best_model_info['max_length'])[0]\n",
        "\n",
        "        # Encode documents (re-encode cho demo, thực tế nên cache)\n",
        "        doc_texts = [doc['text'] for doc in law_docs]\n",
        "        if best_model_info['type'] == 'sentence_transformers':\n",
        "            doc_embeddings = encode_with_sentence_transformers(doc_texts, best_model_info['name'])\n",
        "        else:\n",
        "            doc_embeddings = encode_with_transformers(doc_texts, best_model_info['name'], best_model_info['max_length'])\n",
        "\n",
        "        # Search\n",
        "        top_indices, top_scores = search_top_k(test_query_embedding, doc_embeddings, k=10)\n",
        "\n",
        "        # Display results\n",
        "        display_search_results(test_query, law_docs, top_indices, top_scores, max_display=5)\n",
        "\n",
        "        # Metrics\n",
        "        metrics = calculate_metrics(top_scores)\n",
        "        print(f\"\\n📊 Metrics for this query:\")\n",
        "        print(f\"   - Max Score: {metrics['max_score']:.4f}\")\n",
        "        print(f\"   - Top-5 Average: {metrics['avg_top5']:.4f}\")\n",
        "        print(f\"   - Results ≥ 0.7: {metrics['scores_above_07']}\")\n",
        "        print(f\"   - Results ≥ 0.5: {metrics['scores_above_05']}\")\n",
        "    else:\n",
        "        print(\"❌ Could not find model info for testing\")\n",
        "\n",
        "else:\n",
        "    print(\"⚠️ No evaluation results available. Run the full evaluation first!\")\n",
        "\n",
        "print(f\"\\n✅ Single query test completed!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "legal_ai_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
