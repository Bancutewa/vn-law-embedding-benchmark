{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ÄÃ¡nh GiÃ¡ MÃ´ HÃ¬nh Embedding Cho Luáº­t Tiáº¿ng Viá»‡t\n",
        "\n",
        "Notebook nÃ y thá»±c hiá»‡n Ä‘Ã¡nh giÃ¡ sÆ¡ bá»™ nhiá»u mÃ´ hÃ¬nh embedding cho tiáº¿ng Viá»‡t vÃ  luáº­t tiáº¿ng Viá»‡t\n",
        "\n",
        "## YÃªu cáº§u:\n",
        "- ÄÃ¡nh giÃ¡ cÃ¡c mÃ´ hÃ¬nh embedding tá»« 512 token trá»Ÿ lÃªn\n",
        "- LÆ°u embeddings trÃªn RAM\n",
        "- LÃ m giÃ u data: 200-300 vÄƒn báº£n luáº­t\n",
        "- Sá»­ dá»¥ng queries tá»« benchmark\n",
        "- ÄÃ¡nh giÃ¡ top 10-15 káº¿t quáº£ vÃ  ngÆ°á»¡ng Ä‘iá»ƒm\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Importing core libraries...\n",
            "âš ï¸  huggingface_hub: expected 0.16.4, got 0.34.4\n",
            "âš ï¸  tokenizers: expected 0.13.3, got 0.22.0\n",
            "âš ï¸  transformers: expected 4.32.1, got 4.56.1\n",
            "âš ï¸  sentence-transformers: expected 2.2.2, got 5.1.0\n",
            "\n",
            "ğŸ”„ Importing transformers...\n",
            "âœ… transformers imported successfully\n",
            "âœ… transformers functionality test passed\n",
            "\n",
            "ğŸ”„ Importing sentence-transformers...\n",
            "âœ… sentence-transformers imported successfully\n",
            "âœ… sentence-transformers functionality test passed (embedding shape: (1, 384))\n",
            "\n",
            "ğŸ”„ Importing document processing...\n",
            "âœ… python-docx imported successfully\n",
            "\n",
            "ğŸ–¥ï¸  Using device: cuda\n",
            "   GPU: NVIDIA GeForce RTX 3050 Ti Laptop GPU\n",
            "   GPU Memory: 4.3 GB\n",
            "\n",
            "ğŸ‰ All libraries loaded successfully! Ready for evaluation.\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "print(\"ğŸ”„ Importing core libraries...\")\n",
        "\n",
        "# Check installed versions\n",
        "def check_version(package_name, expected_version=None):\n",
        "    try:\n",
        "        import importlib.metadata\n",
        "        version = importlib.metadata.version(package_name)\n",
        "        if expected_version and version != expected_version:\n",
        "            print(f\"âš ï¸  {package_name}: expected {expected_version}, got {version}\")\n",
        "        else:\n",
        "            print(f\"âœ… {package_name}: {version}\")\n",
        "        return True, version\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ {package_name}: not found or error ({e})\")\n",
        "        return False, None\n",
        "\n",
        "# Check critical versions\n",
        "check_version(\"huggingface_hub\", \"0.16.4\")\n",
        "check_version(\"tokenizers\", \"0.13.3\")\n",
        "check_version(\"transformers\", \"4.32.1\")\n",
        "check_version(\"sentence-transformers\", \"2.2.2\")\n",
        "\n",
        "# Import transformers with detailed error handling\n",
        "print(\"\\nğŸ”„ Importing transformers...\")\n",
        "try:\n",
        "    from transformers import AutoTokenizer, AutoModel\n",
        "    print(\"âœ… transformers imported successfully\")\n",
        "    \n",
        "    # Quick functionality test\n",
        "    test_tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "    test_tokens = test_tokenizer(\"test\", return_tensors=\"pt\")\n",
        "    print(\"âœ… transformers functionality test passed\")\n",
        "    del test_tokenizer, test_tokens\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âŒ transformers failed: {e}\")\n",
        "    print(\"ğŸ”§ If this fails, please restart kernel and run first cell again\")\n",
        "    raise\n",
        "\n",
        "# Import sentence-transformers with detailed error handling\n",
        "print(\"\\nğŸ”„ Importing sentence-transformers...\")\n",
        "try:\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "    print(\"âœ… sentence-transformers imported successfully\")\n",
        "    \n",
        "    # Quick functionality test\n",
        "    test_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "    test_embedding = test_model.encode([\"test sentence\"])\n",
        "    print(f\"âœ… sentence-transformers functionality test passed (embedding shape: {test_embedding.shape})\")\n",
        "    del test_model, test_embedding\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âŒ sentence-transformers failed: {e}\")\n",
        "    print(\"ğŸ”§ If this fails, please restart kernel and run first cell again\")\n",
        "    raise\n",
        "\n",
        "# Import document processing\n",
        "print(\"\\nğŸ”„ Importing document processing...\")\n",
        "try:\n",
        "    from docx import Document\n",
        "    print(\"âœ… python-docx imported successfully\")\n",
        "except ImportError:\n",
        "    print(\"ğŸ“¦ Installing python-docx...\")\n",
        "    import subprocess\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"python-docx==0.8.11\"])\n",
        "    from docx import Document\n",
        "    print(\"âœ… python-docx installed and imported\")\n",
        "\n",
        "# Device configuration\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"\\nğŸ–¥ï¸  Using device: {device}\")\n",
        "if device == \"cuda\":\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name()}\")\n",
        "    print(f\"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "\n",
        "print(\"\\nğŸ‰ All libraries loaded successfully! Ready for evaluation.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Chuáº©n bá»‹ dá»¯ liá»‡u luáº­t\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”¢ Setting up Roman numeral converter...\n",
            "âœ… Roman converter test:\n",
            "   I -> 1\n",
            "   II -> 2\n",
            "   III -> 3\n",
            "   IV -> 4\n",
            "   V -> 5\n",
            "   VI -> 6\n",
            "   VII -> 7\n",
            "   VIII -> 8\n",
            "   IX -> 9\n",
            "   X -> 10\n",
            "   L -> 50\n",
            "   C -> 100\n",
            "   D -> 500\n",
            "   M -> 1000\n",
            "âœ… Roman numeral converter ready!\n"
          ]
        }
      ],
      "source": [
        "# ===== ROMAN NUMBER CONVERTER =====\n",
        "print(\"ğŸ”¢ Setting up Roman numeral converter...\")\n",
        "\n",
        "ROMAN_MAP = {'I':1,'V':5,'X':10,'L':50,'C':100,'D':500,'M':1000}\n",
        "\n",
        "def roman_to_int(s: str):\n",
        "    \"\"\"\n",
        "    Chuyá»ƒn Ä‘á»•i sá»‘ La MÃ£ sang sá»‘ nguyÃªn\n",
        "    VÃ­ dá»¥: 'I' -> 1, 'IV' -> 4, 'IX' -> 9, 'X' -> 10\n",
        "    \"\"\"\n",
        "    s = s.upper().strip()\n",
        "    if not s or any(ch not in ROMAN_MAP for ch in s):\n",
        "        return None\n",
        "    total = 0\n",
        "    prev = 0\n",
        "    for ch in reversed(s):\n",
        "        val = ROMAN_MAP[ch]\n",
        "        if val < prev:\n",
        "            total -= val\n",
        "        else:\n",
        "            total += val\n",
        "            prev = val\n",
        "    return total\n",
        "\n",
        "# Test Roman converter\n",
        "test_romans = ['I',\"II\",\"III\",\"IV\",\"V\",\"VI\",\"VII\",\"VIII\",\"IX\",\"X\", \"L\", \"C\", \"D\", \"M\"]\n",
        "print(\"âœ… Roman converter test:\")\n",
        "for roman in test_romans:\n",
        "    print(f\"   {roman} -> {roman_to_int(roman)}\")\n",
        "\n",
        "print(\"âœ… Roman numeral converter ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”§ Setting up embedding utility functions...\n",
            "âœ… Embedding utility functions ready!\n",
            "   ğŸ“¦ encode_with_transformers: for transformers models with mean pooling\n",
            "   ğŸ“¦ encode_with_sentence_transformers: for sentence-transformers models\n",
            "   ğŸ’¾ All embeddings stored in RAM (not vector database)\n"
          ]
        }
      ],
      "source": [
        "# ===== UTILITY FUNCTIONS FOR EMBEDDING =====\n",
        "print(\"ğŸ”§ Setting up embedding utility functions...\")\n",
        "\n",
        "def mean_pooling(model_output, attention_mask):\n",
        "    \"\"\"\n",
        "    Mean pooling Ä‘á»ƒ táº¡o sentence embeddings tá»« token embeddings\n",
        "    \n",
        "    Input:\n",
        "    - model_output: output tá»« transformer model\n",
        "    - attention_mask: mask Ä‘á»ƒ ignore padding tokens\n",
        "    \n",
        "    Output:\n",
        "    - Sentence embeddings vá»›i mean pooling\n",
        "    \"\"\"\n",
        "    token_embeddings = model_output[0]  # First element of model_output contains all token embeddings\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "\n",
        "def encode_with_transformers(texts, model_name, max_length=512, batch_size=32):\n",
        "    \"\"\"\n",
        "    Encode texts using transformers library vá»›i mean pooling\n",
        "    \n",
        "    Input:\n",
        "    - texts: list of texts to encode\n",
        "    - model_name: HuggingFace model name\n",
        "    - max_length: maximum sequence length\n",
        "    - batch_size: batch size for processing\n",
        "    \n",
        "    Output:\n",
        "    - numpy array of embeddings (stored in RAM)\n",
        "    \"\"\"\n",
        "    print(f\"Loading model: {model_name}\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModel.from_pretrained(model_name).to(device)\n",
        "    model.eval()\n",
        "    \n",
        "    all_embeddings = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(0, len(texts), batch_size), desc=\"Encoding\"):\n",
        "            batch = texts[i:i+batch_size]\n",
        "            \n",
        "            # Tokenize\n",
        "            encoded = tokenizer(\n",
        "                batch, \n",
        "                padding=True, \n",
        "                truncation=True, \n",
        "                max_length=max_length,\n",
        "                return_tensors='pt'\n",
        "            ).to(device)\n",
        "            \n",
        "            # Get model output\n",
        "            model_output = model(**encoded)\n",
        "            \n",
        "            # Mean pooling\n",
        "            sentence_embeddings = mean_pooling(model_output, encoded['attention_mask'])\n",
        "            \n",
        "            # Normalize embeddings\n",
        "            sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)\n",
        "            \n",
        "            # Move to CPU and convert to numpy (store in RAM)\n",
        "            embeddings = sentence_embeddings.cpu().numpy()\n",
        "            all_embeddings.append(embeddings)\n",
        "            \n",
        "            # Clear GPU memory\n",
        "            del encoded, model_output, sentence_embeddings, embeddings\n",
        "            torch.cuda.empty_cache() if device == \"cuda\" else None\n",
        "    \n",
        "    # Delete model to free memory\n",
        "    del model, tokenizer\n",
        "    torch.cuda.empty_cache() if device == \"cuda\" else None\n",
        "    \n",
        "    # Combine all embeddings and store in RAM\n",
        "    final_embeddings = np.vstack(all_embeddings)\n",
        "    print(f\"   âœ… Generated {final_embeddings.shape[0]} embeddings, stored in RAM\")\n",
        "    \n",
        "    return final_embeddings\n",
        "\n",
        "def encode_with_sentence_transformers(texts, model_name, batch_size=32):\n",
        "    \"\"\"\n",
        "    Encode texts using sentence-transformers library\n",
        "    \n",
        "    Input:\n",
        "    - texts: list of texts to encode  \n",
        "    - model_name: SentenceTransformer model name\n",
        "    - batch_size: batch size for processing\n",
        "    \n",
        "    Output:\n",
        "    - numpy array of embeddings (stored in RAM)\n",
        "    \"\"\"\n",
        "    print(f\"Loading model: {model_name}\")\n",
        "    model = SentenceTransformer(model_name)\n",
        "    model.to(device)\n",
        "    \n",
        "    # Encode all texts\n",
        "    embeddings = model.encode(\n",
        "        texts,\n",
        "        batch_size=batch_size,\n",
        "        show_progress_bar=True,\n",
        "        convert_to_numpy=True,  # Convert to numpy (RAM storage)\n",
        "        normalize_embeddings=True  # Normalize for cosine similarity\n",
        "    )\n",
        "    \n",
        "    # Delete model to free memory\n",
        "    del model\n",
        "    torch.cuda.empty_cache() if device == \"cuda\" else None\n",
        "    \n",
        "    print(f\"   âœ… Generated {embeddings.shape[0]} embeddings, stored in RAM\")\n",
        "    \n",
        "    return embeddings\n",
        "\n",
        "print(\"âœ… Embedding utility functions ready!\")\n",
        "print(\"   ğŸ“¦ encode_with_transformers: for transformers models with mean pooling\")\n",
        "print(\"   ğŸ“¦ encode_with_sentence_transformers: for sentence-transformers models\") \n",
        "print(\"   ğŸ’¾ All embeddings stored in RAM (not vector database)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“– Setting up document reading functions...\n",
            "âœ… Document reading functions ready!\n"
          ]
        }
      ],
      "source": [
        "# ===== DOCUMENT READER FUNCTIONS =====\n",
        "print(\"ğŸ“– Setting up document reading functions...\")\n",
        "\n",
        "def read_docx(file_path):\n",
        "    \"\"\"\n",
        "    Äá»c file docx vÃ  tráº£ vá» text\n",
        "    Input: Ä‘Æ°á»ng dáº«n file .docx\n",
        "    Output: text content cá»§a file\n",
        "    \"\"\"\n",
        "    print(f\"   Reading file: {file_path}\")\n",
        "    doc = Document(file_path)\n",
        "    text = \"\\n\".join((p.text or \"\").strip() for p in doc.paragraphs)\n",
        "    print(f\"   âœ… Successfully read {len(text):,} characters\")\n",
        "    return text\n",
        "\n",
        "def normalize_lines(text: str):\n",
        "    \"\"\"\n",
        "    Chuáº©n hÃ³a cÃ¡c dÃ²ng text - loáº¡i bá» whitespace thá»«a\n",
        "    Input: raw text\n",
        "    Output: list cÃ¡c dÃ²ng Ä‘Ã£ Ä‘Æ°á»£c normalize\n",
        "    \"\"\"\n",
        "    lines = [re.sub(r'\\s+$', '', ln) for ln in text.splitlines()]\n",
        "    print(f\"   âœ… Normalized {len(lines):,} lines\")\n",
        "    return lines\n",
        "\n",
        "print(\"âœ… Document reading functions ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âš–ï¸ Setting up PROPER advanced law document chunking (from chunking.py)...\n",
            "âœ… PROPER Advanced law document chunking ready!\n"
          ]
        }
      ],
      "source": [
        "# ===== PROPER ADVANCED LAW DOCUMENT CHUNKING =====\n",
        "print(\"âš–ï¸ Setting up PROPER advanced law document chunking (from chunking.py)...\")\n",
        "\n",
        "def advanced_chunk_law_document(text, max_length=600):\n",
        "    \"\"\"\n",
        "    Chia vÄƒn báº£n luáº­t thÃ nh chunks theo logic CHÃNH XÃC \n",
        "    \n",
        "    2-Pass System:\n",
        "    - Pass 1 (prescan): Äáº¿m CHÆ¯Æ NG & ÄIá»€U á»Ÿ Ä‘áº§u dÃ²ng\n",
        "    - Pass 2 (strict): Strict sequence validation + Clause intro injection\n",
        "    \n",
        "    KEY FEATURES:\n",
        "    - Khoáº£n: PHáº¢I dáº¡ng \"1.\" (sá»‘ + dáº¥u cháº¥m)\n",
        "    - Äiá»ƒm: PHáº¢I dáº¡ng \"a)\" (cÃ³ dáº¥u )). Chá»‰ báº¯t chuá»—i Ä‘iá»ƒm náº¿u má»Ÿ Ä‘áº§u lÃ  a).\n",
        "    - TIÃŠM intro khoáº£n vÃ o content cá»§a má»i Ä‘iá»ƒm (QUAN TRá»ŒNG!)\n",
        "    \"\"\"\n",
        "    print(\"   ğŸ” 2-Pass advanced parsing with full validation...\")\n",
        "    lines = normalize_lines(text)\n",
        "    \n",
        "    # ===== Regex patterns (CHÃNH XÃC tá»« chunking.py) =====\n",
        "    ARTICLE_RE = re.compile(r'^Äiá»u\\s+(\\d+)\\s*[\\.:]?\\s*(.*)$', re.UNICODE)\n",
        "    CHAPTER_RE = re.compile(r'^ChÆ°Æ¡ng\\s+([IVXLCDM]+)\\s*(.*)$', re.UNICODE|re.IGNORECASE)\n",
        "    SECTION_RE = re.compile(r'^Má»¥c\\s+(\\d+)\\s*[:\\-]?\\s*(.*)$', re.UNICODE|re.IGNORECASE)\n",
        "    CLAUSE_RE = re.compile(r'^\\s*(\\d+)\\.\\s*(.*)$', re.UNICODE)  # Khoáº£n: PHáº¢I \"1.\" (sá»‘ + dáº¥u cháº¥m)\n",
        "    POINT_RE = re.compile(r'^\\s*([a-zA-ZÄ‘Ä])\\)\\s+(.*)$', re.UNICODE)  # Äiá»ƒm: PHáº¢I \"a)\" (báº¯t buá»™c cÃ³ ')')\n",
        "    \n",
        "    # ===== PASS 1: Pre-scan CHÆ¯Æ NG/ÄIá»€U =====\n",
        "    def prescan(lines):\n",
        "        chapters_nums, articles_nums = [], []\n",
        "        chapters_labels = []\n",
        "        for line in lines:\n",
        "            if not line: continue\n",
        "            m_ch = CHAPTER_RE.match(line)\n",
        "            if m_ch:\n",
        "                n = roman_to_int(m_ch.group(1))\n",
        "                if n:\n",
        "                    chapters_nums.append(n)\n",
        "                    title = (m_ch.group(2) or \"\").strip()\n",
        "                    chapters_labels.append(f\"ChÆ°Æ¡ng {m_ch.group(1).strip()}\" + (f\" â€“ {title}\" if title else \"\"))\n",
        "                continue\n",
        "            m_art = ARTICLE_RE.match(line)\n",
        "            if m_art:\n",
        "                num = int(m_art.group(1))\n",
        "                articles_nums.append(num)\n",
        "                continue\n",
        "        return chapters_nums, articles_nums, chapters_labels\n",
        "    \n",
        "    # ===== Flush helpers =====\n",
        "    def flush_article_intro(chunks, article_no, article_title, article_intro_buf, chapter, section, stats):\n",
        "        content = (article_intro_buf or \"\").strip()\n",
        "        if not content: return\n",
        "        title_line = f\"Äiá»u {article_no}. {article_title}\".strip() if article_title else f\"Äiá»u {article_no}\"\n",
        "        chunks.append({\n",
        "            \"content\": f\"{title_line}\\n{content}\",\n",
        "            \"title\": f\"Äiá»u {article_no} - {article_title}\" if article_title else f\"Äiá»u {article_no}\",\n",
        "            \"type\": \"article_intro\",\n",
        "            \"metadata\": {\n",
        "                \"chapter\": chapter,\n",
        "                \"section\": section,\n",
        "                \"article_no\": article_no,\n",
        "                \"article_title\": article_title,\n",
        "                \"exact_citation\": f\"Äiá»u {article_no}\"\n",
        "            }\n",
        "        })\n",
        "        stats[\"article_intro\"] += 1\n",
        "    \n",
        "    def flush_clause(chunks, article_no, article_title, clause_no, content, chapter, section, stats):\n",
        "        content = (content or \"\").strip()\n",
        "        if not content: return\n",
        "        chunks.append({\n",
        "            \"content\": f\"Khoáº£n {clause_no}. {content}\",\n",
        "            \"title\": f\"Äiá»u {article_no}, Khoáº£n {clause_no}\",\n",
        "            \"type\": \"clause\",\n",
        "            \"metadata\": {\n",
        "                \"chapter\": chapter,\n",
        "                \"section\": section,\n",
        "                \"article_no\": article_no,\n",
        "                \"article_title\": article_title,\n",
        "                \"clause_no\": clause_no,\n",
        "                \"exact_citation\": f\"Äiá»u {article_no} khoáº£n {clause_no}\"\n",
        "            }\n",
        "        })\n",
        "        stats[\"clauses\"] += 1\n",
        "    \n",
        "    def flush_point(chunks, article_no, article_title, clause_no, letter, content, chapter, section, stats, clause_intro=None):\n",
        "        content = (content or \"\").strip()\n",
        "        if not content: return\n",
        "        \n",
        "        # ğŸ”¥ TIÃŠM intro khoáº£n vÃ o Ä‘áº§u ná»™i dung Ä‘iá»ƒm (KEY FEATURE tá»« chunking.py!)\n",
        "        if clause_intro:\n",
        "            intro = clause_intro.rstrip().rstrip(':') + ':'\n",
        "            content = f\"{intro}\\n{content}\"\n",
        "        \n",
        "        letter = letter.lower()\n",
        "        chunks.append({\n",
        "            \"content\": f\"Khoáº£n {clause_no}, Ä‘iá»ƒm {letter}) {content}\",\n",
        "            \"title\": f\"Äiá»u {article_no}, Khoáº£n {clause_no}, Äiá»ƒm {letter})\",\n",
        "            \"type\": \"point\",\n",
        "            \"metadata\": {\n",
        "                \"chapter\": chapter,\n",
        "                \"section\": section,\n",
        "                \"article_no\": article_no,\n",
        "                \"article_title\": article_title,\n",
        "                \"clause_no\": clause_no,\n",
        "                \"point_letter\": letter,\n",
        "                \"exact_citation\": f\"Äiá»u {article_no} khoáº£n {clause_no} Ä‘iá»ƒm {letter})\",\n",
        "                \"clause_intro\": clause_intro  # LÆ°u Ä‘á»ƒ trace\n",
        "            }\n",
        "        })\n",
        "        stats[\"points\"] += 1\n",
        "    \n",
        "    print(f\"   ğŸ“„ Processing {len(lines):,} lines...\")\n",
        "    \n",
        "    # PASS 1: Pre-scan\n",
        "    print(\"   ğŸ” Pass 1: Pre-scanning structure...\")\n",
        "    chapters_nums, articles_nums, chapters_labels = prescan(lines)\n",
        "    chapters_set, articles_set = set(chapters_nums), set(articles_nums)\n",
        "    \n",
        "    print(f\"      - Pre-scan found {len(chapters_nums)} chapters: {chapters_nums[:10]}{'...' if len(chapters_nums)>10 else ''}\")\n",
        "    print(f\"      - Pre-scan found {len(articles_nums)} articles: {articles_nums[:20]}{'...' if len(articles_nums)>20 else ''}\")\n",
        "    \n",
        "    # PASS 2: Strict chunking\n",
        "    print(\"   ğŸ” Pass 2: Strict parsing with sequence validation...\")\n",
        "    chunks = []\n",
        "    stats = {\"articles\": 0, \"article_intro\": 0, \"clauses\": 0, \"points\": 0}\n",
        "    warnings = []\n",
        "    \n",
        "    chapter_label = None\n",
        "    section_label = None\n",
        "    article_no = None\n",
        "    article_title = \"\"\n",
        "    expecting_article_title = False\n",
        "    article_intro_buf = \"\"\n",
        "    article_has_any_chunk = False\n",
        "    \n",
        "    clause_no = None\n",
        "    clause_buf = \"\"\n",
        "    clause_intro_current = None  # ğŸ”¥ Intro cá»§a khoáº£n sáº½ Ä‘Æ°á»£c tiÃªm vÃ o má»i Ä‘iá»ƒm\n",
        "    in_points = False\n",
        "    point_letter = None\n",
        "    point_buf = \"\"\n",
        "    \n",
        "    expected_chapter = None\n",
        "    expected_article = None\n",
        "    seeking_article = False\n",
        "    \n",
        "    def close_clause():\n",
        "        nonlocal clause_no, clause_buf, in_points, point_letter, point_buf, article_has_any_chunk, clause_intro_current\n",
        "        if clause_no is None: return\n",
        "        if in_points and point_letter:\n",
        "            flush_point(chunks, article_no, article_title, clause_no, point_letter,\n",
        "                        point_buf, chapter_label, section_label, stats, clause_intro_current)\n",
        "        elif clause_buf.strip():\n",
        "            flush_clause(chunks, article_no, article_title, clause_no, clause_buf,\n",
        "                         chapter_label, section_label, stats)\n",
        "        article_has_any_chunk = True\n",
        "        clause_no, clause_buf, in_points, point_letter, point_buf = None, \"\", False, None, \"\"\n",
        "        clause_intro_current = None\n",
        "    \n",
        "    def close_article_if_needed():\n",
        "        nonlocal article_intro_buf, article_has_any_chunk\n",
        "        if (not article_has_any_chunk) and article_intro_buf.strip():\n",
        "            flush_article_intro(chunks, article_no, article_title, article_intro_buf,\n",
        "                                chapter_label, section_label, stats)\n",
        "        article_intro_buf = \"\"\n",
        "        article_has_any_chunk = False\n",
        "    \n",
        "    for ln_idx, line in enumerate(lines, start=1):\n",
        "        if not line: continue\n",
        "        \n",
        "        # Seeking article logic (strict sequence validation)\n",
        "        if seeking_article:\n",
        "            m_art_seek = ARTICLE_RE.match(line)\n",
        "            if m_art_seek:\n",
        "                a_no = int(m_art_seek.group(1))\n",
        "                if a_no == expected_article:\n",
        "                    seeking_article = False\n",
        "                    close_clause()\n",
        "                    if article_no is not None:\n",
        "                        close_article_if_needed()\n",
        "                    article_no = a_no\n",
        "                    article_title = (m_art_seek.group(2) or \"\").strip()\n",
        "                    stats[\"articles\"] += 1\n",
        "                    if not article_title:\n",
        "                        expecting_article_title = True\n",
        "                    expected_article = a_no + 1\n",
        "                    clause_no = None; clause_buf = \"\"; in_points = False; point_letter = None; point_buf = \"\"\n",
        "                    clause_intro_current = None\n",
        "                    continue\n",
        "                else:\n",
        "                    continue\n",
        "            m_ch_seek = CHAPTER_RE.match(line)\n",
        "            if m_ch_seek:\n",
        "                break  # Stop if hit new chapter while seeking\n",
        "            continue\n",
        "        \n",
        "        # Expecting article title on next line\n",
        "        if expecting_article_title:\n",
        "            if not (CHAPTER_RE.match(line) or SECTION_RE.match(line) or CLAUSE_RE.match(line) or POINT_RE.match(line) or ARTICLE_RE.match(line)):\n",
        "                article_title = line; expecting_article_title = False; continue\n",
        "            else:\n",
        "                expecting_article_title = False\n",
        "        \n",
        "        # CHÆ¯Æ NG (with strict sequence validation)\n",
        "        m_ch = CHAPTER_RE.match(line)\n",
        "        if m_ch:\n",
        "            close_clause()\n",
        "            if article_no is not None:\n",
        "                close_article_if_needed()\n",
        "            article_no = None\n",
        "            article_title = \"\"\n",
        "            article_intro_buf = \"\"\n",
        "            expecting_article_title = False\n",
        "            \n",
        "            roman = m_ch.group(1).strip()\n",
        "            ch_num = roman_to_int(roman) or 0\n",
        "            ch_title = (m_ch.group(2) or \"\").strip()\n",
        "            lbl = f\"ChÆ°Æ¡ng {roman}\" + (f\" â€“ {ch_title}\" if ch_title else \"\")\n",
        "            \n",
        "            if expected_chapter is None:\n",
        "                expected_chapter = ch_num + 1\n",
        "            else:\n",
        "                if ch_num == expected_chapter:\n",
        "                    expected_chapter = ch_num + 1\n",
        "                elif ch_num > expected_chapter:\n",
        "                    if expected_chapter not in chapters_set:\n",
        "                        warnings.append(f\"Missing Chapter {expected_chapter} - stopping at {lbl}\")\n",
        "                        break\n",
        "                    else:\n",
        "                        warnings.append(f\"Skipping {lbl} - waiting for Chapter {expected_chapter}\")\n",
        "                        continue\n",
        "                else:\n",
        "                    warnings.append(f\"Skipping {lbl} - backward chapter number\")\n",
        "                    continue\n",
        "            \n",
        "            chapter_label = lbl\n",
        "            section_label = None\n",
        "            continue\n",
        "        \n",
        "        # Má»¤C\n",
        "        m_sec = SECTION_RE.match(line)\n",
        "        if m_sec:\n",
        "            close_clause()\n",
        "            if article_no is not None:\n",
        "                close_article_if_needed()\n",
        "            article_no = None\n",
        "            article_title = \"\"\n",
        "            article_intro_buf = \"\"\n",
        "            expecting_article_title = False\n",
        "            \n",
        "            sec_no = m_sec.group(1).strip()\n",
        "            sec_title = (m_sec.group(2) or \"\").strip()\n",
        "            section_label = f\"Má»¥c {sec_no}\" + (f\" â€“ {sec_title}\" if sec_title else \"\")\n",
        "            continue\n",
        "        \n",
        "        # ÄIá»€U (with strict sequence validation)\n",
        "        m_art = ARTICLE_RE.match(line)\n",
        "        if m_art:\n",
        "            a_no = int(m_art.group(1))\n",
        "            a_title = (m_art.group(2) or \"\").strip()\n",
        "            \n",
        "            if expected_article is None:\n",
        "                expected_article = a_no + 1\n",
        "                close_clause()\n",
        "                if article_no is not None: close_article_if_needed()\n",
        "                article_no = a_no; article_title = a_title; stats[\"articles\"] += 1\n",
        "                if not article_title: expecting_article_title = True\n",
        "                clause_no = None; clause_buf = \"\"; in_points = False; point_letter = None; point_buf = \"\"\n",
        "                clause_intro_current = None\n",
        "                continue\n",
        "            else:\n",
        "                if a_no == expected_article:\n",
        "                    expected_article = a_no + 1\n",
        "                    close_clause()\n",
        "                    if article_no is not None: close_article_if_needed()\n",
        "                    article_no = a_no; article_title = a_title; stats[\"articles\"] += 1\n",
        "                    if not article_title: expecting_article_title = True\n",
        "                    clause_no = None; clause_buf = \"\"; in_points = False; point_letter = None; point_buf = \"\"\n",
        "                    clause_intro_current = None\n",
        "                    continue\n",
        "                elif a_no > expected_article:\n",
        "                    if expected_article not in articles_set:\n",
        "                        warnings.append(f\"Missing Article {expected_article} - stopping at Article {a_no}\")\n",
        "                        break\n",
        "                    else:\n",
        "                        warnings.append(f\"Skipping Article {a_no} - waiting for Article {expected_article}\")\n",
        "                        seeking_article = True\n",
        "                        continue\n",
        "                else:\n",
        "                    warnings.append(f\"Skipping Article {a_no} - backward article number\")\n",
        "                    continue\n",
        "        \n",
        "        # Skip if not in any article\n",
        "        if article_no is None:\n",
        "            continue\n",
        "        \n",
        "        # KHOáº¢N â€” PHáº¢I \"1.\" (sá»‘ + dáº¥u cháº¥m) - STRICT!\n",
        "        m_k = CLAUSE_RE.match(line)\n",
        "        if m_k and m_k.group(1).isdigit():\n",
        "            if article_intro_buf.strip():\n",
        "                flush_article_intro(chunks, article_no, article_title, article_intro_buf,\n",
        "                                    chapter_label, section_label, stats)\n",
        "                article_intro_buf = \"\"; article_has_any_chunk = True\n",
        "            close_clause()\n",
        "            clause_no = int(m_k.group(1))\n",
        "            clause_buf = (m_k.group(2) or \"\").strip()\n",
        "            in_points = False; point_letter = None; point_buf = \"\"\n",
        "            clause_intro_current = None\n",
        "            continue\n",
        "        \n",
        "        # ÄIá»‚M â€” ğŸ”¥ chá»‰ báº¯t Ä‘áº§u chuá»—i Ä‘iá»ƒm náº¿u má»Ÿ Ä‘áº§u lÃ  a) (KEY LOGIC!)\n",
        "        m_p = POINT_RE.match(line)\n",
        "        if m_p and clause_no is not None:\n",
        "            letter = m_p.group(1).lower()\n",
        "            text = (m_p.group(2) or \"\").strip()\n",
        "            \n",
        "            if not in_points:\n",
        "                if letter != 'a':\n",
        "                    # ğŸ”¥ khÃ´ng coi lÃ  Ä‘iá»ƒm -> gá»™p vÃ o ná»™i dung khoáº£n (KEY LOGIC!)\n",
        "                    clause_buf += (\"\\\\n\" if clause_buf else \"\") + f\"{letter}) {text}\"\n",
        "                    continue\n",
        "                # ğŸ”¥ báº¯t Ä‘áº§u chuá»—i Ä‘iá»ƒm vá»›i 'a)' â€” KHÃ”NG flush chunk \"Khoáº£n X\"\n",
        "                # lÆ°u intro khoáº£n Ä‘á»ƒ tiÃªm vÃ o Má»ŒI Ä‘iá»ƒm (KEY FEATURE!)\n",
        "                clause_intro_current = clause_buf.strip() if clause_buf.strip() else None\n",
        "                clause_buf = \"\"\n",
        "                in_points = True\n",
        "                point_letter = letter\n",
        "                point_buf = text\n",
        "                continue\n",
        "            \n",
        "            # Ä‘ang trong chuá»—i Ä‘iá»ƒm: flush Ä‘iá»ƒm trÆ°á»›c, má»Ÿ Ä‘iá»ƒm má»›i\n",
        "            if point_letter:\n",
        "                flush_point(chunks, article_no, article_title, clause_no, point_letter,\n",
        "                            point_buf, chapter_label, section_label, stats, clause_intro_current)\n",
        "            in_points = True\n",
        "            point_letter = letter\n",
        "            point_buf = text\n",
        "            continue\n",
        "        \n",
        "        # Ná»™i dung kÃ©o dÃ i\n",
        "        if clause_no is not None:\n",
        "            if in_points and point_letter:\n",
        "                point_buf += (\"\\\\n\" if point_buf else \"\") + line\n",
        "            else:\n",
        "                clause_buf += (\"\\\\n\" if clause_buf else \"\") + line\n",
        "        else:\n",
        "            # intro Ä‘iá»u (chá»‰ tá»“n táº¡i trÆ°á»›c khi cÃ³ khoáº£n Ä‘áº§u tiÃªn)\n",
        "            article_intro_buf += (\"\\\\n\" if article_intro_buf else \"\") + line\n",
        "    \n",
        "    # Káº¿t thÃºc file\n",
        "    close_clause()\n",
        "    if article_no is not None:\n",
        "        close_article_if_needed()\n",
        "    \n",
        "    # Filter valid chunks\n",
        "    final_chunks = []\n",
        "    for chunk in chunks:\n",
        "        content = chunk['content'].strip()\n",
        "        if len(content) > 50:  # Chá»‰ láº¥y chunks Ä‘á»§ dÃ i\n",
        "            final_chunks.append(chunk)\n",
        "    \n",
        "    print(f\"   ğŸ“Š PROPER advanced parsing results:\")\n",
        "    print(f\"      - Processed {stats['articles']} articles (strict sequence)\")\n",
        "    print(f\"      - Created {stats['article_intro']} article intros\") \n",
        "    print(f\"      - Created {stats['clauses']} clauses\")\n",
        "    print(f\"      - Created {stats['points']} points (with clause intro injection)\")\n",
        "    print(f\"      - Final valid chunks: {len(final_chunks)}\")\n",
        "    \n",
        "    if warnings:\n",
        "        print(f\"   âš ï¸  Warnings: {len(warnings)} issues detected\")\n",
        "        for w in warnings[:3]:  # Show first 3 warnings\n",
        "            print(f\"      - {w}\")\n",
        "    \n",
        "    return final_chunks\n",
        "\n",
        "print(\"âœ… PROPER Advanced law document chunking ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“š Loading law document from LuatHonNhan folder...\n",
            "âœ… Found law file: LuatHonNhan/luat_hon_nhan_va_gia_dinh.docx\n",
            "\n",
            "ğŸ“– Step 1: Reading DOCX file...\n",
            "   Reading file: LuatHonNhan/luat_hon_nhan_va_gia_dinh.docx\n",
            "   âœ… Successfully read 86,564 characters\n",
            "\n",
            "ğŸ”¨ Step 2: PROPER Advanced chunking with 2-pass validation...\n",
            "   ğŸ” 2-Pass advanced parsing with full validation...\n",
            "   âœ… Normalized 608 lines\n",
            "   ğŸ“„ Processing 608 lines...\n",
            "   ğŸ” Pass 1: Pre-scanning structure...\n",
            "      - Pre-scan found 9 chapters: [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "      - Pre-scan found 133 articles: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]...\n",
            "   ğŸ” Pass 2: Strict parsing with sequence validation...\n",
            "   ğŸ“Š PROPER advanced parsing results:\n",
            "      - Processed 133 articles (strict sequence)\n",
            "      - Created 44 article intros\n",
            "      - Created 274 clauses\n",
            "      - Created 80 points (with clause intro injection)\n",
            "      - Final valid chunks: 396\n",
            "\n",
            "ğŸ—‚ï¸ Step 3: Preparing data for evaluation...\n",
            "   âœ… Processed 396 law document chunks\n",
            "   ğŸ“Š Average chunk length: 226 characters\n",
            "\n",
            "ğŸ“ˆ Step 4: Chunk distribution analysis...\n",
            "   ğŸ“Š Chunk distribution by type:\n",
            "      - article_intro: 44 chunks\n",
            "      - clause: 272 chunks\n",
            "      - point: 80 chunks\n",
            "\n",
            "ğŸ” Step 5: Sample chunks preview...\n",
            "\n",
            "   ğŸ“„ Chunk 1: Äiá»u 1 - Pháº¡m vi Ä‘iá»u chá»‰nh\n",
            "      Type: article_intro | Length: 248 chars\n",
            "      Content preview: Äiá»u 1. Pháº¡m vi Ä‘iá»u chá»‰nh\n",
            "Luáº­t nÃ y quy Ä‘á»‹nh cháº¿ Ä‘á»™ hÃ´n nhÃ¢n vÃ  gia Ä‘Ã¬nh; chuáº©n má»±c phÃ¡p lÃ½ cho cÃ¡ch á»©ng xá»­ giá»¯a cÃ¡c thÃ nh viÃªn gia Ä‘Ã¬nh; trÃ¡ch nhiá»‡m ...\n",
            "      Metadata: {'chapter': 'ChÆ°Æ¡ng I', 'section': None, 'article_no': 1, 'article_title': 'Pháº¡m vi Ä‘iá»u chá»‰nh', 'exact_citation': 'Äiá»u 1'}\n",
            "\n",
            "   ğŸ“„ Chunk 2: Äiá»u 2, Khoáº£n 1\n",
            "      Type: clause | Length: 75 chars\n",
            "      Content preview: Khoáº£n 1. HÃ´n nhÃ¢n tá»± nguyá»‡n, tiáº¿n bá»™, má»™t vá»£ má»™t chá»“ng, vá»£ chá»“ng bÃ¬nh Ä‘áº³ng....\n",
            "      Metadata: {'chapter': 'ChÆ°Æ¡ng I', 'section': None, 'article_no': 2, 'article_title': 'Nhá»¯ng nguyÃªn táº¯c cÆ¡ báº£n cá»§a cháº¿ Ä‘á»™ hÃ´n nhÃ¢n vÃ  gia Ä‘Ã¬nh', 'clause_no': 1, 'exact_citation': 'Äiá»u 2 khoáº£n 1'}\n",
            "\n",
            "   ğŸ“„ Chunk 3: Äiá»u 2, Khoáº£n 2\n",
            "      Type: clause | Length: 266 chars\n",
            "      Content preview: Khoáº£n 2. HÃ´n nhÃ¢n giá»¯a cÃ´ng dÃ¢n Viá»‡t Nam thuá»™c cÃ¡c dÃ¢n tá»™c, tÃ´n giÃ¡o, giá»¯a ngÆ°á»i theo tÃ´n giÃ¡o vá»›i ngÆ°á»i khÃ´ng theo tÃ´n giÃ¡o, giá»¯a ngÆ°á»i cÃ³ tÃ­n ngÆ°á»¡ng...\n",
            "      Metadata: {'chapter': 'ChÆ°Æ¡ng I', 'section': None, 'article_no': 2, 'article_title': 'Nhá»¯ng nguyÃªn táº¯c cÆ¡ báº£n cá»§a cháº¿ Ä‘á»™ hÃ´n nhÃ¢n vÃ  gia Ä‘Ã¬nh', 'clause_no': 2, 'exact_citation': 'Äiá»u 2 khoáº£n 2'}\n",
            "\n",
            "âœ… Successfully loaded 396 law document chunks!\n",
            "ğŸ¯ Dataset ready for embedding evaluation (Target: 200-300 chunks)\n"
          ]
        }
      ],
      "source": [
        "# ===== LOAD LAW DOCUMENT DATA =====\n",
        "print(\"ğŸ“š Loading law document from LuatHonNhan folder...\")\n",
        "\n",
        "law_file_path = \"LuatHonNhan/luat_hon_nhan_va_gia_dinh.docx\"\n",
        "if os.path.exists(law_file_path):\n",
        "    print(f\"âœ… Found law file: {law_file_path}\")\n",
        "    \n",
        "    # BÆ°á»›c 1: Äá»c file docx\n",
        "    print(\"\\nğŸ“– Step 1: Reading DOCX file...\")\n",
        "    law_text = read_docx(law_file_path)\n",
        "    \n",
        "    # BÆ°á»›c 2: Chia thÃ nh chunks vá»›i thuáº­t toÃ¡n PROPER ADVANCED \n",
        "    print(\"\\nğŸ”¨ Step 2: PROPER Advanced chunking with 2-pass validation...\")\n",
        "    law_chunks = advanced_chunk_law_document(law_text, max_length=600)\n",
        "    \n",
        "    # BÆ°á»›c 3: Chuáº©n bá»‹ dá»¯ liá»‡u cho Ä‘Ã¡nh giÃ¡\n",
        "    print(\"\\nğŸ—‚ï¸ Step 3: Preparing data for evaluation...\")\n",
        "    law_docs = []\n",
        "    for i, chunk in enumerate(law_chunks):\n",
        "        law_docs.append({\n",
        "            'id': i,\n",
        "            'title': chunk['title'],\n",
        "            'text': chunk['content'],\n",
        "            'length': len(chunk['content']),\n",
        "            'type': chunk['type'],\n",
        "            'metadata': chunk.get('metadata', {})\n",
        "        })\n",
        "    \n",
        "    print(f\"   âœ… Processed {len(law_docs)} law document chunks\")\n",
        "    print(f\"   ğŸ“Š Average chunk length: {np.mean([doc['length'] for doc in law_docs]):.0f} characters\")\n",
        "    \n",
        "    # BÆ°á»›c 4: Thá»‘ng kÃª theo loáº¡i\n",
        "    print(f\"\\nğŸ“ˆ Step 4: Chunk distribution analysis...\")\n",
        "    type_counts = {}\n",
        "    for doc in law_docs:\n",
        "        doc_type = doc['type']\n",
        "        type_counts[doc_type] = type_counts.get(doc_type, 0) + 1\n",
        "    \n",
        "    print(f\"   ğŸ“Š Chunk distribution by type:\")\n",
        "    for chunk_type, count in type_counts.items():\n",
        "        print(f\"      - {chunk_type}: {count} chunks\")\n",
        "    \n",
        "    # BÆ°á»›c 5: Hiá»ƒn thá»‹ examples\n",
        "    print(f\"\\nğŸ” Step 5: Sample chunks preview...\")\n",
        "    for i in range(min(3, len(law_docs))):\n",
        "        doc = law_docs[i]\n",
        "        print(f\"\\n   ğŸ“„ Chunk {i+1}: {doc['title']}\")\n",
        "        print(f\"      Type: {doc['type']} | Length: {doc['length']} chars\")\n",
        "        print(f\"      Content preview: {doc['text'][:150]}...\")\n",
        "        if doc.get('metadata'):\n",
        "            print(f\"      Metadata: {doc['metadata']}\")\n",
        "    \n",
        "    print(f\"\\nâœ… Successfully loaded {len(law_docs)} law document chunks!\")\n",
        "    print(f\"ğŸ¯ Dataset ready for embedding evaluation (Target: 200-300 chunks)\")\n",
        "        \n",
        "else:\n",
        "    print(f\"âŒ File {law_file_path} not found!\")\n",
        "    print(\"   Please make sure the LuatHonNhan folder is in the correct location\")\n",
        "    print(f\"   Expected path: {os.path.abspath(law_file_path)}\")\n",
        "    law_docs = []\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Chuáº©n bá»‹ cÃ¡c query tá»« benchmark\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¤– Setting up models for evaluation...\n",
            "âœ… Prepared 6 models for evaluation:\n",
            "   1. minhquan6203/paraphrase-vietnamese-law\n",
            "      Type: transformers | Max Length: 512 tokens\n",
            "      Description: MÃ´ hÃ¬nh Sentence Similarity Ä‘Ã£ fine tune trÃªn bá»™ luáº­t phÃ¡p Viá»‡t Nam\n",
            "\n",
            "   2. sentence-transformers/paraphrase-multilingual-mpnet-base-v2\n",
            "      Type: sentence_transformers | Max Length: 512 tokens\n",
            "      Description: MÃ´ hÃ¬nh cÆ¡ sá»Ÿ Ä‘a ngÃ´n ngá»¯ (base model)\n",
            "\n",
            "   3. huyhuy123/paraphrase-vietnamese-law-ALQAC\n",
            "      Type: transformers | Max Length: 512 tokens\n",
            "      Description: Fine-tuned trá»±c tiáº¿p trÃªn mÃ´ hÃ¬nh paraphrase-vietnamese-law\n",
            "\n",
            "   4. namnguyenba2003/Vietnamese_Law_Embedding_finetuned_v3_256dims\n",
            "      Type: transformers | Max Length: 512 tokens\n",
            "      Description: MÃ´ hÃ¬nh embedding luáº­t Viá»‡t Nam vá»›i 256 dimensions\n",
            "\n",
            "   5. maiduchuy321/vietnamese-bi-encoder-fine-tuning-for-law-chatbot\n",
            "      Type: transformers | Max Length: 512 tokens\n",
            "      Description: Bi-encoder cho chatbot luáº­t Viá»‡t Nam\n",
            "\n",
            "   6. BAAI/bge-m3\n",
            "      Type: sentence_transformers | Max Length: 8192 tokens\n",
            "      Description: BGE-M3 - mÃ´ hÃ¬nh multilingual embedding hiá»‡n Ä‘áº¡i\n",
            "\n",
            "ğŸ¯ All models support â‰¥512 tokens as required!\n",
            "ğŸ’¾ Embeddings will be stored in RAM (not vector database)\n"
          ]
        }
      ],
      "source": [
        "# ===== MODELS TO EVALUATE =====\n",
        "print(\"ğŸ¤– Setting up models for evaluation...\")\n",
        "\n",
        "models_to_evaluate = [\n",
        "    {\n",
        "        'name': 'minhquan6203/paraphrase-vietnamese-law',\n",
        "        'type': 'transformers',  \n",
        "        'description': 'MÃ´ hÃ¬nh Sentence Similarity Ä‘Ã£ fine tune trÃªn bá»™ luáº­t phÃ¡p Viá»‡t Nam',\n",
        "        'max_length': 512\n",
        "    },\n",
        "    {\n",
        "        'name': 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2',\n",
        "        'type': 'sentence_transformers',\n",
        "        'description': 'MÃ´ hÃ¬nh cÆ¡ sá»Ÿ Ä‘a ngÃ´n ngá»¯ (base model)',\n",
        "        'max_length': 512\n",
        "    },\n",
        "    {\n",
        "        'name': 'huyhuy123/paraphrase-vietnamese-law-ALQAC',\n",
        "        'type': 'transformers',\n",
        "        'description': 'Fine-tuned trá»±c tiáº¿p trÃªn mÃ´ hÃ¬nh paraphrase-vietnamese-law',\n",
        "        'max_length': 512\n",
        "    },\n",
        "    {\n",
        "        'name': 'namnguyenba2003/Vietnamese_Law_Embedding_finetuned_v3_256dims',\n",
        "        'type': 'transformers',\n",
        "        'description': 'MÃ´ hÃ¬nh embedding luáº­t Viá»‡t Nam vá»›i 256 dimensions',\n",
        "        'max_length': 512\n",
        "    },\n",
        "    {\n",
        "        'name': 'maiduchuy321/vietnamese-bi-encoder-fine-tuning-for-law-chatbot',\n",
        "        'type': 'transformers',\n",
        "        'description': 'Bi-encoder cho chatbot luáº­t Viá»‡t Nam',\n",
        "        'max_length': 512\n",
        "    },\n",
        "    {\n",
        "        'name': 'BAAI/bge-m3',\n",
        "        'type': 'sentence_transformers',\n",
        "        'description': 'BGE-M3 - mÃ´ hÃ¬nh multilingual embedding hiá»‡n Ä‘áº¡i',\n",
        "        'max_length': 8192\n",
        "    }\n",
        "]\n",
        "\n",
        "print(f\"âœ… Prepared {len(models_to_evaluate)} models for evaluation:\")\n",
        "for i, model in enumerate(models_to_evaluate):\n",
        "    print(f\"   {i+1}. {model['name']}\")\n",
        "    print(f\"      Type: {model['type']} | Max Length: {model['max_length']} tokens\")\n",
        "    print(f\"      Description: {model['description']}\")\n",
        "    print()\n",
        "\n",
        "print(\"ğŸ¯ All models support â‰¥512 tokens as required!\")\n",
        "print(\"ğŸ’¾ Embeddings will be stored in RAM (not vector database)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prepared 20 benchmark queries\n",
            "Sample queries:\n",
            "1. NgÆ°á»i bá»‹ bá»‡nh tÃ¢m tháº§n lÃ  ngÆ°á»i máº¥t nÄƒng lá»±c hÃ nh vi dÃ¢n sá»± lÃ  Ä‘Ãºng hay sai?\n",
            "2. Sá»± thá»a thuáº­n cá»§a cÃ¡c bÃªn khÃ´ng vi pháº¡m Ä‘iá»u cáº¥m cá»§a phÃ¡p luáº­t, khÃ´ng trÃ¡i Ä‘áº¡o Ä‘á»©c xÃ£ há»™i thÃ¬ Ä‘Æ°á»£c gá»i lÃ  há»£p Ä‘á»“ng lÃ  Ä‘Ãºng hay sai?\n",
            "3. Tiá»n phÃºng viáº¿ng Ä‘Ã¡m ma cÅ©ng thuá»™c di sáº£n thá»«a káº¿ cá»§a ngÆ°á»i cháº¿t Ä‘á»ƒ láº¡i lÃ  Ä‘Ãºng hay sai?\n",
            "4. CÃ¡ nhÃ¢n Ä‘Æ°á»£c hÆ°á»Ÿng di sáº£n thá»«a káº¿ pháº£i tráº£ ná»£ thay cho ngÆ°á»i Ä‘á»ƒ láº¡i di sáº£n lÃ  Ä‘Ãºng hay sai?\n",
            "5. Há»£p Ä‘á»“ng vÃ´ hiá»‡u lÃ  há»£p Ä‘á»“ng vi pháº¡m phÃ¡p luáº­t lÃ  Ä‘Ãºng hay sai?\n"
          ]
        }
      ],
      "source": [
        "# CÃ¡c query tá»« benchmark\n",
        "benchmark_queries = [\n",
        "    \"NgÆ°á»i bá»‹ bá»‡nh tÃ¢m tháº§n lÃ  ngÆ°á»i máº¥t nÄƒng lá»±c hÃ nh vi dÃ¢n sá»± lÃ  Ä‘Ãºng hay sai?\",\n",
        "    \"Sá»± thá»a thuáº­n cá»§a cÃ¡c bÃªn khÃ´ng vi pháº¡m Ä‘iá»u cáº¥m cá»§a phÃ¡p luáº­t, khÃ´ng trÃ¡i Ä‘áº¡o Ä‘á»©c xÃ£ há»™i thÃ¬ Ä‘Æ°á»£c gá»i lÃ  há»£p Ä‘á»“ng lÃ  Ä‘Ãºng hay sai?\",\n",
        "    \"Tiá»n phÃºng viáº¿ng Ä‘Ã¡m ma cÅ©ng thuá»™c di sáº£n thá»«a káº¿ cá»§a ngÆ°á»i cháº¿t Ä‘á»ƒ láº¡i lÃ  Ä‘Ãºng hay sai?\",\n",
        "    \"CÃ¡ nhÃ¢n Ä‘Æ°á»£c hÆ°á»Ÿng di sáº£n thá»«a káº¿ pháº£i tráº£ ná»£ thay cho ngÆ°á»i Ä‘á»ƒ láº¡i di sáº£n lÃ  Ä‘Ãºng hay sai?\",\n",
        "    \"Há»£p Ä‘á»“ng vÃ´ hiá»‡u lÃ  há»£p Ä‘á»“ng vi pháº¡m phÃ¡p luáº­t lÃ  Ä‘Ãºng hay sai?\",\n",
        "    \n",
        "    # CÃ¡c query vá» Luáº­t HÃ´n nhÃ¢n & Gia Ä‘Ã¬nh (phÃ¹ há»£p vá»›i data LuatHonNhan)\n",
        "    \"Hoa lá»£i, lá»£i tá»©c phÃ¡t sinh tá»« tÃ i sáº£n riÃªng cá»§a má»™t bÃªn vá»£ hoáº·c chá»“ng sáº½ lÃ  tÃ i sáº£n chung náº¿u hoa lá»£i, lá»£i tá»©c Ä‘Ã³ lÃ  nguá»“n sá»‘ng duy nháº¥t cá»§a gia Ä‘Ã¬nh.\",\n",
        "    \"Há»™i LiÃªn hiá»‡p phá»¥ ná»¯ cÃ³ quyá»n yÃªu cáº§u TÃ²a Ã¡n ra quyáº¿t Ä‘á»‹nh há»§y káº¿t hÃ´n trÃ¡i phÃ¡p luáº­t do vi pháº¡m sá»± tá»± nguyá»‡n.\",\n",
        "    \"HÃ´n nhÃ¢n chá»‰ cháº¥m dá»©t khi má»™t bÃªn vá»£, chá»“ng cháº¿t.\",\n",
        "    \"Káº¿t hÃ´n cÃ³ yáº¿u tá»‘ nÆ°á»›c ngoÃ i cÃ³ thá»ƒ Ä‘Äƒng kÃ½ táº¡i UBND cáº¥p xÃ£.\",\n",
        "    \"Khi cha máº¹ khÃ´ng thá»ƒ nuÃ´i dÆ°á»¡ng, cáº¥p dÆ°á»¡ng Ä‘Æ°á»£c cho con, thÃ¬ Ã´ng bÃ  pháº£i cÃ³ nghÄ©a vá»¥ nuÃ´i dÆ°á»¡ng hoáº·c cáº¥p dÆ°á»¡ng cho chÃ¡u.\",\n",
        "    \"Khi hÃ´n nhÃ¢n cháº¥m dá»©t, má»i quyá»n vÃ  nghÄ©a vá»¥ giá»¯a nhá»¯ng ngÆ°á»i Ä‘Ã£ tá»«ng lÃ  vá»£ chá»“ng cÅ©ng cháº¥m dá»©t.\",\n",
        "    \"Khi vá»£ chá»“ng ly hÃ´n, con dÆ°á»›i 36 thÃ¡ng tuá»•i Ä‘Æ°á»£c giao cho ngÆ°á»i vá»£ trá»±c tiáº¿p nuÃ´i dÆ°á»¡ng.\",\n",
        "    \"Khi vá»£ hoáº·c chá»“ng thá»±c hiá»‡n nhá»¯ng giao dá»‹ch phá»¥c vá»¥ cho nhu cáº§u thiáº¿t yáº¿u cá»§a gia Ä‘Ã¬nh mÃ  khÃ´ng cÃ³ sá»± Ä‘á»“ng Ã½ cá»§a bÃªn kia thÃ¬ ngÆ°á»i thá»±c hiá»‡n giao dá»‹ch Ä‘Ã³ pháº£i thanh toÃ¡n báº±ng tÃ i sáº£n riÃªng cá»§a mÃ¬nh.\",\n",
        "    \"Khi khÃ´ng sá»‘ng chung cÃ¹ng vá»›i cha máº¹, con Ä‘Ã£ thÃ nh niÃªn cÃ³ kháº£ nÄƒng lao Ä‘á»™ng pháº£i cáº¥p dÆ°á»¡ng cho cha máº¹.\",\n",
        "    \"Chá»‰ UBND cáº¥p tá»‰nh nÆ¡i cÃ´ng dÃ¢n Viá»‡t Nam cÆ° trÃº má»›i cÃ³ tháº©m quyá»n Ä‘Äƒng kÃ½ viá»‡c káº¿t hÃ´n giá»¯a cÃ´ng dÃ¢n Viá»‡t Nam vá»›i ngÆ°á»i nÆ°á»›c ngoÃ i.\",\n",
        "    \n",
        "    # ThÃªm cÃ¡c query khÃ¡c Ä‘á»ƒ test Ä‘a dáº¡ng hÆ¡n\n",
        "    \"Äiá»u kiá»‡n káº¿t hÃ´n cá»§a nam vÃ  ná»¯ theo phÃ¡p luáº­t Viá»‡t Nam lÃ  gÃ¬?\",\n",
        "    \"TÃ i sáº£n nÃ o Ä‘Æ°á»£c coi lÃ  tÃ i sáº£n chung cá»§a vá»£ chá»“ng?\",\n",
        "    \"Thá»§ tá»¥c ly hÃ´n táº¡i tÃ²a Ã¡n Ä‘Æ°á»£c quy Ä‘á»‹nh nhÆ° tháº¿ nÃ o?\",\n",
        "    \"Quyá»n vÃ  nghÄ©a vá»¥ cá»§a cha máº¹ Ä‘á»‘i vá»›i con chÆ°a thÃ nh niÃªn?\",\n",
        "    \"TrÆ°á»ng há»£p nÃ o vá»£ chá»“ng cÃ³ thá»ƒ thá»a thuáº­n vá» cháº¿ Ä‘á»™ tÃ i sáº£n?\"\n",
        "]\n",
        "\n",
        "print(f\"Prepared {len(benchmark_queries)} benchmark queries\")\n",
        "print(\"Sample queries:\")\n",
        "for i, query in enumerate(benchmark_queries[:5]):\n",
        "    print(f\"{i+1}. {query}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Danh sÃ¡ch cÃ¡c mÃ´ hÃ¬nh cáº§n Ä‘Ã¡nh giÃ¡ (â‰¥512 tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Search vÃ  Evaluation Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ” Setting up search and evaluation functions...\n",
            "âœ… Search and evaluation functions ready!\n"
          ]
        }
      ],
      "source": [
        "# ===== SEARCH AND EVALUATION FUNCTIONS =====\n",
        "print(\"ğŸ” Setting up search and evaluation functions...\")\n",
        "\n",
        "def search_top_k(query_embedding, doc_embeddings, k=15):\n",
        "    \"\"\"\n",
        "    TÃ¬m top-k documents tÆ°Æ¡ng tá»± nháº¥t vá»›i query (lÆ°u trÃªn RAM)\n",
        "    \n",
        "    Input:\n",
        "    - query_embedding: vector embedding cá»§a query (1D array)\n",
        "    - doc_embeddings: matrix embeddings cá»§a documents (2D array)\n",
        "    - k: sá»‘ lÆ°á»£ng top results cáº§n láº¥y\n",
        "    \n",
        "    Output:\n",
        "    - top_indices: indices cá»§a top-k documents\n",
        "    - top_scores: similarity scores cá»§a top-k documents\n",
        "    \"\"\"\n",
        "    # TÃ­nh cosine similarity giá»¯a query vÃ  táº¥t cáº£ documents\n",
        "    similarities = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
        "    \n",
        "    # Sáº¯p xáº¿p theo Ä‘á»™ tÆ°Æ¡ng tá»± giáº£m dáº§n vÃ  láº¥y top-k\n",
        "    top_indices = np.argsort(similarities)[::-1][:k]\n",
        "    top_scores = similarities[top_indices]\n",
        "    \n",
        "    return top_indices, top_scores\n",
        "\n",
        "def calculate_metrics(scores, threshold_07=0.7, threshold_05=0.5):\n",
        "    \"\"\"\n",
        "    TÃ­nh toÃ¡n cÃ¡c metrics Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng retrieval\n",
        "    \n",
        "    Input:\n",
        "    - scores: array of similarity scores\n",
        "    - threshold_07: ngÆ°á»¡ng cao (0.7)\n",
        "    - threshold_05: ngÆ°á»¡ng tháº¥p (0.5)\n",
        "    \n",
        "    Output:\n",
        "    - dict chá»©a cÃ¡c metrics\n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"max_score\": float(np.max(scores)),\n",
        "        \"avg_top3\": float(np.mean(scores[:3])) if len(scores) >= 3 else float(np.mean(scores)),\n",
        "        \"avg_top5\": float(np.mean(scores[:5])) if len(scores) >= 5 else float(np.mean(scores)),\n",
        "        \"avg_top10\": float(np.mean(scores[:10])) if len(scores) >= 10 else float(np.mean(scores)),\n",
        "        \"avg_all\": float(np.mean(scores)),\n",
        "        \"scores_above_07\": int(np.sum(scores >= threshold_07)),\n",
        "        \"scores_above_05\": int(np.sum(scores >= threshold_05)),\n",
        "        \"min_score\": float(np.min(scores))\n",
        "    }\n",
        "\n",
        "def display_search_results(query, law_docs, top_indices, top_scores, max_display=5):\n",
        "    \"\"\"\n",
        "    Hiá»ƒn thá»‹ káº¿t quáº£ search má»™t cÃ¡ch rÃµ rÃ ng\n",
        "    \n",
        "    Input:\n",
        "    - query: cÃ¢u há»i query\n",
        "    - law_docs: list of law documents\n",
        "    - top_indices: indices cá»§a top results\n",
        "    - top_scores: similarity scores\n",
        "    - max_display: sá»‘ lÆ°á»£ng results tá»‘i Ä‘a Ä‘á»ƒ hiá»ƒn thá»‹\n",
        "    \"\"\"\n",
        "    print(f\"ğŸ“ Query: {query}\")\n",
        "    print(f\"ğŸ¯ Top {min(max_display, len(top_indices))} Results:\")\n",
        "    \n",
        "    for i in range(min(max_display, len(top_indices))):\n",
        "        idx = top_indices[i]\n",
        "        score = top_scores[i]\n",
        "        doc = law_docs[idx]\n",
        "        \n",
        "        print(f\"\\n   {i+1}. Score: {score:.4f} | {doc['title']}\")\n",
        "        print(f\"      Type: {doc['type']} | Length: {doc['length']} chars\")\n",
        "        print(f\"      Content: {doc['text'][:200]}...\")\n",
        "        \n",
        "        # Hiá»ƒn thá»‹ metadata náº¿u cÃ³\n",
        "        if doc.get('metadata') and doc['metadata']:\n",
        "            metadata_str = \", \".join([f\"{k}: {v}\" for k, v in doc['metadata'].items()])\n",
        "            print(f\"      Metadata: {metadata_str}\")\n",
        "\n",
        "print(\"âœ… Search and evaluation functions ready!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Model Evaluation Engine\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ§ª Setting up model evaluation engine...\n",
            "âœ… Model evaluation engine ready!\n"
          ]
        }
      ],
      "source": [
        "# ===== MODEL EVALUATION ENGINE =====\n",
        "print(\"ğŸ§ª Setting up model evaluation engine...\")\n",
        "\n",
        "def evaluate_single_model(model_info, law_docs, queries, top_k=15, show_detailed_results=True):\n",
        "    \"\"\"\n",
        "    ÄÃ¡nh giÃ¡ má»™t mÃ´ hÃ¬nh embedding trÃªn dataset luáº­t vÃ  benchmark queries\n",
        "    \n",
        "    Input:\n",
        "    - model_info: dict chá»©a thÃ´ng tin model (name, type, max_length...)\n",
        "    - law_docs: list of law documents\n",
        "    - queries: list of benchmark queries\n",
        "    - top_k: sá»‘ lÆ°á»£ng top results Ä‘á»ƒ Ä‘Ã¡nh giÃ¡\n",
        "    - show_detailed_results: cÃ³ hiá»ƒn thá»‹ káº¿t quáº£ chi tiáº¿t khÃ´ng\n",
        "    \n",
        "    Output:\n",
        "    - dict chá»©a results vÃ  metrics cá»§a model\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"ğŸ” EVALUATING MODEL: {model_info['name']}\")\n",
        "    print(f\"ğŸ“ Description: {model_info['description']}\")\n",
        "    print(f\"ğŸ”§ Type: {model_info['type']} | Max Length: {model_info['max_length']} tokens\")\n",
        "    print(f\"{'='*80}\")\n",
        "    \n",
        "    try:\n",
        "        # BÆ°á»›c 1: Chuáº©n bá»‹ texts\n",
        "        doc_texts = [doc['text'] for doc in law_docs]\n",
        "        print(f\"\\nğŸ“š Step 1: Prepared {len(doc_texts)} document texts\")\n",
        "        \n",
        "        # BÆ°á»›c 2: Encode documents\n",
        "        print(f\"\\nğŸ”¨ Step 2: Encoding documents...\")\n",
        "        if model_info['type'] == 'sentence_transformers':\n",
        "            doc_embeddings = encode_with_sentence_transformers(\n",
        "                doc_texts, \n",
        "                model_info['name'], \n",
        "                batch_size=16\n",
        "            )\n",
        "        else:\n",
        "            doc_embeddings = encode_with_transformers(\n",
        "                doc_texts, \n",
        "                model_info['name'], \n",
        "                max_length=model_info['max_length'],\n",
        "                batch_size=16\n",
        "            )\n",
        "        \n",
        "        print(f\"   âœ… Document embeddings shape: {doc_embeddings.shape}\")\n",
        "        \n",
        "        # BÆ°á»›c 3: Encode queries\n",
        "        print(f\"\\nğŸ” Step 3: Encoding queries...\")\n",
        "        if model_info['type'] == 'sentence_transformers':\n",
        "            query_embeddings = encode_with_sentence_transformers(\n",
        "                queries, \n",
        "                model_info['name'], \n",
        "                batch_size=16\n",
        "            )\n",
        "        else:\n",
        "            query_embeddings = encode_with_transformers(\n",
        "                queries, \n",
        "                model_info['name'], \n",
        "                max_length=model_info['max_length'],\n",
        "                batch_size=16\n",
        "            )\n",
        "        \n",
        "        print(f\"   âœ… Query embeddings shape: {query_embeddings.shape}\")\n",
        "        \n",
        "        # BÆ°á»›c 4: Evaluate tá»«ng query\n",
        "        print(f\"\\nğŸ“Š Step 4: Evaluating {len(queries)} queries...\")\n",
        "        query_results = []\n",
        "        all_metrics = []\n",
        "        \n",
        "        for i, query in enumerate(queries):\n",
        "            print(f\"\\n   ğŸ” Query {i+1}/{len(queries)}\")\n",
        "            \n",
        "            # Search top-k documents\n",
        "            top_indices, top_scores = search_top_k(\n",
        "                query_embeddings[i], \n",
        "                doc_embeddings, \n",
        "                k=top_k\n",
        "            )\n",
        "            \n",
        "            # Calculate metrics\n",
        "            metrics = calculate_metrics(top_scores)\n",
        "            all_metrics.append(metrics)\n",
        "            \n",
        "            # Store results\n",
        "            query_result = {\n",
        "                'query': query,\n",
        "                'query_id': i,\n",
        "                'top_indices': top_indices.tolist(),\n",
        "                'top_scores': top_scores.tolist(),\n",
        "                'metrics': metrics\n",
        "            }\n",
        "            query_results.append(query_result)\n",
        "            \n",
        "            # Show detailed results for first few queries\n",
        "            if show_detailed_results and i < 3:\n",
        "                display_search_results(query, law_docs, top_indices, top_scores, max_display=3)\n",
        "                print(f\"      ğŸ“ˆ Metrics: Max={metrics['max_score']:.4f}, Avg_top5={metrics['avg_top5']:.4f}, Above_0.7={metrics['scores_above_07']}\")\n",
        "        \n",
        "        # BÆ°á»›c 5: Aggregate metrics\n",
        "        print(f\"\\nğŸ“ˆ Step 5: Aggregating metrics...\")\n",
        "        \n",
        "        # Calculate average metrics across all queries\n",
        "        avg_metrics = {}\n",
        "        metric_keys = all_metrics[0].keys()\n",
        "        for key in metric_keys:\n",
        "            if key.startswith('scores_above'):\n",
        "                # For count metrics, sum then average\n",
        "                avg_metrics[f\"avg_{key}\"] = np.mean([m[key] for m in all_metrics])\n",
        "            else:\n",
        "                # For score metrics, just average\n",
        "                avg_metrics[f\"avg_{key}\"] = np.mean([m[key] for m in all_metrics])\n",
        "        \n",
        "        # Final result\n",
        "        final_result = {\n",
        "            'model_name': model_info['name'],\n",
        "            'model_type': model_info['type'],\n",
        "            'model_description': model_info['description'],\n",
        "            'max_length': model_info['max_length'],\n",
        "            'num_queries': len(queries),\n",
        "            'num_documents': len(law_docs),\n",
        "            'top_k': top_k,\n",
        "            'query_results': query_results,\n",
        "            'aggregated_metrics': avg_metrics,\n",
        "            'evaluation_success': True\n",
        "        }\n",
        "        \n",
        "        # Print summary\n",
        "        print(f\"\\nâœ… EVALUATION COMPLETED SUCCESSFULLY!\")\n",
        "        print(f\"   ğŸ“Š Average Results:\")\n",
        "        print(f\"      - Avg Max Score: {avg_metrics['avg_max_score']:.4f}\")\n",
        "        print(f\"      - Avg Top-5 Score: {avg_metrics['avg_avg_top5']:.4f}\")\n",
        "        print(f\"      - Avg Above 0.7: {avg_metrics['avg_scores_above_07']:.1f}\")\n",
        "        print(f\"      - Avg Above 0.5: {avg_metrics['avg_scores_above_05']:.1f}\")\n",
        "        \n",
        "        return final_result\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\\nâŒ EVALUATION FAILED: {str(e)}\")\n",
        "        return {\n",
        "            'model_name': model_info['name'],\n",
        "            'model_type': model_info['type'],\n",
        "            'error': str(e),\n",
        "            'evaluation_success': False\n",
        "        }\n",
        "\n",
        "print(\"âœ… Model evaluation engine ready!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Run Evaluation cho táº¥t cáº£ Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ Starting evaluation for all models...\n",
            "âœ… Ready to evaluate with:\n",
            "   ğŸ“š Documents: 396 law chunks\n",
            "   â“ Queries: 20 benchmark questions\n",
            "   ğŸ¤– Models: 6 models to test\n",
            "   ğŸ¯ Top-K: 15 results per query\n",
            "\n",
            "ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– \n",
            "ğŸ¤– EVALUATING MODEL 1/6\n",
            "ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– \n",
            "\n",
            "================================================================================\n",
            "ğŸ” EVALUATING MODEL: minhquan6203/paraphrase-vietnamese-law\n",
            "ğŸ“ Description: MÃ´ hÃ¬nh Sentence Similarity Ä‘Ã£ fine tune trÃªn bá»™ luáº­t phÃ¡p Viá»‡t Nam\n",
            "ğŸ”§ Type: transformers | Max Length: 512 tokens\n",
            "================================================================================\n",
            "\n",
            "ğŸ“š Step 1: Prepared 396 document texts\n",
            "\n",
            "ğŸ”¨ Step 2: Encoding documents...\n",
            "Loading model: minhquan6203/paraphrase-vietnamese-law\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Encoding: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 10.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… Generated 396 embeddings, stored in RAM\n",
            "   âœ… Document embeddings shape: (396, 768)\n",
            "\n",
            "ğŸ” Step 3: Encoding queries...\n",
            "Loading model: minhquan6203/paraphrase-vietnamese-law\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Encoding: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 32.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… Generated 20 embeddings, stored in RAM\n",
            "   âœ… Query embeddings shape: (20, 768)\n",
            "\n",
            "ğŸ“Š Step 4: Evaluating 20 queries...\n",
            "\n",
            "   ğŸ” Query 1/20\n",
            "ğŸ“ Query: NgÆ°á»i bá»‹ bá»‡nh tÃ¢m tháº§n lÃ  ngÆ°á»i máº¥t nÄƒng lá»±c hÃ nh vi dÃ¢n sá»± lÃ  Ä‘Ãºng hay sai?\n",
            "ğŸ¯ Top 3 Results:\n",
            "\n",
            "   1. Score: 0.3415 | Äiá»u 5, Khoáº£n 2, Äiá»ƒm h)\n",
            "      Type: point | Length: 59 chars\n",
            "      Content: Khoáº£n 2, Ä‘iá»ƒm h) Cáº¥m cÃ¡c hÃ nh vi sau Ä‘Ã¢y:\n",
            "Báº¡o lá»±c gia Ä‘Ã¬nh;...\n",
            "      Metadata: chapter: ChÆ°Æ¡ng I, section: None, article_no: 5, article_title: Báº£o vá»‡ cháº¿ Ä‘á»™ hÃ´n nhÃ¢n vÃ  gia Ä‘Ã¬nh, clause_no: 2, point_letter: h, exact_citation: Äiá»u 5 khoáº£n 2 Ä‘iá»ƒm h), clause_intro: Cáº¥m cÃ¡c hÃ nh vi sau Ä‘Ã¢y:\n",
            "\n",
            "   2. Score: 0.3082 | Äiá»u 74 - Bá»“i thÆ°á»ng thiá»‡t háº¡i do con gÃ¢y ra\n",
            "      Type: article_intro | Length: 187 chars\n",
            "      Content: Äiá»u 74. Bá»“i thÆ°á»ng thiá»‡t háº¡i do con gÃ¢y ra\n",
            "Cha máº¹ pháº£i bá»“i thÆ°á»ng thiá»‡t háº¡i do con chÆ°a thÃ nh niÃªn, con Ä‘Ã£ thÃ nh niÃªn máº¥t nÄƒng lá»±c hÃ nh vi dÃ¢n sá»± gÃ¢y ra theo quy Ä‘á»‹nh cá»§a Bá»™ luáº­t dÃ¢n sá»±....\n",
            "      Metadata: chapter: ChÆ°Æ¡ng V, section: Má»¥c 1 â€“ QUYá»€N VÃ€ NGHÄ¨A Vá»¤ GIá»®A CHA Máº¸ VÃ€ CON, article_no: 74, article_title: Bá»“i thÆ°á»ng thiá»‡t háº¡i do con gÃ¢y ra, exact_citation: Äiá»u 74\n",
            "\n",
            "   3. Score: 0.2932 | Äiá»u 3, Khoáº£n 17\n",
            "      Type: clause | Length: 137 chars\n",
            "      Content: Khoáº£n 17. Nhá»¯ng ngÆ°á»i cÃ¹ng dÃ²ng mÃ¡u vá» trá»±c há»‡ lÃ  nhá»¯ng ngÆ°á»i cÃ³ quan há»‡ huyáº¿t thá»‘ng, trong Ä‘Ã³, ngÆ°á»i nÃ y sinh ra ngÆ°á»i kia káº¿ tiáº¿p nhau....\n",
            "      Metadata: chapter: ChÆ°Æ¡ng I, section: None, article_no: 3, article_title: Giáº£i thÃ­ch tá»« ngá»¯, clause_no: 17, exact_citation: Äiá»u 3 khoáº£n 17\n",
            "      ğŸ“ˆ Metrics: Max=0.3415, Avg_top5=0.3018, Above_0.7=0\n",
            "\n",
            "   ğŸ” Query 2/20\n",
            "ğŸ“ Query: Sá»± thá»a thuáº­n cá»§a cÃ¡c bÃªn khÃ´ng vi pháº¡m Ä‘iá»u cáº¥m cá»§a phÃ¡p luáº­t, khÃ´ng trÃ¡i Ä‘áº¡o Ä‘á»©c xÃ£ há»™i thÃ¬ Ä‘Æ°á»£c gá»i lÃ  há»£p Ä‘á»“ng lÃ  Ä‘Ãºng hay sai?\n",
            "ğŸ¯ Top 3 Results:\n",
            "\n",
            "   1. Score: 0.7058 | Äiá»u 49, Khoáº£n 2\n",
            "      Type: clause | Length: 146 chars\n",
            "      Content: Khoáº£n 2. HÃ¬nh thá»©c sá»­a Ä‘á»•i, bá»• sung ná»™i dung cá»§a thá»a thuáº­n vá» cháº¿ Ä‘á»™ tÃ i sáº£n theo thá»a thuáº­n Ä‘Æ°á»£c Ã¡p dá»¥ng theo quy Ä‘á»‹nh táº¡i Äiá»u 47 cá»§a Luáº­t nÃ y....\n",
            "      Metadata: chapter: ChÆ°Æ¡ng III, section: Má»¥c 3 â€“ CHáº¾ Äá»˜ TÃ€I Sáº¢N Cá»¦A Vá»¢ CHá»’NG, article_no: 49, article_title: Sá»­a Ä‘á»•i, bá»• sung ná»™i dung cá»§a thá»a thuáº­n vá» cháº¿ Ä‘á»™ tÃ i sáº£n cá»§a vá»£ chá»“ng, clause_no: 2, exact_citation: Äiá»u 49 khoáº£n 2\n",
            "\n",
            "   2. Score: 0.6969 | Äiá»u 12, Khoáº£n 3\n",
            "      Type: clause | Length: 115 chars\n",
            "      Content: Khoáº£n 3. Quan há»‡ tÃ i sáº£n, nghÄ©a vá»¥ vÃ  há»£p Ä‘á»“ng giá»¯a cÃ¡c bÃªn Ä‘Æ°á»£c giáº£i quyáº¿t theo quy Ä‘á»‹nh táº¡i Äiá»u 16 cá»§a Luáº­t nÃ y....\n",
            "      Metadata: chapter: ChÆ°Æ¡ng II, section: None, article_no: 12, article_title: Háº­u quáº£ phÃ¡p lÃ½ cá»§a viá»‡c há»§y káº¿t hÃ´n trÃ¡i phÃ¡p luáº­t, clause_no: 3, exact_citation: Äiá»u 12 khoáº£n 3\n",
            "\n",
            "   3. Score: 0.6722 | Äiá»u 48, Khoáº£n 1, Äiá»ƒm d)\n",
            "      Type: point | Length: 102 chars\n",
            "      Content: Khoáº£n 1, Ä‘iá»ƒm d) Ná»™i dung cÆ¡ báº£n cá»§a thá»a thuáº­n vá» cháº¿ Ä‘á»™ tÃ i sáº£n bao gá»“m:\n",
            "Ná»™i dung khÃ¡c cÃ³ liÃªn quan....\n",
            "      Metadata: chapter: ChÆ°Æ¡ng III, section: Má»¥c 3 â€“ CHáº¾ Äá»˜ TÃ€I Sáº¢N Cá»¦A Vá»¢ CHá»’NG, article_no: 48, article_title: Ná»™i dung cÆ¡ báº£n cá»§a thá»a thuáº­n vá» cháº¿ Ä‘á»™ tÃ i sáº£n cá»§a vá»£ chá»“ng, clause_no: 1, point_letter: d, exact_citation: Äiá»u 48 khoáº£n 1 Ä‘iá»ƒm d), clause_intro: Ná»™i dung cÆ¡ báº£n cá»§a thá»a thuáº­n vá» cháº¿ Ä‘á»™ tÃ i sáº£n bao gá»“m:\n",
            "      ğŸ“ˆ Metrics: Max=0.7058, Avg_top5=0.6613, Above_0.7=1\n",
            "\n",
            "   ğŸ” Query 3/20\n",
            "ğŸ“ Query: Tiá»n phÃºng viáº¿ng Ä‘Ã¡m ma cÅ©ng thuá»™c di sáº£n thá»«a káº¿ cá»§a ngÆ°á»i cháº¿t Ä‘á»ƒ láº¡i lÃ  Ä‘Ãºng hay sai?\n",
            "ğŸ¯ Top 3 Results:\n",
            "\n",
            "   1. Score: 0.9016 | Äiá»u 66, Khoáº£n 3\n",
            "      Type: clause | Length: 221 chars\n",
            "      Content: Khoáº£n 3. Trong trÆ°á»ng há»£p viá»‡c chia di sáº£n áº£nh hÆ°á»Ÿng nghiÃªm trá»ng Ä‘áº¿n Ä‘á»i sá»‘ng cá»§a vá»£ hoáº·c chá»“ng cÃ²n sá»‘ng, gia Ä‘Ã¬nh thÃ¬ vá»£, chá»“ng cÃ²n sá»‘ng cÃ³ quyá»n yÃªu cáº§u TÃ²a Ã¡n háº¡n cháº¿ phÃ¢n chia di sáº£n theo quy Ä‘á»‹n...\n",
            "      Metadata: chapter: ChÆ°Æ¡ng IV, section: Má»¥c 2 â€“ HÃ”N NHÃ‚N CHáº¤M Dá»¨T DO Vá»¢, CHá»’NG CHáº¾T HOáº¶C Bá»Š TÃ’A ÃN TUYÃŠN Bá» LÃ€ ÄÃƒ CHáº¾T, article_no: 66, article_title: Giáº£i quyáº¿t tÃ i sáº£n cá»§a vá»£ chá»“ng trong trÆ°á»ng há»£p má»™t bÃªn cháº¿t hoáº·c bá»‹ TÃ²a Ã¡n tuyÃªn bá»‘ lÃ  Ä‘Ã£ cháº¿t, clause_no: 3, exact_citation: Äiá»u 66 khoáº£n 3\n",
            "\n",
            "   2. Score: 0.8939 | Äiá»u 66, Khoáº£n 1\n",
            "      Type: clause | Length: 256 chars\n",
            "      Content: Khoáº£n 1. Khi má»™t bÃªn vá»£, chá»“ng cháº¿t hoáº·c bá»‹ TÃ²a Ã¡n tuyÃªn bá»‘ lÃ  Ä‘Ã£ cháº¿t thÃ¬ bÃªn cÃ²n sá»‘ng quáº£n lÃ½ tÃ i sáº£n chung cá»§a vá»£ chá»“ng, trá»« trÆ°á»ng há»£p trong di chÃºc cÃ³ chá»‰ Ä‘á»‹nh ngÆ°á»i khÃ¡c quáº£n lÃ½ di sáº£n hoáº·c nhá»¯n...\n",
            "      Metadata: chapter: ChÆ°Æ¡ng IV, section: Má»¥c 2 â€“ HÃ”N NHÃ‚N CHáº¤M Dá»¨T DO Vá»¢, CHá»’NG CHáº¾T HOáº¶C Bá»Š TÃ’A ÃN TUYÃŠN Bá» LÃ€ ÄÃƒ CHáº¾T, article_no: 66, article_title: Giáº£i quyáº¿t tÃ i sáº£n cá»§a vá»£ chá»“ng trong trÆ°á»ng há»£p má»™t bÃªn cháº¿t hoáº·c bá»‹ TÃ²a Ã¡n tuyÃªn bá»‘ lÃ  Ä‘Ã£ cháº¿t, clause_no: 1, exact_citation: Äiá»u 66 khoáº£n 1\n",
            "\n",
            "   3. Score: 0.8129 | Äiá»u 66, Khoáº£n 2\n",
            "      Type: clause | Length: 258 chars\n",
            "      Content: Khoáº£n 2. Khi cÃ³ yÃªu cáº§u vá» chia di sáº£n thÃ¬ tÃ i sáº£n chung cá»§a vá»£ chá»“ng Ä‘Æ°á»£c chia Ä‘Ã´i, trá»« trÆ°á»ng há»£p vá»£ chá»“ng cÃ³ thá»a thuáº­n vá» cháº¿ Ä‘á»™ tÃ i sáº£n. Pháº§n tÃ i sáº£n cá»§a vá»£, chá»“ng cháº¿t hoáº·c bá»‹ TÃ²a Ã¡n tuyÃªn bá»‘ lÃ ...\n",
            "      Metadata: chapter: ChÆ°Æ¡ng IV, section: Má»¥c 2 â€“ HÃ”N NHÃ‚N CHáº¤M Dá»¨T DO Vá»¢, CHá»’NG CHáº¾T HOáº¶C Bá»Š TÃ’A ÃN TUYÃŠN Bá» LÃ€ ÄÃƒ CHáº¾T, article_no: 66, article_title: Giáº£i quyáº¿t tÃ i sáº£n cá»§a vá»£ chá»“ng trong trÆ°á»ng há»£p má»™t bÃªn cháº¿t hoáº·c bá»‹ TÃ²a Ã¡n tuyÃªn bá»‘ lÃ  Ä‘Ã£ cháº¿t, clause_no: 2, exact_citation: Äiá»u 66 khoáº£n 2\n",
            "      ğŸ“ˆ Metrics: Max=0.9016, Avg_top5=0.8197, Above_0.7=4\n",
            "\n",
            "   ğŸ” Query 4/20\n",
            "\n",
            "   ğŸ” Query 5/20\n",
            "\n",
            "   ğŸ” Query 6/20\n",
            "\n",
            "   ğŸ” Query 7/20\n",
            "\n",
            "   ğŸ” Query 8/20\n",
            "\n",
            "   ğŸ” Query 9/20\n",
            "\n",
            "   ğŸ” Query 10/20\n",
            "\n",
            "   ğŸ” Query 11/20\n",
            "\n",
            "   ğŸ” Query 12/20\n",
            "\n",
            "   ğŸ” Query 13/20\n",
            "\n",
            "   ğŸ” Query 14/20\n",
            "\n",
            "   ğŸ” Query 15/20\n",
            "\n",
            "   ğŸ” Query 16/20\n",
            "\n",
            "   ğŸ” Query 17/20\n",
            "\n",
            "   ğŸ” Query 18/20\n",
            "\n",
            "   ğŸ” Query 19/20\n",
            "\n",
            "   ğŸ” Query 20/20\n",
            "\n",
            "ğŸ“ˆ Step 5: Aggregating metrics...\n",
            "\n",
            "âœ… EVALUATION COMPLETED SUCCESSFULLY!\n",
            "   ğŸ“Š Average Results:\n",
            "      - Avg Max Score: 0.9034\n",
            "      - Avg Top-5 Score: 0.8780\n",
            "      - Avg Above 0.7: 11.4\n",
            "      - Avg Above 0.5: 12.8\n",
            "âœ… Model 1 evaluation completed successfully!\n",
            "â³ Waiting 2 seconds before next model...\n",
            "\n",
            "ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– \n",
            "ğŸ¤– EVALUATING MODEL 2/6\n",
            "ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– \n",
            "\n",
            "================================================================================\n",
            "ğŸ” EVALUATING MODEL: sentence-transformers/paraphrase-multilingual-mpnet-base-v2\n",
            "ğŸ“ Description: MÃ´ hÃ¬nh cÆ¡ sá»Ÿ Ä‘a ngÃ´n ngá»¯ (base model)\n",
            "ğŸ”§ Type: sentence_transformers | Max Length: 512 tokens\n",
            "================================================================================\n",
            "\n",
            "ğŸ“š Step 1: Prepared 396 document texts\n",
            "\n",
            "ğŸ”¨ Step 2: Encoding documents...\n",
            "Loading model: sentence-transformers/paraphrase-multilingual-mpnet-base-v2\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "162e6c3c8d784b3498431a03d672e288",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… Generated 396 embeddings, stored in RAM\n",
            "   âœ… Document embeddings shape: (396, 768)\n",
            "\n",
            "ğŸ” Step 3: Encoding queries...\n",
            "Loading model: sentence-transformers/paraphrase-multilingual-mpnet-base-v2\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99ec758f4148480193b41b3817cfd4e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… Generated 20 embeddings, stored in RAM\n",
            "   âœ… Query embeddings shape: (20, 768)\n",
            "\n",
            "ğŸ“Š Step 4: Evaluating 20 queries...\n",
            "\n",
            "   ğŸ” Query 1/20\n",
            "ğŸ“ Query: NgÆ°á»i bá»‹ bá»‡nh tÃ¢m tháº§n lÃ  ngÆ°á»i máº¥t nÄƒng lá»±c hÃ nh vi dÃ¢n sá»± lÃ  Ä‘Ãºng hay sai?\n",
            "ğŸ¯ Top 3 Results:\n",
            "\n",
            "   1. Score: 0.5186 | Äiá»u 69, Khoáº£n 3\n",
            "      Type: clause | Length: 135 chars\n",
            "      Content: Khoáº£n 3. GiÃ¡m há»™ hoáº·c Ä‘áº¡i diá»‡n theo quy Ä‘á»‹nh cá»§a Bá»™ luáº­t dÃ¢n sá»± cho con chÆ°a thÃ nh niÃªn, con Ä‘Ã£ thÃ nh niÃªn máº¥t nÄƒng lá»±c hÃ nh vi dÃ¢n sá»±....\n",
            "      Metadata: chapter: ChÆ°Æ¡ng V, section: Má»¥c 1 â€“ QUYá»€N VÃ€ NGHÄ¨A Vá»¤ GIá»®A CHA Máº¸ VÃ€ CON, article_no: 69, article_title: NghÄ©a vá»¥ vÃ  quyá»n cá»§a cha máº¹, clause_no: 3, exact_citation: Äiá»u 69 khoáº£n 3\n",
            "\n",
            "   2. Score: 0.5023 | Äiá»u 51, Khoáº£n 2\n",
            "      Type: clause | Length: 337 chars\n",
            "      Content: Khoáº£n 2. Cha, máº¹, ngÆ°á»i thÃ¢n thÃ­ch khÃ¡c cÃ³ quyá»n yÃªu cáº§u TÃ²a Ã¡n giáº£i quyáº¿t ly hÃ´n khi má»™t bÃªn vá»£, chá»“ng do bá»‹ bá»‡nh tÃ¢m tháº§n hoáº·c máº¯c bá»‡nh khÃ¡c mÃ  khÃ´ng thá»ƒ nháº­n thá»©c, lÃ m chá»§ Ä‘Æ°á»£c hÃ nh vi cá»§a mÃ¬nh, Ä‘á»“...\n",
            "      Metadata: chapter: ChÆ°Æ¡ng IV, section: Má»¥c 1 â€“ LY HÃ”N, article_no: 51, article_title: Quyá»n yÃªu cáº§u giáº£i quyáº¿t ly hÃ´n, clause_no: 2, exact_citation: Äiá»u 51 khoáº£n 2\n",
            "\n",
            "   3. Score: 0.4844 | Äiá»u 77, Khoáº£n 3\n",
            "      Type: clause | Length: 140 chars\n",
            "      Content: Khoáº£n 3. Trong trÆ°á»ng há»£p con Ä‘Ã£ thÃ nh niÃªn máº¥t nÄƒng lá»±c hÃ nh vi dÃ¢n sá»± thÃ¬ viá»‡c Ä‘á»‹nh Ä‘oáº¡t tÃ i sáº£n riÃªng cá»§a con do ngÆ°á»i giÃ¡m há»™ thá»±c hiá»‡n....\n",
            "      Metadata: chapter: ChÆ°Æ¡ng V, section: Má»¥c 1 â€“ QUYá»€N VÃ€ NGHÄ¨A Vá»¤ GIá»®A CHA Máº¸ VÃ€ CON, article_no: 77, article_title: Äá»‹nh Ä‘oáº¡t tÃ i sáº£n riÃªng cá»§a con chÆ°a thÃ nh niÃªn, con Ä‘Ã£ thÃ nh niÃªn máº¥t nÄƒng lá»±c hÃ nh vi dÃ¢n sá»±, clause_no: 3, exact_citation: Äiá»u 77 khoáº£n 3\n",
            "      ğŸ“ˆ Metrics: Max=0.5186, Avg_top5=0.4899, Above_0.7=0\n",
            "\n",
            "   ğŸ” Query 2/20\n",
            "ğŸ“ Query: Sá»± thá»a thuáº­n cá»§a cÃ¡c bÃªn khÃ´ng vi pháº¡m Ä‘iá»u cáº¥m cá»§a phÃ¡p luáº­t, khÃ´ng trÃ¡i Ä‘áº¡o Ä‘á»©c xÃ£ há»™i thÃ¬ Ä‘Æ°á»£c gá»i lÃ  há»£p Ä‘á»“ng lÃ  Ä‘Ãºng hay sai?\n",
            "ğŸ¯ Top 3 Results:\n",
            "\n",
            "   1. Score: 0.6735 | Äiá»u 16, Khoáº£n 1\n",
            "      Type: clause | Length: 296 chars\n",
            "      Content: Khoáº£n 1. Quan há»‡ tÃ i sáº£n, nghÄ©a vá»¥ vÃ  há»£p Ä‘á»“ng cá»§a nam, ná»¯ chung sá»‘ng vá»›i nhau nhÆ° vá»£ chá»“ng mÃ  khÃ´ng Ä‘Äƒng kÃ½ káº¿t hÃ´n Ä‘Æ°á»£c giáº£i quyáº¿t theo thá»a thuáº­n giá»¯a cÃ¡c bÃªn; trong trÆ°á»ng há»£p khÃ´ng cÃ³ thá»a thuáº­n ...\n",
            "      Metadata: chapter: ChÆ°Æ¡ng II, section: None, article_no: 16, article_title: Giáº£i quyáº¿t quan há»‡ tÃ i sáº£n, nghÄ©a vá»¥ vÃ  há»£p Ä‘á»“ng cá»§a nam, ná»¯ chung sá»‘ng vá»›i nhau nhÆ° vá»£ chá»“ng mÃ  khÃ´ng Ä‘Äƒng kÃ½ káº¿t hÃ´n, clause_no: 1, exact_citation: Äiá»u 16 khoáº£n 1\n",
            "\n",
            "   2. Score: 0.6356 | Äiá»u 37, Khoáº£n 1\n",
            "      Type: clause | Length: 175 chars\n",
            "      Content: Khoáº£n 1. NghÄ©a vá»¥ phÃ¡t sinh tá»« giao dá»‹ch do vá»£ chá»“ng cÃ¹ng thá»a thuáº­n xÃ¡c láº­p, nghÄ©a vá»¥ bá»“i thÆ°á»ng thiá»‡t háº¡i mÃ  theo quy Ä‘á»‹nh cá»§a phÃ¡p luáº­t vá»£ chá»“ng cÃ¹ng pháº£i chá»‹u trÃ¡ch nhiá»‡m;...\n",
            "      Metadata: chapter: ChÆ°Æ¡ng III, section: Má»¥c 3 â€“ CHáº¾ Äá»˜ TÃ€I Sáº¢N Cá»¦A Vá»¢ CHá»’NG, article_no: 37, article_title: NghÄ©a vá»¥ chung vá» tÃ i sáº£n cá»§a vá»£ chá»“ng, clause_no: 1, exact_citation: Äiá»u 37 khoáº£n 1\n",
            "\n",
            "   3. Score: 0.6211 | Äiá»u 50, Khoáº£n 1, Äiá»ƒm a)\n",
            "      Type: point | Length: 244 chars\n",
            "      Content: Khoáº£n 1, Ä‘iá»ƒm a) Thá»a thuáº­n vá» cháº¿ Ä‘á»™ tÃ i sáº£n cá»§a vá»£ chá»“ng bá»‹ TÃ²a Ã¡n tuyÃªn bá»‘ vÃ´ hiá»‡u khi thuá»™c má»™t trong cÃ¡c trÆ°á»ng há»£p sau Ä‘Ã¢y:\n",
            "KhÃ´ng tuÃ¢n thá»§ Ä‘iá»u kiá»‡n cÃ³ hiá»‡u lá»±c cá»§a giao dá»‹ch Ä‘Æ°á»£c quy Ä‘á»‹nh táº¡i B...\n",
            "      Metadata: chapter: ChÆ°Æ¡ng III, section: Má»¥c 3 â€“ CHáº¾ Äá»˜ TÃ€I Sáº¢N Cá»¦A Vá»¢ CHá»’NG, article_no: 50, article_title: Thá»a thuáº­n vá» cháº¿ Ä‘á»™ tÃ i sáº£n cá»§a vá»£ chá»“ng bá»‹ vÃ´ hiá»‡u, clause_no: 1, point_letter: a, exact_citation: Äiá»u 50 khoáº£n 1 Ä‘iá»ƒm a), clause_intro: Thá»a thuáº­n vá» cháº¿ Ä‘á»™ tÃ i sáº£n cá»§a vá»£ chá»“ng bá»‹ TÃ²a Ã¡n tuyÃªn bá»‘ vÃ´ hiá»‡u khi thuá»™c má»™t trong cÃ¡c trÆ°á»ng há»£p sau Ä‘Ã¢y:\n",
            "      ğŸ“ˆ Metrics: Max=0.6735, Avg_top5=0.6327, Above_0.7=0\n",
            "\n",
            "   ğŸ” Query 3/20\n",
            "ğŸ“ Query: Tiá»n phÃºng viáº¿ng Ä‘Ã¡m ma cÅ©ng thuá»™c di sáº£n thá»«a káº¿ cá»§a ngÆ°á»i cháº¿t Ä‘á»ƒ láº¡i lÃ  Ä‘Ãºng hay sai?\n",
            "ğŸ¯ Top 3 Results:\n",
            "\n",
            "   1. Score: 0.6119 | Äiá»u 66, Khoáº£n 1\n",
            "      Type: clause | Length: 256 chars\n",
            "      Content: Khoáº£n 1. Khi má»™t bÃªn vá»£, chá»“ng cháº¿t hoáº·c bá»‹ TÃ²a Ã¡n tuyÃªn bá»‘ lÃ  Ä‘Ã£ cháº¿t thÃ¬ bÃªn cÃ²n sá»‘ng quáº£n lÃ½ tÃ i sáº£n chung cá»§a vá»£ chá»“ng, trá»« trÆ°á»ng há»£p trong di chÃºc cÃ³ chá»‰ Ä‘á»‹nh ngÆ°á»i khÃ¡c quáº£n lÃ½ di sáº£n hoáº·c nhá»¯n...\n",
            "      Metadata: chapter: ChÆ°Æ¡ng IV, section: Má»¥c 2 â€“ HÃ”N NHÃ‚N CHáº¤M Dá»¨T DO Vá»¢, CHá»’NG CHáº¾T HOáº¶C Bá»Š TÃ’A ÃN TUYÃŠN Bá» LÃ€ ÄÃƒ CHáº¾T, article_no: 66, article_title: Giáº£i quyáº¿t tÃ i sáº£n cá»§a vá»£ chá»“ng trong trÆ°á»ng há»£p má»™t bÃªn cháº¿t hoáº·c bá»‹ TÃ²a Ã¡n tuyÃªn bá»‘ lÃ  Ä‘Ã£ cháº¿t, clause_no: 1, exact_citation: Äiá»u 66 khoáº£n 1\n",
            "\n",
            "   2. Score: 0.5780 | Äiá»u 118, Khoáº£n 4\n",
            "      Type: clause | Length: 56 chars\n",
            "      Content: Khoáº£n 4. NgÆ°á»i cáº¥p dÆ°á»¡ng hoáº·c ngÆ°á»i Ä‘Æ°á»£c cáº¥p dÆ°á»¡ng cháº¿t;...\n",
            "      Metadata: chapter: ChÆ°Æ¡ng VII, section: None, article_no: 118, article_title: Cháº¥m dá»©t nghÄ©a vá»¥ cáº¥p dÆ°á»¡ng, clause_no: 4, exact_citation: Äiá»u 118 khoáº£n 4\n",
            "\n",
            "   3. Score: 0.5650 | Äiá»u 67, Khoáº£n 2, Äiá»ƒm b)\n",
            "      Type: point | Length: 328 chars\n",
            "      Content: Khoáº£n 2, Ä‘iá»ƒm b) Quan há»‡ tÃ i sáº£n cá»§a ngÆ°á»i bá»‹ tuyÃªn bá»‘ lÃ  Ä‘Ã£ cháº¿t trá»Ÿ vá» vá»›i ngÆ°á»i vá»£ hoáº·c chá»“ng Ä‘Æ°á»£c giáº£i quyáº¿t nhÆ° sau:\n",
            "Trong trÆ°á»ng há»£p hÃ´n nhÃ¢n khÃ´ng Ä‘Æ°á»£c khÃ´i phá»¥c thÃ¬ tÃ i sáº£n cÃ³ Ä‘Æ°á»£c trÆ°á»›c khi q...\n",
            "      Metadata: chapter: ChÆ°Æ¡ng IV, section: Má»¥c 2 â€“ HÃ”N NHÃ‚N CHáº¤M Dá»¨T DO Vá»¢, CHá»’NG CHáº¾T HOáº¶C Bá»Š TÃ’A ÃN TUYÃŠN Bá» LÃ€ ÄÃƒ CHáº¾T, article_no: 67, article_title: Quan há»‡ nhÃ¢n thÃ¢n, tÃ i sáº£n khi vá»£, chá»“ng bá»‹ tuyÃªn bá»‘ lÃ  Ä‘Ã£ cháº¿t mÃ  trá»Ÿ vá», clause_no: 2, point_letter: b, exact_citation: Äiá»u 67 khoáº£n 2 Ä‘iá»ƒm b), clause_intro: Quan há»‡ tÃ i sáº£n cá»§a ngÆ°á»i bá»‹ tuyÃªn bá»‘ lÃ  Ä‘Ã£ cháº¿t trá»Ÿ vá» vá»›i ngÆ°á»i vá»£ hoáº·c chá»“ng Ä‘Æ°á»£c giáº£i quyáº¿t nhÆ° sau:\n",
            "      ğŸ“ˆ Metrics: Max=0.6119, Avg_top5=0.5722, Above_0.7=0\n",
            "\n",
            "   ğŸ” Query 4/20\n",
            "\n",
            "   ğŸ” Query 5/20\n",
            "\n",
            "   ğŸ” Query 6/20\n",
            "\n",
            "   ğŸ” Query 7/20\n",
            "\n",
            "   ğŸ” Query 8/20\n",
            "\n",
            "   ğŸ” Query 9/20\n",
            "\n",
            "   ğŸ” Query 10/20\n",
            "\n",
            "   ğŸ” Query 11/20\n",
            "\n",
            "   ğŸ” Query 12/20\n",
            "\n",
            "   ğŸ” Query 13/20\n",
            "\n",
            "   ğŸ” Query 14/20\n",
            "\n",
            "   ğŸ” Query 15/20\n",
            "\n",
            "   ğŸ” Query 16/20\n",
            "\n",
            "   ğŸ” Query 17/20\n",
            "\n",
            "   ğŸ” Query 18/20\n",
            "\n",
            "   ğŸ” Query 19/20\n",
            "\n",
            "   ğŸ” Query 20/20\n",
            "\n",
            "ğŸ“ˆ Step 5: Aggregating metrics...\n",
            "\n",
            "âœ… EVALUATION COMPLETED SUCCESSFULLY!\n",
            "   ğŸ“Š Average Results:\n",
            "      - Avg Max Score: 0.7647\n",
            "      - Avg Top-5 Score: 0.7310\n",
            "      - Avg Above 0.7: 8.0\n",
            "      - Avg Above 0.5: 14.1\n",
            "âœ… Model 2 evaluation completed successfully!\n",
            "â³ Waiting 2 seconds before next model...\n",
            "\n",
            "ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– \n",
            "ğŸ¤– EVALUATING MODEL 3/6\n",
            "ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– \n",
            "\n",
            "================================================================================\n",
            "ğŸ” EVALUATING MODEL: huyhuy123/paraphrase-vietnamese-law-ALQAC\n",
            "ğŸ“ Description: Fine-tuned trá»±c tiáº¿p trÃªn mÃ´ hÃ¬nh paraphrase-vietnamese-law\n",
            "ğŸ”§ Type: transformers | Max Length: 512 tokens\n",
            "================================================================================\n",
            "\n",
            "ğŸ“š Step 1: Prepared 396 document texts\n",
            "\n",
            "ğŸ”¨ Step 2: Encoding documents...\n",
            "Loading model: huyhuy123/paraphrase-vietnamese-law-ALQAC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Encoding: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 10.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… Generated 396 embeddings, stored in RAM\n",
            "   âœ… Document embeddings shape: (396, 768)\n",
            "\n",
            "ğŸ” Step 3: Encoding queries...\n",
            "Loading model: huyhuy123/paraphrase-vietnamese-law-ALQAC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Encoding: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 30.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… Generated 20 embeddings, stored in RAM\n",
            "   âœ… Query embeddings shape: (20, 768)\n",
            "\n",
            "ğŸ“Š Step 4: Evaluating 20 queries...\n",
            "\n",
            "   ğŸ” Query 1/20\n",
            "\n",
            "   ğŸ” Query 2/20\n",
            "\n",
            "   ğŸ” Query 3/20\n",
            "\n",
            "   ğŸ” Query 4/20\n",
            "\n",
            "   ğŸ” Query 5/20\n",
            "\n",
            "   ğŸ” Query 6/20\n",
            "\n",
            "   ğŸ” Query 7/20\n",
            "\n",
            "   ğŸ” Query 8/20\n",
            "\n",
            "   ğŸ” Query 9/20\n",
            "\n",
            "   ğŸ” Query 10/20\n",
            "\n",
            "   ğŸ” Query 11/20\n",
            "\n",
            "   ğŸ” Query 12/20\n",
            "\n",
            "   ğŸ” Query 13/20\n",
            "\n",
            "   ğŸ” Query 14/20\n",
            "\n",
            "   ğŸ” Query 15/20\n",
            "\n",
            "   ğŸ” Query 16/20\n",
            "\n",
            "   ğŸ” Query 17/20\n",
            "\n",
            "   ğŸ” Query 18/20\n",
            "\n",
            "   ğŸ” Query 19/20\n",
            "\n",
            "   ğŸ” Query 20/20\n",
            "\n",
            "ğŸ“ˆ Step 5: Aggregating metrics...\n",
            "\n",
            "âœ… EVALUATION COMPLETED SUCCESSFULLY!\n",
            "   ğŸ“Š Average Results:\n",
            "      - Avg Max Score: 0.8711\n",
            "      - Avg Top-5 Score: 0.7927\n",
            "      - Avg Above 0.7: 6.6\n",
            "      - Avg Above 0.5: 13.2\n",
            "âœ… Model 3 evaluation completed successfully!\n",
            "â³ Waiting 2 seconds before next model...\n",
            "\n",
            "ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– \n",
            "ğŸ¤– EVALUATING MODEL 4/6\n",
            "ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– \n",
            "\n",
            "================================================================================\n",
            "ğŸ” EVALUATING MODEL: namnguyenba2003/Vietnamese_Law_Embedding_finetuned_v3_256dims\n",
            "ğŸ“ Description: MÃ´ hÃ¬nh embedding luáº­t Viá»‡t Nam vá»›i 256 dimensions\n",
            "ğŸ”§ Type: transformers | Max Length: 512 tokens\n",
            "================================================================================\n",
            "\n",
            "ğŸ“š Step 1: Prepared 396 document texts\n",
            "\n",
            "ğŸ”¨ Step 2: Encoding documents...\n",
            "Loading model: namnguyenba2003/Vietnamese_Law_Embedding_finetuned_v3_256dims\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Encoding: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [01:52<00:00,  4.51s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… Generated 396 embeddings, stored in RAM\n",
            "   âœ… Document embeddings shape: (396, 1024)\n",
            "\n",
            "ğŸ” Step 3: Encoding queries...\n",
            "Loading model: namnguyenba2003/Vietnamese_Law_Embedding_finetuned_v3_256dims\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Encoding: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.32s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… Generated 20 embeddings, stored in RAM\n",
            "   âœ… Query embeddings shape: (20, 1024)\n",
            "\n",
            "ğŸ“Š Step 4: Evaluating 20 queries...\n",
            "\n",
            "   ğŸ” Query 1/20\n",
            "\n",
            "   ğŸ” Query 2/20\n",
            "\n",
            "   ğŸ” Query 3/20\n",
            "\n",
            "   ğŸ” Query 4/20\n",
            "\n",
            "   ğŸ” Query 5/20\n",
            "\n",
            "   ğŸ” Query 6/20\n",
            "\n",
            "   ğŸ” Query 7/20\n",
            "\n",
            "   ğŸ” Query 8/20\n",
            "\n",
            "   ğŸ” Query 9/20\n",
            "\n",
            "   ğŸ” Query 10/20\n",
            "\n",
            "   ğŸ” Query 11/20\n",
            "\n",
            "   ğŸ” Query 12/20\n",
            "\n",
            "   ğŸ” Query 13/20\n",
            "\n",
            "   ğŸ” Query 14/20\n",
            "\n",
            "   ğŸ” Query 15/20\n",
            "\n",
            "   ğŸ” Query 16/20\n",
            "\n",
            "   ğŸ” Query 17/20\n",
            "\n",
            "   ğŸ” Query 18/20\n",
            "\n",
            "   ğŸ” Query 19/20\n",
            "\n",
            "   ğŸ” Query 20/20\n",
            "\n",
            "ğŸ“ˆ Step 5: Aggregating metrics...\n",
            "\n",
            "âœ… EVALUATION COMPLETED SUCCESSFULLY!\n",
            "   ğŸ“Š Average Results:\n",
            "      - Avg Max Score: 0.8577\n",
            "      - Avg Top-5 Score: 0.8287\n",
            "      - Avg Above 0.7: 12.5\n",
            "      - Avg Above 0.5: 15.0\n",
            "âœ… Model 4 evaluation completed successfully!\n",
            "â³ Waiting 2 seconds before next model...\n",
            "\n",
            "ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– \n",
            "ğŸ¤– EVALUATING MODEL 5/6\n",
            "ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– \n",
            "\n",
            "================================================================================\n",
            "ğŸ” EVALUATING MODEL: maiduchuy321/vietnamese-bi-encoder-fine-tuning-for-law-chatbot\n",
            "ğŸ“ Description: Bi-encoder cho chatbot luáº­t Viá»‡t Nam\n",
            "ğŸ”§ Type: transformers | Max Length: 512 tokens\n",
            "================================================================================\n",
            "\n",
            "ğŸ“š Step 1: Prepared 396 document texts\n",
            "\n",
            "ğŸ”¨ Step 2: Encoding documents...\n",
            "Loading model: maiduchuy321/vietnamese-bi-encoder-fine-tuning-for-law-chatbot\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Encoding: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:03<00:00,  7.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… Generated 396 embeddings, stored in RAM\n",
            "   âœ… Document embeddings shape: (396, 768)\n",
            "\n",
            "ğŸ” Step 3: Encoding queries...\n",
            "Loading model: maiduchuy321/vietnamese-bi-encoder-fine-tuning-for-law-chatbot\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Encoding: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 28.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… Generated 20 embeddings, stored in RAM\n",
            "   âœ… Query embeddings shape: (20, 768)\n",
            "\n",
            "ğŸ“Š Step 4: Evaluating 20 queries...\n",
            "\n",
            "   ğŸ” Query 1/20\n",
            "\n",
            "   ğŸ” Query 2/20\n",
            "\n",
            "   ğŸ” Query 3/20\n",
            "\n",
            "   ğŸ” Query 4/20\n",
            "\n",
            "   ğŸ” Query 5/20\n",
            "\n",
            "   ğŸ” Query 6/20\n",
            "\n",
            "   ğŸ” Query 7/20\n",
            "\n",
            "   ğŸ” Query 8/20\n",
            "\n",
            "   ğŸ” Query 9/20\n",
            "\n",
            "   ğŸ” Query 10/20\n",
            "\n",
            "   ğŸ” Query 11/20\n",
            "\n",
            "   ğŸ” Query 12/20\n",
            "\n",
            "   ğŸ” Query 13/20\n",
            "\n",
            "   ğŸ” Query 14/20\n",
            "\n",
            "   ğŸ” Query 15/20\n",
            "\n",
            "   ğŸ” Query 16/20\n",
            "\n",
            "   ğŸ” Query 17/20\n",
            "\n",
            "   ğŸ” Query 18/20\n",
            "\n",
            "   ğŸ” Query 19/20\n",
            "\n",
            "   ğŸ” Query 20/20\n",
            "\n",
            "ğŸ“ˆ Step 5: Aggregating metrics...\n",
            "\n",
            "âœ… EVALUATION COMPLETED SUCCESSFULLY!\n",
            "   ğŸ“Š Average Results:\n",
            "      - Avg Max Score: 0.6379\n",
            "      - Avg Top-5 Score: 0.5981\n",
            "      - Avg Above 0.7: 2.2\n",
            "      - Avg Above 0.5: 10.6\n",
            "âœ… Model 5 evaluation completed successfully!\n",
            "â³ Waiting 2 seconds before next model...\n",
            "\n",
            "ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– \n",
            "ğŸ¤– EVALUATING MODEL 6/6\n",
            "ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– ğŸ¤– \n",
            "\n",
            "================================================================================\n",
            "ğŸ” EVALUATING MODEL: BAAI/bge-m3\n",
            "ğŸ“ Description: BGE-M3 - mÃ´ hÃ¬nh multilingual embedding hiá»‡n Ä‘áº¡i\n",
            "ğŸ”§ Type: sentence_transformers | Max Length: 8192 tokens\n",
            "================================================================================\n",
            "\n",
            "ğŸ“š Step 1: Prepared 396 document texts\n",
            "\n",
            "ğŸ”¨ Step 2: Encoding documents...\n",
            "Loading model: BAAI/bge-m3\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "596bca93c109479e9f08b12444d548b7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… Generated 396 embeddings, stored in RAM\n",
            "   âœ… Document embeddings shape: (396, 1024)\n",
            "\n",
            "ğŸ” Step 3: Encoding queries...\n",
            "Loading model: BAAI/bge-m3\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "505b261994e14b20a815163e601432e9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… Generated 20 embeddings, stored in RAM\n",
            "   âœ… Query embeddings shape: (20, 1024)\n",
            "\n",
            "ğŸ“Š Step 4: Evaluating 20 queries...\n",
            "\n",
            "   ğŸ” Query 1/20\n",
            "\n",
            "   ğŸ” Query 2/20\n",
            "\n",
            "   ğŸ” Query 3/20\n",
            "\n",
            "   ğŸ” Query 4/20\n",
            "\n",
            "   ğŸ” Query 5/20\n",
            "\n",
            "   ğŸ” Query 6/20\n",
            "\n",
            "   ğŸ” Query 7/20\n",
            "\n",
            "   ğŸ” Query 8/20\n",
            "\n",
            "   ğŸ” Query 9/20\n",
            "\n",
            "   ğŸ” Query 10/20\n",
            "\n",
            "   ğŸ” Query 11/20\n",
            "\n",
            "   ğŸ” Query 12/20\n",
            "\n",
            "   ğŸ” Query 13/20\n",
            "\n",
            "   ğŸ” Query 14/20\n",
            "\n",
            "   ğŸ” Query 15/20\n",
            "\n",
            "   ğŸ” Query 16/20\n",
            "\n",
            "   ğŸ” Query 17/20\n",
            "\n",
            "   ğŸ” Query 18/20\n",
            "\n",
            "   ğŸ” Query 19/20\n",
            "\n",
            "   ğŸ” Query 20/20\n",
            "\n",
            "ğŸ“ˆ Step 5: Aggregating metrics...\n",
            "\n",
            "âœ… EVALUATION COMPLETED SUCCESSFULLY!\n",
            "   ğŸ“Š Average Results:\n",
            "      - Avg Max Score: 0.7181\n",
            "      - Avg Top-5 Score: 0.6819\n",
            "      - Avg Above 0.7: 4.7\n",
            "      - Avg Above 0.5: 12.9\n",
            "âœ… Model 6 evaluation completed successfully!\n",
            "\n",
            "====================================================================================================\n",
            "ğŸ‰ EVALUATION SUMMARY\n",
            "====================================================================================================\n",
            "âœ… Successful evaluations: 6\n",
            "âŒ Failed evaluations: 0\n",
            "ğŸ“Š Total models evaluated: 6\n",
            "\n",
            "ğŸ“ˆ Quick Performance Preview:\n",
            "   ğŸ¤– paraphrase-vietnamese-law\n",
            "      Max Score: 0.9034 | Top-5: 0.8780 | Above 0.7: 11.4\n",
            "   ğŸ¤– paraphrase-multilingual-mpnet-base-v2\n",
            "      Max Score: 0.7647 | Top-5: 0.7310 | Above 0.7: 8.0\n",
            "   ğŸ¤– paraphrase-vietnamese-law-ALQAC\n",
            "      Max Score: 0.8711 | Top-5: 0.7927 | Above 0.7: 6.6\n",
            "   ğŸ¤– Vietnamese_Law_Embedding_finetuned_v3_256dims\n",
            "      Max Score: 0.8577 | Top-5: 0.8287 | Above 0.7: 12.5\n",
            "   ğŸ¤– vietnamese-bi-encoder-fine-tuning-for-law-chatbot\n",
            "      Max Score: 0.6379 | Top-5: 0.5981 | Above 0.7: 2.2\n",
            "   ğŸ¤– bge-m3\n",
            "      Max Score: 0.7181 | Top-5: 0.6819 | Above 0.7: 4.7\n",
            "\n",
            "ğŸ¯ Ready for detailed analysis and report generation!\n",
            "ğŸ“Š Variable 'evaluation_results' contains all results for further analysis.\n"
          ]
        }
      ],
      "source": [
        "# ===== RUN EVALUATION FOR ALL MODELS =====\n",
        "print(\"ğŸš€ Starting evaluation for all models...\")\n",
        "\n",
        "# Check available data\n",
        "if not law_docs:\n",
        "    print(\"âŒ Error: No law documents loaded! Please run the data loading cells first.\")\n",
        "    evaluation_results = []\n",
        "else:\n",
        "    print(f\"âœ… Ready to evaluate with:\")\n",
        "    print(f\"   ğŸ“š Documents: {len(law_docs)} law chunks\")\n",
        "    print(f\"   â“ Queries: {len(benchmark_queries)} benchmark questions\")\n",
        "    print(f\"   ğŸ¤– Models: {len(models_to_evaluate)} models to test\")\n",
        "    print(f\"   ğŸ¯ Top-K: 15 results per query\")\n",
        "    \n",
        "    # Storage for results\n",
        "    evaluation_results = []\n",
        "    successful_evaluations = 0\n",
        "    failed_evaluations = 0\n",
        "    \n",
        "    # Evaluate each model\n",
        "    for i, model_info in enumerate(models_to_evaluate):\n",
        "        print(f\"\\n{'ğŸ¤– '*20}\")\n",
        "        print(f\"ğŸ¤– EVALUATING MODEL {i+1}/{len(models_to_evaluate)}\")\n",
        "        print(f\"{'ğŸ¤– '*20}\")\n",
        "        \n",
        "        try:\n",
        "            # Run evaluation\n",
        "            result = evaluate_single_model(\n",
        "                model_info=model_info,\n",
        "                law_docs=law_docs,\n",
        "                queries=benchmark_queries,\n",
        "                top_k=15,\n",
        "                show_detailed_results=(i < 2)  # Show details for first 2 models only\n",
        "            )\n",
        "            \n",
        "            if result['evaluation_success']:\n",
        "                evaluation_results.append(result)\n",
        "                successful_evaluations += 1\n",
        "                print(f\"âœ… Model {i+1} evaluation completed successfully!\")\n",
        "            else:\n",
        "                print(f\"âŒ Model {i+1} evaluation failed: {result.get('error', 'Unknown error')}\")\n",
        "                failed_evaluations += 1\n",
        "            \n",
        "            # Wait between models to prevent memory issues\n",
        "            if i < len(models_to_evaluate) - 1:\n",
        "                print(f\"â³ Waiting 2 seconds before next model...\")\n",
        "                time.sleep(2)\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Unexpected error evaluating model {i+1}: {str(e)}\")\n",
        "            failed_evaluations += 1\n",
        "            continue\n",
        "    \n",
        "    # Final summary\n",
        "    print(f\"\\n{'='*100}\")\n",
        "    print(f\"ğŸ‰ EVALUATION SUMMARY\")\n",
        "    print(f\"{'='*100}\")\n",
        "    print(f\"âœ… Successful evaluations: {successful_evaluations}\")\n",
        "    print(f\"âŒ Failed evaluations: {failed_evaluations}\")\n",
        "    print(f\"ğŸ“Š Total models evaluated: {len(evaluation_results)}\")\n",
        "    \n",
        "    if evaluation_results:\n",
        "        print(f\"\\nğŸ“ˆ Quick Performance Preview:\")\n",
        "        for result in evaluation_results:\n",
        "            metrics = result['aggregated_metrics']\n",
        "            model_name = result['model_name'].split('/')[-1]  # Get model name without path\n",
        "            print(f\"   ğŸ¤– {model_name}\")\n",
        "            print(f\"      Max Score: {metrics['avg_max_score']:.4f} | Top-5: {metrics['avg_avg_top5']:.4f} | Above 0.7: {metrics['avg_scores_above_07']:.1f}\")\n",
        "    \n",
        "    print(f\"\\nğŸ¯ Ready for detailed analysis and report generation!\")\n",
        "    print(f\"ğŸ“Š Variable 'evaluation_results' contains all results for further analysis.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Analysis vÃ  Final Report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“Š Generating detailed analysis and final report...\n",
            "\n",
            "====================================================================================================\n",
            "ğŸ“‹ COMPREHENSIVE EVALUATION REPORT\n",
            "====================================================================================================\n",
            "ğŸ“Š DATASET INFORMATION:\n",
            "   ğŸ“š Law Documents: 396 chunks from Luáº­t HÃ´n nhÃ¢n vÃ  Gia Ä‘Ã¬nh\n",
            "   â“ Benchmark Queries: 20 questions\n",
            "   ğŸ” Evaluation Method: Top-15 retrieval with cosine similarity\n",
            "   ğŸ’¾ Storage: RAM-based (no vector database)\n",
            "\n",
            "ğŸ† RANKING BY PERFORMANCE:\n",
            "   Metric: Average Max Score across all queries\n",
            "\n",
            "Rank Model                                         Max Score  Top-5    â‰¥0.7   â‰¥0.5   Type        \n",
            "-----------------------------------------------------------------------------------------------\n",
            "1    paraphrase-vietnamese-law                     0.9034     0.8780   11.4   12.8   transformers\n",
            "2    paraphrase-vietnamese-law-ALQAC               0.8711     0.7927   6.6    13.2   transformers\n",
            "3    Vietnamese_Law_Embedding_finetuned_v3_25      0.8577     0.8287   12.5   15.0   transformers\n",
            "4    paraphrase-multilingual-mpnet-base-v2         0.7647     0.7310   8.0    14.1   sentence_transformers\n",
            "5    bge-m3                                        0.7181     0.6819   4.7    12.9   sentence_transformers\n",
            "6    vietnamese-bi-encoder-fine-tuning-for-la      0.6379     0.5981   2.2    10.6   transformers\n",
            "\n",
            "â­ RECOMMENDED MODEL:\n",
            "   ğŸ¥‡ minhquan6203/paraphrase-vietnamese-law\n",
            "   ğŸ“ MÃ´ hÃ¬nh Sentence Similarity Ä‘Ã£ fine tune trÃªn bá»™ luáº­t phÃ¡p Viá»‡t Nam\n",
            "   ğŸ¯ Performance Highlights:\n",
            "      - Average Max Score: 0.9034\n",
            "      - Average Top-5 Score: 0.8780\n",
            "      - Queries with score â‰¥ 0.7: 11.4 per query\n",
            "      - Queries with score â‰¥ 0.5: 12.8 per query\n",
            "\n",
            "ğŸ“ˆ PERFORMANCE ANALYSIS:\n",
            "   ğŸ“Š Overall Statistics:\n",
            "      - Best Max Score: 0.9034\n",
            "      - Worst Max Score: 0.6379\n",
            "      - Average Max Score: 0.7921\n",
            "      - Best Top-5 Score: 0.8780\n",
            "      - Average Top-5 Score: 0.7518\n",
            "\n",
            "ğŸ”§ MODEL TYPE COMPARISON:\n",
            "   ğŸ”¨ Transformers models: 4 models, avg score: 0.8175\n",
            "   ğŸ“¦ Sentence-transformers: 2 models, avg score: 0.7414\n",
            "   âœ… Transformers models perform better on average (+0.0761)\n",
            "\n",
            "ğŸ’¡ RECOMMENDATIONS:\n",
            "   ğŸ¯ For Production Deployment:\n",
            "      - Primary: minhquan6203/paraphrase-vietnamese-law\n",
            "      - Type: transformers\n",
            "      - Max Length: 512 tokens\n",
            "   ğŸ¥ˆ Alternative Option:\n",
            "      - huyhuy123/paraphrase-vietnamese-law-ALQAC\n",
            "      - Performance difference: 0.0323\n",
            "\n",
            "ğŸ” DETAILED QUERY ANALYSIS:\n",
            "   ğŸ“ Sample Query Performance (Best Model):\n",
            "\n",
            "   Query 1: NgÆ°á»i bá»‹ bá»‡nh tÃ¢m tháº§n lÃ  ngÆ°á»i máº¥t nÄƒng lá»±c hÃ nh vi dÃ¢n sá»± ...\n",
            "      Max Score: 0.3415\n",
            "      Top-3 Average: 0.3143\n",
            "      Results â‰¥ 0.7: 0\n",
            "\n",
            "   Query 2: Sá»± thá»a thuáº­n cá»§a cÃ¡c bÃªn khÃ´ng vi pháº¡m Ä‘iá»u cáº¥m cá»§a phÃ¡p lu...\n",
            "      Max Score: 0.7058\n",
            "      Top-3 Average: 0.6917\n",
            "      Results â‰¥ 0.7: 1\n",
            "\n",
            "   Query 3: Tiá»n phÃºng viáº¿ng Ä‘Ã¡m ma cÅ©ng thuá»™c di sáº£n thá»«a káº¿ cá»§a ngÆ°á»i ...\n",
            "      Max Score: 0.9016\n",
            "      Top-3 Average: 0.8695\n",
            "      Results â‰¥ 0.7: 4\n",
            "\n",
            "====================================================================================================\n",
            "âœ… EVALUATION COMPLETED SUCCESSFULLY!\n",
            "ğŸ“Š Summary saved to 'evaluation_summary' variable\n",
            "ğŸ“‹ Full results available in 'evaluation_results' variable\n",
            "====================================================================================================\n",
            "\n",
            "ğŸ’¾ EXPORT OPTIONS:\n",
            "   To save results to JSON file:\n",
            "   â†’ import json\n",
            "   â†’ with open('embedding_evaluation_results.json', 'w', encoding='utf-8') as f:\n",
            "   â†’     json.dump(evaluation_results, f, ensure_ascii=False, indent=2)\n",
            "\n",
            "ğŸ‰ Report generation completed!\n"
          ]
        }
      ],
      "source": [
        "# ===== DETAILED ANALYSIS AND FINAL REPORT =====\n",
        "print(\"ğŸ“Š Generating detailed analysis and final report...\")\n",
        "\n",
        "if not evaluation_results:\n",
        "    print(\"âŒ No evaluation results available. Please run the evaluation first!\")\n",
        "else:\n",
        "    print(f\"\\n{'='*100}\")\n",
        "    print(f\"ğŸ“‹ COMPREHENSIVE EVALUATION REPORT\")\n",
        "    print(f\"{'='*100}\")\n",
        "    \n",
        "    # Sort models by average max score (best first)\n",
        "    sorted_results = sorted(\n",
        "        evaluation_results, \n",
        "        key=lambda x: x['aggregated_metrics']['avg_max_score'], \n",
        "        reverse=True\n",
        "    )\n",
        "    \n",
        "    print(f\"ğŸ“Š DATASET INFORMATION:\")\n",
        "    print(f\"   ğŸ“š Law Documents: {len(law_docs)} chunks from Luáº­t HÃ´n nhÃ¢n vÃ  Gia Ä‘Ã¬nh\")\n",
        "    print(f\"   â“ Benchmark Queries: {len(benchmark_queries)} questions\")\n",
        "    print(f\"   ğŸ” Evaluation Method: Top-15 retrieval with cosine similarity\")\n",
        "    print(f\"   ğŸ’¾ Storage: RAM-based (no vector database)\")\n",
        "    \n",
        "    print(f\"\\nğŸ† RANKING BY PERFORMANCE:\")\n",
        "    print(f\"   Metric: Average Max Score across all queries\")\n",
        "    \n",
        "    # Create comparison table\n",
        "    print(f\"\\n{'Rank':<4} {'Model':<45} {'Max Score':<10} {'Top-5':<8} {'â‰¥0.7':<6} {'â‰¥0.5':<6} {'Type':<12}\")\n",
        "    print(f\"{'-'*95}\")\n",
        "    \n",
        "    for i, result in enumerate(sorted_results):\n",
        "        metrics = result['aggregated_metrics']\n",
        "        model_name = result['model_name'].split('/')[-1][:40]  # Truncate long names\n",
        "        model_type = result['model_type']\n",
        "        \n",
        "        print(f\"{i+1:<4} {model_name:<45} {metrics['avg_max_score']:<10.4f} \"\n",
        "              f\"{metrics['avg_avg_top5']:<8.4f} {metrics['avg_scores_above_07']:<6.1f} \"\n",
        "              f\"{metrics['avg_scores_above_05']:<6.1f} {model_type:<12}\")\n",
        "    \n",
        "    # Best model analysis\n",
        "    best_model = sorted_results[0]\n",
        "    print(f\"\\nâ­ RECOMMENDED MODEL:\")\n",
        "    print(f\"   ğŸ¥‡ {best_model['model_name']}\")\n",
        "    print(f\"   ğŸ“ {best_model['model_description']}\")\n",
        "    print(f\"   ğŸ¯ Performance Highlights:\")\n",
        "    best_metrics = best_model['aggregated_metrics']\n",
        "    print(f\"      - Average Max Score: {best_metrics['avg_max_score']:.4f}\")\n",
        "    print(f\"      - Average Top-5 Score: {best_metrics['avg_avg_top5']:.4f}\")\n",
        "    print(f\"      - Queries with score â‰¥ 0.7: {best_metrics['avg_scores_above_07']:.1f} per query\")\n",
        "    print(f\"      - Queries with score â‰¥ 0.5: {best_metrics['avg_scores_above_05']:.1f} per query\")\n",
        "    \n",
        "    # Performance analysis\n",
        "    print(f\"\\nğŸ“ˆ PERFORMANCE ANALYSIS:\")\n",
        "    \n",
        "    # Calculate overall statistics\n",
        "    all_max_scores = [r['aggregated_metrics']['avg_max_score'] for r in evaluation_results]\n",
        "    all_top5_scores = [r['aggregated_metrics']['avg_avg_top5'] for r in evaluation_results]\n",
        "    \n",
        "    print(f\"   ğŸ“Š Overall Statistics:\")\n",
        "    print(f\"      - Best Max Score: {max(all_max_scores):.4f}\")\n",
        "    print(f\"      - Worst Max Score: {min(all_max_scores):.4f}\")\n",
        "    print(f\"      - Average Max Score: {np.mean(all_max_scores):.4f}\")\n",
        "    print(f\"      - Best Top-5 Score: {max(all_top5_scores):.4f}\")\n",
        "    print(f\"      - Average Top-5 Score: {np.mean(all_top5_scores):.4f}\")\n",
        "    \n",
        "    # Model type analysis\n",
        "    transformers_models = [r for r in evaluation_results if r['model_type'] == 'transformers']\n",
        "    sentence_transformers_models = [r for r in evaluation_results if r['model_type'] == 'sentence_transformers']\n",
        "    \n",
        "    if transformers_models and sentence_transformers_models:\n",
        "        print(f\"\\nğŸ”§ MODEL TYPE COMPARISON:\")\n",
        "        \n",
        "        trans_avg = np.mean([r['aggregated_metrics']['avg_max_score'] for r in transformers_models])\n",
        "        sent_avg = np.mean([r['aggregated_metrics']['avg_max_score'] for r in sentence_transformers_models])\n",
        "        \n",
        "        print(f\"   ğŸ”¨ Transformers models: {len(transformers_models)} models, avg score: {trans_avg:.4f}\")\n",
        "        print(f\"   ğŸ“¦ Sentence-transformers: {len(sentence_transformers_models)} models, avg score: {sent_avg:.4f}\")\n",
        "        \n",
        "        if trans_avg > sent_avg:\n",
        "            print(f\"   âœ… Transformers models perform better on average (+{trans_avg - sent_avg:.4f})\")\n",
        "        else:\n",
        "            print(f\"   âœ… Sentence-transformers models perform better on average (+{sent_avg - trans_avg:.4f})\")\n",
        "    \n",
        "    # Recommendations\n",
        "    print(f\"\\nğŸ’¡ RECOMMENDATIONS:\")\n",
        "    print(f\"   ğŸ¯ For Production Deployment:\")\n",
        "    print(f\"      - Primary: {best_model['model_name']}\")\n",
        "    print(f\"      - Type: {best_model['model_type']}\")\n",
        "    print(f\"      - Max Length: {best_model['max_length']} tokens\")\n",
        "    \n",
        "    if len(sorted_results) > 1:\n",
        "        second_best = sorted_results[1]\n",
        "        print(f\"   ğŸ¥ˆ Alternative Option:\")\n",
        "        print(f\"      - {second_best['model_name']}\")\n",
        "        print(f\"      - Performance difference: {best_metrics['avg_max_score'] - second_best['aggregated_metrics']['avg_max_score']:.4f}\")\n",
        "    \n",
        "    print(f\"\\nğŸ” DETAILED QUERY ANALYSIS:\")\n",
        "    print(f\"   ğŸ“ Sample Query Performance (Best Model):\")\n",
        "    \n",
        "    # Show performance on first 3 queries for best model\n",
        "    best_query_results = best_model['query_results'][:3]\n",
        "    for i, qr in enumerate(best_query_results):\n",
        "        print(f\"\\n   Query {i+1}: {qr['query'][:60]}...\")\n",
        "        print(f\"      Max Score: {qr['metrics']['max_score']:.4f}\")\n",
        "        print(f\"      Top-3 Average: {qr['metrics']['avg_top3']:.4f}\")\n",
        "        print(f\"      Results â‰¥ 0.7: {qr['metrics']['scores_above_07']}\")\n",
        "    \n",
        "    # Save summary to variables for further use\n",
        "    evaluation_summary = {\n",
        "        'best_model': best_model['model_name'],\n",
        "        'best_score': best_metrics['avg_max_score'],\n",
        "        'total_models_evaluated': len(evaluation_results),\n",
        "        'total_queries': len(benchmark_queries),\n",
        "        'total_documents': len(law_docs),\n",
        "        'sorted_results': sorted_results\n",
        "    }\n",
        "    \n",
        "    print(f\"\\n{'='*100}\")\n",
        "    print(f\"âœ… EVALUATION COMPLETED SUCCESSFULLY!\")\n",
        "    print(f\"ğŸ“Š Summary saved to 'evaluation_summary' variable\")\n",
        "    print(f\"ğŸ“‹ Full results available in 'evaluation_results' variable\")\n",
        "    print(f\"{'='*100}\")\n",
        "    \n",
        "    # Export option\n",
        "    print(f\"\\nğŸ’¾ EXPORT OPTIONS:\")\n",
        "    print(f\"   To save results to JSON file:\")\n",
        "    print(f\"   â†’ import json\")\n",
        "    print(f\"   â†’ with open('embedding_evaluation_results.json', 'w', encoding='utf-8') as f:\")\n",
        "    print(f\"   â†’     json.dump(evaluation_results, f, ensure_ascii=False, indent=2)\")\n",
        "    \n",
        "    print(f\"\\nğŸ‰ Report generation completed!\")\n",
        "    \n",
        "    # Make summary available globally\n",
        "    globals()['evaluation_summary'] = evaluation_summary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Test vá»›i Single Query\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ§ª Quick test with single query...\n",
            "ğŸ“ Test Query: Äiá»u kiá»‡n káº¿t hÃ´n cá»§a nam vÃ  ná»¯ theo phÃ¡p luáº­t Viá»‡t Nam lÃ  gÃ¬?\n",
            "ğŸ¯ Using manual model: sentence-transformers/paraphrase-multilingual-mpnet-base-v2\n",
            "ğŸ” Testing single query with model `sentence-transformers/paraphrase-multilingual-mpnet-base-v2`...\n",
            "Loading model: sentence-transformers/paraphrase-multilingual-mpnet-base-v2\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c2166c33860847c8a608f66790151156",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… Generated 1 embeddings, stored in RAM\n",
            "Loading model: sentence-transformers/paraphrase-multilingual-mpnet-base-v2\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20d83ab0089449f09d27fecc1646882d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… Generated 396 embeddings, stored in RAM\n",
            "ğŸ“ Query: Äiá»u kiá»‡n káº¿t hÃ´n cá»§a nam vÃ  ná»¯ theo phÃ¡p luáº­t Viá»‡t Nam lÃ  gÃ¬?\n",
            "ğŸ¯ Top 5 Results:\n",
            "\n",
            "   1. Score: 0.8354 | Äiá»u 126, Khoáº£n 1\n",
            "      Type: clause | Length: 309 chars\n",
            "      Content: Khoáº£n 1. Trong viá»‡c káº¿t hÃ´n giá»¯a cÃ´ng dÃ¢n Viá»‡t Nam vá»›i ngÆ°á»i nÆ°á»›c ngoÃ i, má»—i bÃªn pháº£i tuÃ¢n theo phÃ¡p luáº­t cá»§a nÆ°á»›c mÃ¬nh vá» Ä‘iá»u kiá»‡n káº¿t hÃ´n; náº¿u viá»‡c káº¿t hÃ´n Ä‘Æ°á»£c tiáº¿n hÃ nh táº¡i cÆ¡ quan nhÃ  nÆ°á»›c cÃ³ th...\n",
            "      Metadata: chapter: ChÆ°Æ¡ng VIII, section: None, article_no: 126, article_title: Káº¿t hÃ´n cÃ³ yáº¿u tá»‘ nÆ°á»›c ngoÃ i, clause_no: 1, exact_citation: Äiá»u 126 khoáº£n 1\n",
            "\n",
            "   2. Score: 0.8299 | Äiá»u 126, Khoáº£n 2\n",
            "      Type: clause | Length: 173 chars\n",
            "      Content: Khoáº£n 2. Viá»‡c káº¿t hÃ´n giá»¯a nhá»¯ng ngÆ°á»i nÆ°á»›c ngoÃ i thÆ°á»ng trÃº á»Ÿ Viá»‡t Nam táº¡i cÆ¡ quan cÃ³ tháº©m quyá»n cá»§a Viá»‡t Nam pháº£i tuÃ¢n theo cÃ¡c quy Ä‘á»‹nh cá»§a Luáº­t nÃ y vá» Ä‘iá»u kiá»‡n káº¿t hÃ´n....\n",
            "      Metadata: chapter: ChÆ°Æ¡ng VIII, section: None, article_no: 126, article_title: Káº¿t hÃ´n cÃ³ yáº¿u tá»‘ nÆ°á»›c ngoÃ i, clause_no: 2, exact_citation: Äiá»u 126 khoáº£n 2\n",
            "\n",
            "   3. Score: 0.8036 | Äiá»u 122, Khoáº£n 1\n",
            "      Type: clause | Length: 393 chars\n",
            "      Content: Khoáº£n 1. CÃ¡c quy Ä‘á»‹nh cá»§a phÃ¡p luáº­t vá» hÃ´n nhÃ¢n vÃ  gia Ä‘Ã¬nh cá»§a nÆ°á»›c Cá»™ng hÃ²a xÃ£ há»™i chá»§ nghÄ©a Viá»‡t Nam Ä‘Æ°á»£c Ã¡p dá»¥ng Ä‘á»‘i vá»›i quan há»‡ hÃ´n nhÃ¢n vÃ  gia Ä‘Ã¬nh cÃ³ yáº¿u tá»‘ nÆ°á»›c ngoÃ i, trá»« trÆ°á»ng há»£p Luáº­t nÃ y ...\n",
            "      Metadata: chapter: ChÆ°Æ¡ng VIII, section: None, article_no: 122, article_title: Ãp dá»¥ng phÃ¡p luáº­t Ä‘á»‘i vá»›i quan há»‡ hÃ´n nhÃ¢n vÃ  gia Ä‘Ã¬nh cÃ³ yáº¿u tá»‘ nÆ°á»›c ngoÃ i, clause_no: 1, exact_citation: Äiá»u 122 khoáº£n 1\n",
            "\n",
            "   4. Score: 0.8022 | Äiá»u 2, Khoáº£n 2\n",
            "      Type: clause | Length: 266 chars\n",
            "      Content: Khoáº£n 2. HÃ´n nhÃ¢n giá»¯a cÃ´ng dÃ¢n Viá»‡t Nam thuá»™c cÃ¡c dÃ¢n tá»™c, tÃ´n giÃ¡o, giá»¯a ngÆ°á»i theo tÃ´n giÃ¡o vá»›i ngÆ°á»i khÃ´ng theo tÃ´n giÃ¡o, giá»¯a ngÆ°á»i cÃ³ tÃ­n ngÆ°á»¡ng vá»›i ngÆ°á»i khÃ´ng cÃ³ tÃ­n ngÆ°á»¡ng, giá»¯a cÃ´ng dÃ¢n Viá»‡t...\n",
            "      Metadata: chapter: ChÆ°Æ¡ng I, section: None, article_no: 2, article_title: Nhá»¯ng nguyÃªn táº¯c cÆ¡ báº£n cá»§a cháº¿ Ä‘á»™ hÃ´n nhÃ¢n vÃ  gia Ä‘Ã¬nh, clause_no: 2, exact_citation: Äiá»u 2 khoáº£n 2\n",
            "\n",
            "   5. Score: 0.7996 | Äiá»u 130 - Ãp dá»¥ng cháº¿ Ä‘á»™ tÃ i sáº£n cá»§a vá»£ chá»“ng theo thá»a thuáº­n; giáº£i quyáº¿t háº­u quáº£ cá»§a viá»‡c nam, ná»¯ chung sá»‘ng vá»›i nhau nhÆ° vá»£ chá»“ng mÃ  khÃ´ng Ä‘Äƒng kÃ½ káº¿t hÃ´n cÃ³ yáº¿u tá»‘ nÆ°á»›c ngoÃ i\n",
            "      Type: article_intro | Length: 500 chars\n",
            "      Content: Äiá»u 130. Ãp dá»¥ng cháº¿ Ä‘á»™ tÃ i sáº£n cá»§a vá»£ chá»“ng theo thá»a thuáº­n; giáº£i quyáº¿t háº­u quáº£ cá»§a viá»‡c nam, ná»¯ chung sá»‘ng vá»›i nhau nhÆ° vá»£ chá»“ng mÃ  khÃ´ng Ä‘Äƒng kÃ½ káº¿t hÃ´n cÃ³ yáº¿u tá»‘ nÆ°á»›c ngoÃ i\n",
            "Trong trÆ°á»ng há»£p cÃ³ yÃª...\n",
            "      Metadata: chapter: ChÆ°Æ¡ng VIII, section: None, article_no: 130, article_title: Ãp dá»¥ng cháº¿ Ä‘á»™ tÃ i sáº£n cá»§a vá»£ chá»“ng theo thá»a thuáº­n; giáº£i quyáº¿t háº­u quáº£ cá»§a viá»‡c nam, ná»¯ chung sá»‘ng vá»›i nhau nhÆ° vá»£ chá»“ng mÃ  khÃ´ng Ä‘Äƒng kÃ½ káº¿t hÃ´n cÃ³ yáº¿u tá»‘ nÆ°á»›c ngoÃ i, exact_citation: Äiá»u 130\n",
            "\n",
            "ğŸ“Š Metrics for this query:\n",
            "   - Max Score: 0.8354\n",
            "   - Top-5 Average: 0.8141\n",
            "   - Results â‰¥ 0.7: 10\n",
            "   - Results â‰¥ 0.5: 10\n",
            "\n",
            "âœ… Single query test completed!\n"
          ]
        }
      ],
      "source": [
        "# ===== TEST SINGLE QUERY =====\n",
        "print(\"ğŸ§ª Quick test with single query...\")\n",
        "\n",
        "# Test query\n",
        "test_query = \"Äiá»u kiá»‡n káº¿t hÃ´n cá»§a nam vÃ  ná»¯ theo phÃ¡p luáº­t Viá»‡t Nam lÃ  gÃ¬?\"\n",
        "print(f\"ğŸ“ Test Query: {test_query}\")\n",
        "\n",
        "manual_model_name = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\" \n",
        "\n",
        "# Check evaluation summary\n",
        "if 'evaluation_summary' in globals() and evaluation_summary:\n",
        "    if manual_model_name:  \n",
        "        best_model_name = manual_model_name\n",
        "        print(f\"ğŸ¯ Using manual model: {best_model_name}\")\n",
        "    else:\n",
        "        best_model_name = evaluation_summary['best_model']\n",
        "        print(f\"ğŸ¥‡ Using best model: {best_model_name}\")\n",
        "\n",
        "    # Find model info\n",
        "    best_model_info = None\n",
        "    for model in models_to_evaluate:\n",
        "        if model['name'] == best_model_name:\n",
        "            best_model_info = model\n",
        "            break\n",
        "\n",
        "    if best_model_info:\n",
        "        print(f\"ğŸ” Testing single query with model `{best_model_info['name']}`...\")\n",
        "\n",
        "        # Encode query\n",
        "        if best_model_info['type'] == 'sentence_transformers':\n",
        "            test_query_embedding = encode_with_sentence_transformers([test_query], best_model_info['name'])[0]\n",
        "        else:\n",
        "            test_query_embedding = encode_with_transformers([test_query], best_model_info['name'], best_model_info['max_length'])[0]\n",
        "\n",
        "        # Encode documents (re-encode cho demo, thá»±c táº¿ nÃªn cache)\n",
        "        doc_texts = [doc['text'] for doc in law_docs]\n",
        "        if best_model_info['type'] == 'sentence_transformers':\n",
        "            doc_embeddings = encode_with_sentence_transformers(doc_texts, best_model_info['name'])\n",
        "        else:\n",
        "            doc_embeddings = encode_with_transformers(doc_texts, best_model_info['name'], best_model_info['max_length'])\n",
        "\n",
        "        # Search\n",
        "        top_indices, top_scores = search_top_k(test_query_embedding, doc_embeddings, k=10)\n",
        "\n",
        "        # Display results\n",
        "        display_search_results(test_query, law_docs, top_indices, top_scores, max_display=5)\n",
        "\n",
        "        # Metrics\n",
        "        metrics = calculate_metrics(top_scores)\n",
        "        print(f\"\\nğŸ“Š Metrics for this query:\")\n",
        "        print(f\"   - Max Score: {metrics['max_score']:.4f}\")\n",
        "        print(f\"   - Top-5 Average: {metrics['avg_top5']:.4f}\")\n",
        "        print(f\"   - Results â‰¥ 0.7: {metrics['scores_above_07']}\")\n",
        "        print(f\"   - Results â‰¥ 0.5: {metrics['scores_above_05']}\")\n",
        "    else:\n",
        "        print(\"âŒ Could not find model info for testing\")\n",
        "\n",
        "else:\n",
        "    print(\"âš ï¸ No evaluation results available. Run the full evaluation first!\")\n",
        "\n",
        "print(f\"\\nâœ… Single query test completed!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "legal_ai_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
