# ğŸ” Vietnamese Legal Embedding Model Evaluation & Testing

Dá»± Ã¡n nÃ y Ä‘Ã¡nh giÃ¡ vÃ  so sÃ¡nh cÃ¡c mÃ´ hÃ¬nh embedding cho vÄƒn báº£n luáº­t tiáº¿ng Viá»‡t, vá»›i giao diá»‡n Gradio Ä‘á»ƒ test interactive.

## ğŸ“‹ Tá»•ng quan

- **Dataset:** Luáº­t Viá»‡t Nam tá»« nhiá»u lÄ©nh vá»±c (hiá»‡n táº¡i: 511 chunks tá»« 7 luáº­t)
- **Benchmark Questions:** 511 cÃ¢u há»i tá»« Excel files â†’ Random 50 cÃ¢u cho evaluation
- **Models:** 4 mÃ´ hÃ¬nh embedding Vietnamese vÃ  multilingual
- **Chunking:** 2-pass system vá»›i clause intro injection & law_id tá»± Ä‘á»™ng
- **Storage:** Qdrant vector database vá»›i batch upsert
- **Analysis:** **Top 3 queries** vá»›i **full content** vÃ  thÃ´ng tin Ä‘á»‘i chiáº¿u
- **Output:** `embedding_evaluation_results.json` vá»›i detailed analysis

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c

```
vn-law-embedding-benchmark/
â”œâ”€â”€ embedding_evaluation.py       # Main evaluation script
â”œâ”€â”€ find_law_files.py            # Law document discovery
â”œâ”€â”€ find_question_files.py       # Question extraction from Excel
â”œâ”€â”€ README.md                    # Documentation
â”œâ”€â”€ requirements.txt             # Dependencies
â”œâ”€â”€ setup_environment.bat        # Environment setup
â”œâ”€â”€ Danh_Gia_Mo_Hinh_Embedding.ipynb  # Jupyter notebook
â”œâ”€â”€ data_files/                  # Data files
â”‚   â”œâ”€â”€ law_file_paths.json      # Law document metadata
â”‚   â””â”€â”€ law_questions.json       # Benchmark questions
â”œâ”€â”€ results/                     # Output files
â”‚   â”œâ”€â”€ embedding_evaluation_results.json
â”‚   â””â”€â”€ top_queries_analysis.json
â”œâ”€â”€ utilities/                   # Utility scripts
â”‚   â”œâ”€â”€ view_top_queries.py      # View top queries results
â”‚   â”œâ”€â”€ test_chunking.py         # Chunking tests
â”‚   â””â”€â”€ test_readable_files.py   # File reading tests
â””â”€â”€ law_content/                 # Raw law documents
```

## ğŸš€ CÃ¡ch sá»­ dá»¥ng

### 1. Chuáº©n bá»‹ dá»¯ liá»‡u

```bash
# 1. TÃ¬m vÃ  catalog táº¥t cáº£ file luáº­t
python find_law_files.py

# 2. TrÃ­ch xuáº¥t cÃ¢u há»i tá»« file Excel
python find_question_files.py

# Output files:
# - data_files/law_file_paths.json: Danh sÃ¡ch file luáº­t
# - data_files/law_questions.json: 511 cÃ¢u há»i benchmark
```

### 2. Cháº¡y Ä‘Ã¡nh giÃ¡ vá»›i 50 cÃ¢u há»i random

```bash
# Cháº¡y full evaluation vá»›i 50 queries random + hiá»ƒn thá»‹ top 3
python embedding_evaluation.py

# Output:
# - results/embedding_evaluation_results.json: Káº¿t quáº£ Ä‘Ã¡nh giÃ¡ Ä‘áº§y Ä‘á»§ (ghi Ä‘Ã¨)
# - results/top_queries_analysis.json: Top queries analysis sáº¡ch (tá»± Ä‘á»™ng táº¡o)
# - Console: Top 3 queries vá»›i full content vÃ  thÃ´ng tin Ä‘á»‘i chiáº¿u


## ğŸ“Š Output Format

### Top 3 Queries Display
```

ğŸ” TOP 3 QUERIES BY TOTAL SCORE (Best Model)

1.  Total Score: 12.456
    Query: [CÃ¢u há»i tá»« Excel]
    Category: Báº¥t Ä‘á»™ng sáº£n - Luáº­t Äáº¥t Äai
    Expected Answer: [CÃ¢u tráº£ lá»i tÃ­ch cá»±c tá»« Excel]...
    Negative Answer: [CÃ¢u tráº£ lá»i tiÃªu cá»±c tá»« Excel]...

    ğŸ“„ Rank 1: Score 0.823 | Law: LDATDAI
    ğŸ“ Citation: Äiá»u 1
    ğŸ“– Content: Äiá»u 1. Pháº¡m vi Ä‘iá»u chá»‰nh Luáº­t nÃ y quy Ä‘á»‹nh...
    ... (500 chars total)

    ğŸ“„ Rank 2: Score 0.756 | Law: LDATDAI
    ğŸ“ Citation: Äiá»u 2
    ğŸ“– Content: Äiá»u 2. Äá»‘i tÆ°á»£ng Ã¡p dá»¥ng...
    ... (300 chars total)

````

### JSON Results
```json
{
  "model_name": "minhquan6203/paraphrase-vietnamese-law",
  "top_queries_by_total_score": [
    {
      "rank": 1,
      "query": "CÃ¢u há»i...",
      "total_score": 12.456,
      "question_info": {
        "category": "Báº¥t Ä‘á»™ng sáº£n - Luáº­t Äáº¥t Äai",
        "positive_answer": "CÃ¢u tráº£ lá»i tÃ­ch cá»±c...",
        "negative_answer": "CÃ¢u tráº£ lá»i tiÃªu cá»±c...",
        "source_file": "Luáº­t Ä‘áº¥t Ä‘ai 2024_.xlsx"
      },
      "top_answers": [
        {
          "rank": 1,
          "score": 0.823,
          "citation": "Äiá»u 1",
          "law_id": "LDATDAI",
          "content": "Full content...",
          "metadata": {...}
        }
      ]
    }
  ]
}
````

### 3. CÃ i Ä‘áº·t mÃ´i trÆ°á»ng

```bash
# Táº¡o virtual environment
python -m venv legal_ai_env
source legal_ai_env/bin/activate  # Linux/Mac

# CLI
setup_environment.bat # Windows

# hoáº·c
legal_ai_env\Scripts\activate     # Windows

# CÃ i Ä‘áº·t dependencies
pip install -r requirements.txt
```

Script nÃ y sáº½:

- âœ… Load vÃ  chunk dá»¯ liá»‡u luáº­t tá»« DOCX (tá»± Ä‘á»™ng táº¡o law_id)
- âœ… TrÃ­ch xuáº¥t cÃ¢u há»i tá»« Excel files (format Query-Positive-Negative)
- âœ… **Random 50 cÃ¢u há»i** tá»« 511 cÃ¢u benchmark Ä‘á»ƒ Ä‘Ã¡nh giÃ¡
- âœ… ÄÃ¡nh giÃ¡ 4 mÃ´ hÃ¬nh embedding vá»›i 50 cÃ¢u há»i Ä‘Ã£ chá»n
- âœ… LÆ°u trá»¯ embeddings trong Qdrant vector database
- âœ… **Hiá»ƒn thá»‹ TOP 3 cÃ¢u há»i** cÃ³ tá»•ng score cao nháº¥t vá»›i **full content**
- âœ… Táº¡o bÃ¡o cÃ¡o chi tiáº¿t vá»›i ranking vÃ  phÃ¢n tÃ­ch
- âœ… Ghi Ä‘Ã¨ file `embedding_evaluation_results.json`

## ğŸ¤– Models Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡

1. **ğŸ† minhquan6203/paraphrase-vietnamese-law** (Best)
2. **sentence-transformers/paraphrase-multilingual-mpnet-base-v2**
3. **namnguyenba2003/Vietnamese_Law_Embedding_finetuned_v3_256dims**
4. **truro7/vn-law-embedding**

## ğŸ“Š Dataset & Questions

### Luáº­t Documents

- **Tá»± Ä‘á»™ng phÃ¡t hiá»‡n:** Script `find_law_files.py` tÃ¬m táº¥t cáº£ file .docx trong `law_content/`
- **Chunking thÃ´ng minh:** Chia theo cáº¥u trÃºc Äiá»u-Khoáº£n-Äiá»ƒm vá»›i law_id tá»± Ä‘á»™ng
- **Law ID mapping:**
  - `LKBDS` â†’ Luáº­t Kinh Doanh Báº¥t Äá»™ng Sáº£n
  - `LNHAO` â†’ Luáº­t NhÃ  á»
  - `LDATDAI` â†’ Luáº­t Äáº¥t Äai
  - `LDAUTU` â†’ Luáº­t Äáº§u TÆ°
  - `LTSDDNONGNGHIEP` â†’ Luáº­t Thuáº¿ Sá»­ Dá»¥ng Äáº¥t NÃ´ng Nghiá»‡p
  - `LTSDDPHINONGNGHIEP` â†’ Luáº­t Thuáº¿ Sá»­ Dá»¥ng Äáº¥t Phi NÃ´ng Nghiá»‡p
  - `LXAYDUNG` â†’ Luáº­t XÃ¢y Dá»±ng

### Benchmark Questions

- **Nguá»“n:** File Excel .xlsx trong thÆ° má»¥c `CÃ¢u há»i/`
- **Format:** Má»—i file cÃ³ 3 cá»™t: `Query`, `Positive`, `Negative`
- **Tá»± Ä‘á»™ng trÃ­ch xuáº¥t:** Script `find_question_files.py` xá»­ lÃ½ táº¥t cáº£ file Excel
- **Sá»‘ lÆ°á»£ng:** 511 cÃ¢u há»i tá»« 4 luáº­t báº¥t Ä‘á»™ng sáº£n

```bash
# TrÃ­ch xuáº¥t cÃ¢u há»i tá»« Excel
python find_question_files.py

# Output: law_questions.json vá»›i cáº¥u trÃºc
{
  "id": "file_name_Q1",
  "query": "CÃ¢u há»i...",
  "positive": "CÃ¢u tráº£ lá»i tÃ­ch cá»±c...",
  "negative": "CÃ¢u tráº£ lá»i tiÃªu cá»±c...",
  "query_variations": ["query1", "query2", ...],
  "full_category": "Báº¥t Ä‘á»™ng sáº£n - Luáº­t Äáº¥t Äai"
}
```

## ğŸ¯ Interface Features

### Search & Testing

- Real-time semantic search
- Top-K adjustable (5-20 results)
- Detailed metrics display
- Error handling robust

### Results Display

- Similarity scores
- Document metadata
- Content preview
- Performance metrics

## ğŸ“Š Evaluation Metrics

- **Max Score:** Äiá»ƒm similarity cao nháº¥t
- **Average Top-5:** Trung bÃ¬nh top-5 results
- **Above 0.7/0.5:** Sá»‘ results trÃªn ngÆ°á»¡ng
- **Cosine Similarity:** PhÆ°Æ¡ng phÃ¡p so sÃ¡nh

## ğŸ“ Cáº¥u trÃºc files

```
vn-law-embedding-benchmark/
â”œâ”€â”€ Danh_Gia_Mo_Hinh_Embedding.ipynb    # Main evaluation script
â”œâ”€â”€ requirements.txt                  # Dependencies
â”œâ”€â”€ setup_environment.bat            # Windows setup script
â”œâ”€â”€ README.md                        # Documentation
â””â”€â”€ LuatHonNhan/                     # Data folder
    â””â”€â”€ luat_hon_nhan_va_gia_dinh.docx
```

## ğŸ”§ System Requirements

- **Python:** 3.8+
- **RAM:** 8GB+ (cho model loading)
- **GPU:** Optional (CUDA support)
- **Storage:** 2GB+ cho models

## ğŸ“ Example Queries

```
"Äiá»u kiá»‡n káº¿t hÃ´n cá»§a nam vÃ  ná»¯ theo phÃ¡p luáº­t Viá»‡t Nam lÃ  gÃ¬?"
"TÃ i sáº£n nÃ o Ä‘Æ°á»£c coi lÃ  tÃ i sáº£n chung cá»§a vá»£ chá»“ng?"
"Thá»§ tá»¥c ly hÃ´n táº¡i tÃ²a Ã¡n Ä‘Æ°á»£c quy Ä‘á»‹nh nhÆ° tháº¿ nÃ o?"
"Quyá»n vÃ  nghÄ©a vá»¥ cá»§a cha máº¹ Ä‘á»‘i vá»›i con chÆ°a thÃ nh niÃªn?"
```

## ğŸ‰ Results Summary

**Best Model:** `minhquan6203/paraphrase-vietnamese-law`

- **Score:** 0.9034
- **Type:** Transformers
- **Specialization:** Fine-tuned cho luáº­t Viá»‡t Nam
