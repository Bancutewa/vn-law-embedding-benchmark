#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Embed chunks vÃ  upload lÃªn Qdrant Database
TÃ¡i sá»­ dá»¥ng Ä‘Æ°á»£c cho cÃ¡c category vÃ  model khÃ¡c nhau
"""

import os
import json
import argparse
import numpy as np
from pathlib import Path
from typing import List, Dict, Any

# Import tá»« modules
from modules.qdrant_manager import (
    get_qdrant_client,
    ensure_collection,
    upsert_embeddings_to_qdrant,
    count_collection_points,
    get_collection_info
)
from modules.embedding_models import encode_texts, get_embedding_dimension

def load_chunks_from_json(json_path: str) -> List[Dict[str, Any]]:
    """Load chunks tá»« file JSON"""
    if not os.path.exists(json_path):
        raise FileNotFoundError(f"Chunk file not found: {json_path}")

    print(f"ğŸ“– Loading chunks from: {json_path}")
    with open(json_path, 'r', encoding='utf-8') as f:
        chunks = json.load(f)

    print(f"   âœ… Loaded {len(chunks)} chunks")

    # Validate chunks cÃ³ content
    valid_chunks = []
    for chunk in chunks:
        if chunk.get('content', '').strip():
            valid_chunks.append(chunk)
        else:
            print(f"   âš ï¸ Skipped chunk with empty content: {chunk.get('id', 'unknown')}")

    print(f"   âœ… Valid chunks: {len(valid_chunks)}")
    return valid_chunks

def extract_texts_from_chunks(chunks: List[Dict[str, Any]]) -> List[str]:
    """Extract text content tá»« chunks Ä‘á»ƒ embedding"""
    texts = []
    for chunk in chunks:
        content = chunk.get('content', '').strip()
        if content:
            texts.append(content)
    return texts

def create_collection_name(model_name: str, category: str) -> str:
    """Táº¡o collection name theo format: model_name/category"""
    # Clean model name (remove special chars, replace / with -)
    clean_model = model_name.replace('/', '-').replace('_', '-')
    return f"{clean_model}-{category}"

def main():
    """Main function"""
    parser = argparse.ArgumentParser(
        description="Embed chunks vÃ  upload lÃªn Qdrant Database",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )

    # ========== THAM Sá» Cáº¦N Sá»¬A ==========
    # File chunk JSON - sá»­a path nÃ y khi cáº§n
    parser.add_argument(
        "--chunk-file",
        default="data/BDS_chunk_155638_250925.json",  # â†â†â† Sá»¬A PATH FILE CHUNK á» ÄÃ‚Y
        help="Path to chunk JSON file (default: data/BDS_chunk_155638_250925.json)"
    )

    # Model embedding - sá»­a model nÃ y khi cáº§n
    parser.add_argument(
        "--model",
        default="minhquan6203/paraphrase-vietnamese-law",  # â†â†â† Sá»¬A MODEL á» ÄÃ‚Y
        help="Embedding model name (default: minhquan6203/paraphrase-vietnamese-law)"
    )

    # Category - sá»­a category nÃ y khi cáº§n
    parser.add_argument(
        "--category",
        default="BDS",  # â†â†â† Sá»¬A CATEGORY á» ÄÃ‚Y
        help="Category name for collection (default: BDS)"
    )

    # Model type - tá»± Ä‘á»™ng detect nhÆ°ng cÃ³ thá»ƒ override
    parser.add_argument(
        "--model-type",
        choices=["transformers", "sentence_transformers"],
        help="Force model type (auto-detected if not specified)"
    )

    # CÃ¡c tham sá»‘ khÃ¡c
    parser.add_argument(
        "--batch-size",
        type=int,
        default=16,
        help="Batch size for embedding (default: 16)"
    )

    parser.add_argument(
        "--device",
        default="cuda",
        choices=["cuda", "cpu"],
        help="Device for embedding (default: cuda)"
    )

    parser.add_argument(
        "--force-recreate",
        action="store_true",
        help="Force recreate collection even if it exists"
    )

    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Test mode: chá»‰ encode vÃ  validate, khÃ´ng upload lÃªn Qdrant"
    )

    args = parser.parse_args()

    print("=" * 80)
    print("ğŸš€ VIETNAMESE LAW EMBEDDING & QDRANT UPLOAD")
    print("=" * 80)
    print(f"ğŸ“ Chunk file: {args.chunk_file}")
    print(f"ğŸ¤– Model: {args.model}")
    print(f"ğŸ“‚ Category: {args.category}")
    print(f"ğŸ¯ Collection: {create_collection_name(args.model, args.category)}")
    print(f"âš™ï¸  Device: {args.device}")
    print(f"ğŸ“¦ Batch size: {args.batch_size}")
    if args.dry_run:
        print("ğŸ” DRY RUN MODE - No upload to Qdrant")
    print("=" * 80)

    try:
        # 1. Load chunks tá»« JSON
        chunks = load_chunks_from_json(args.chunk_file)

        if not chunks:
            print("âŒ No valid chunks found!")
            return

        # 2. Extract texts Ä‘á»ƒ embedding
        texts = extract_texts_from_chunks(chunks)
        print(f"ğŸ“ Extracted {len(texts)} texts for embedding")

        # 3. Setup model info
        # Auto-detect model type
        model_type = args.model_type
        if not model_type:
            # Auto-detect based on model name
            if 'sentence-transformers' in args.model or 'all-MiniLM' in args.model or 'paraphrase-multilingual' in args.model:
                model_type = 'sentence_transformers'
            else:
                model_type = 'transformers'  # Default for most HF models

        model_info = {
            'name': args.model,
            'type': model_type,
            'max_length': 512
        }

        print(f"ğŸ¯ Detected model type: {model_type}")

        # 4. Get embedding dimension
        print(f"ğŸ“ Getting embedding dimension...")
        vector_size = get_embedding_dimension(model_info)
        print(f"   âœ… Embedding dimension: {vector_size}")

        if args.dry_run:
            print("ğŸ” DRY RUN: Skipping embedding and upload")
            return

        # 5. Encode texts thÃ nh embeddings
        print(f"ğŸ§  Encoding {len(texts)} texts with {args.model}...")
        embeddings = encode_texts(
            texts=texts,
            model_info=model_info,
            device=args.device
        )

        print(f"   âœ… Generated embeddings shape: {embeddings.shape}")

        # 6. Káº¿t ná»‘i Qdrant
        print(f"ğŸ—„ï¸  Connecting to Qdrant...")
        client = get_qdrant_client()

        # 7. Táº¡o collection name
        collection_name = create_collection_name(args.model, args.category)
        print(f"ğŸ“‹ Collection name: {collection_name}")

        # 8. Check existing collection
        existing_info = get_collection_info(client, collection_name)
        if existing_info and not args.force_recreate:
            existing_count = existing_info.get('points_count', 0)
            print(f"âš ï¸  Collection '{collection_name}' already exists with {existing_count} points")
            choice = input("   Continue and recreate? (y/N): ").strip().lower()
            if choice != 'y':
                print("âŒ Aborted")
                return

        # 9. Táº¡o collection
        print(f"ğŸ—ï¸  Creating collection '{collection_name}'...")
        ensure_collection(client, collection_name, vector_size)

        # 10. Upload embeddings vÃ  chunks lÃªn Qdrant
        print(f"ğŸ“¤ Uploading to Qdrant...")
        upsert_embeddings_to_qdrant(
            client=client,
            collection_name=collection_name,
            embeddings=embeddings,
            law_docs=chunks,
            batch_size=100  # Qdrant batch size
        )

        # 11. Verify upload
        final_count = count_collection_points(client, collection_name)
        print(f"âœ… SUCCESS! Collection '{collection_name}' now has {final_count} vectors")

        print("\nğŸ‰ EMBEDDING & UPLOAD COMPLETED!")
        print(f"   Collection: {collection_name}")
        print(f"   Vectors: {final_count}")
        print(f"   Dimension: {vector_size}")

    except Exception as e:
        print(f"âŒ ERROR: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
